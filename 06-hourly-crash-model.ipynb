{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Citywide Crash Predictive ML Model\n",
    "\n",
    "We will create a Logistic Regression or Tree based model to predict the daily number of crashes at a known intersection using the following:\n",
    "- weather (temp, snow, rain, precip)\n",
    "- day of week (Mon, Tues...)\n",
    "- intersection characteristics\n",
    "    - speed limit\n",
    "    - volume of traffic\n",
    "    - region\n",
    "    - lanes/ways/turns/split/exit etc.\n",
    "- violations (may want a violations independent model)\n",
    "- red light cam present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from modules.myfuncs import *\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from datetime import datetime\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "# Decision Tree\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sqlite3 version: 2.6.0\n",
      "connected to database/rlc.db\n"
     ]
    }
   ],
   "source": [
    "conn = create_connection('database/rlc.db')  # function from myfuncs file\n",
    "c = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We will try to get data that is daily for all of the above info.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('cam_locations',), ('cam_startend',), ('daily_violations',), ('all_crashes',), ('hourly_congestion',), ('hourly_weather',), ('region_data',), ('intersection_cams',), ('all_hours',), ('int_startend',), ('intersection_chars',), ('signal_crashes',), ('rlc_all_hours',), ('daily_covid',), ('holidays',)]\n",
      "cam_locations\n",
      "\tcamera_id\n",
      "\tintersection\n",
      "\taddress\n",
      "\tviolation_date\n",
      "\tviolations\n",
      "\tlatitude\n",
      "\tlongitude\n",
      "\tmonth\n",
      "\tday\n",
      "\tweekday\n",
      "\tyear\n",
      "\n",
      "cam_startend\n",
      "\tcamera_id\n",
      "\tstart\n",
      "\tend\n",
      "\n",
      "daily_violations\n",
      "\tintersection\n",
      "\tcamera_id\n",
      "\taddress\n",
      "\tviolation_date\n",
      "\tviolations\n",
      "\tlatitude\n",
      "\tlongitude\n",
      "\tmonth\n",
      "\tday\n",
      "\tweekday\n",
      "\tyear\n",
      "\n",
      "all_crashes\n",
      "\tcrash_record_id\n",
      "\trd_no\n",
      "\tcrash_date\n",
      "\tposted_speed_limit\n",
      "\ttraffic_control_device\n",
      "\tdevice_condition\n",
      "\tweather_condition\n",
      "\tlighting_condition\n",
      "\tfirst_crash_type\n",
      "\ttrafficway_type\n",
      "\talignment\n",
      "\troadway_surface_cond\n",
      "\troad_defect\n",
      "\treport_type\n",
      "\tcrash_type\n",
      "\tdamage\n",
      "\tprim_contributory_cause\n",
      "\tsec_contributory_cause\n",
      "\tstreet_no\n",
      "\tstreet_direction\n",
      "\tstreet_name\n",
      "\tbeat_of_occurrence\n",
      "\tnum_units\n",
      "\tmost_severe_injury\n",
      "\tinjuries_total\n",
      "\tinjuries_fatal\n",
      "\tinjuries_incapacitating\n",
      "\tinjuries_non_incapacitating\n",
      "\tinjuries_reported_not_evident\n",
      "\tinjuries_no_indication\n",
      "\tinjuries_unknown\n",
      "\tcrash_hour\n",
      "\tcrash_day_of_week\n",
      "\tcrash_month\n",
      "\tlatitude\n",
      "\tlongitude\n",
      "\tlane_cnt\n",
      "\tintersection_related_i\n",
      "\thit_and_run_i\n",
      "\tcrash_date_est_i\n",
      "\twork_zone_i\n",
      "\twork_zone_type\n",
      "\tworkers_present_i\n",
      "\n",
      "hourly_congestion\n",
      "\tyear\n",
      "\tmonth\n",
      "\tday\n",
      "\thour\n",
      "\tregion_id\n",
      "\tbus_count\n",
      "\tnum_reads\n",
      "\tspeed\n",
      "\tweekday\n",
      "\tquantile_speed\n",
      "\n",
      "hourly_weather\n",
      "\ttemp\n",
      "\train_1h\n",
      "\train_3h\n",
      "\tsnow_1h\n",
      "\tsnow_3h\n",
      "\tweather_main\n",
      "\ttime\n",
      "\tyear\n",
      "\tmonth\n",
      "\tday\n",
      "\thour\n",
      "\tweekday\n",
      "\n",
      "region_data\n",
      "\tregion_id\n",
      "\tregion\n",
      "\tdescription\n",
      "\tnorth\n",
      "\tsouth\n",
      "\teast\n",
      "\twest\n",
      "\n",
      "intersection_cams\n",
      "\tintersection\n",
      "\tlatitude\n",
      "\tlongitude\n",
      "\tcam1\n",
      "\tcam2\n",
      "\tcam3\n",
      "\tregion_id\n",
      "\n",
      "all_hours\n",
      "\tdatetime\n",
      "\tday\n",
      "\thour\n",
      "\tintersection\n",
      "\tmonth\n",
      "\tyear\n",
      "\n",
      "int_startend\n",
      "\tintersection\n",
      "\tstart\n",
      "\tend\n",
      "\n",
      "intersection_chars\n",
      "\tprotected_turn\n",
      "\ttotal_lanes\n",
      "\tmedians\n",
      "\texit\n",
      "\tsplit\n",
      "\tway\n",
      "\tunderpass\n",
      "\tno_left\n",
      "\tangled\n",
      "\ttriangle\n",
      "\tone_way\n",
      "\tturn_lanes\n",
      "\tlat\n",
      "\tlong\n",
      "\trlc\n",
      "\tintersection\n",
      "\tdaily_traffic\n",
      "\tspeed\n",
      "\n",
      "signal_crashes\n",
      "\tcrash_record_id\n",
      "\trd_no\n",
      "\tcrash_date\n",
      "\tposted_speed_limit\n",
      "\ttraffic_control_device\n",
      "\tdevice_condition\n",
      "\tweather_condition\n",
      "\tlighting_condition\n",
      "\tfirst_crash_type\n",
      "\ttrafficway_type\n",
      "\talignment\n",
      "\troadway_surface_cond\n",
      "\troad_defect\n",
      "\treport_type\n",
      "\tcrash_type\n",
      "\tdamage\n",
      "\tprim_contributory_cause\n",
      "\tsec_contributory_cause\n",
      "\tstreet_no\n",
      "\tstreet_direction\n",
      "\tstreet_name\n",
      "\tbeat_of_occurrence\n",
      "\tnum_units\n",
      "\tmost_severe_injury\n",
      "\tinjuries_total\n",
      "\tinjuries_fatal\n",
      "\tinjuries_incapacitating\n",
      "\tinjuries_non_incapacitating\n",
      "\tinjuries_reported_not_evident\n",
      "\tinjuries_no_indication\n",
      "\tinjuries_unknown\n",
      "\tcrash_hour\n",
      "\tcrash_day_of_week\n",
      "\tcrash_month\n",
      "\tlatitude\n",
      "\tlongitude\n",
      "\tlane_cnt\n",
      "\tintersection_related_i\n",
      "\thit_and_run_i\n",
      "\tcrash_date_est_i\n",
      "\twork_zone_i\n",
      "\twork_zone_type\n",
      "\tworkers_present_i\n",
      "\tintersection\n",
      "\tyear\n",
      "\tmonth\n",
      "\tday\n",
      "\thour\n",
      "\tregion_id\n",
      "\ttime\n",
      "\tweekday\n",
      "\tstart\n",
      "\tend\n",
      "\trlc_state\n",
      "\n",
      "rlc_all_hours\n",
      "\tdatetime\n",
      "\tday\n",
      "\thour\n",
      "\tintersection\n",
      "\tmonth\n",
      "\tyear\n",
      "\trlc_state\n",
      "\n",
      "daily_covid\n",
      "\tlab_report_date\n",
      "\tcases_total\n",
      "\tdeaths_total\n",
      "\tcases_age_0_17\n",
      "\tcases_age_18_29\n",
      "\tcases_age_30_39\n",
      "\tcases_age_40_49\n",
      "\tcases_age_50_59\n",
      "\tcases_age_60_69\n",
      "\tcases_age_70_79\n",
      "\tcases_age_80_\n",
      "\tcases_age_unknown\n",
      "\tcases_female\n",
      "\tcases_male\n",
      "\tcases_unknown_gender\n",
      "\tcases_latinx\n",
      "\tcases_asian_non_latinx\n",
      "\tcases_black_non_latinx\n",
      "\tcases_white_non_latinx\n",
      "\tcases_other_non_latinx\n",
      "\tcases_unknown_race_eth\n",
      "\tdeaths_0_17_yrs\n",
      "\tdeaths_18_29_yrs\n",
      "\tdeaths_30_39_yrs\n",
      "\tdeaths_40_49_yrs\n",
      "\tdeaths_50_59_yrs\n",
      "\tdeaths_60_69_yrs\n",
      "\tdeaths_70_79_yrs\n",
      "\tdeaths_80_yrs\n",
      "\tdeaths_unknown_age\n",
      "\tdeaths_female\n",
      "\tdeaths_male\n",
      "\tdeaths_unknown_gender\n",
      "\tdeaths_latinx\n",
      "\tdeaths_asian_non_latinx\n",
      "\tdeaths_black_non_latinx\n",
      "\tdeaths_white_non_latinx\n",
      "\tdeaths_other_non_latinx\n",
      "\tdeaths_unknown_race_eth\n",
      "\thospitalizations_total\n",
      "\thospitalizations_age_0_17\n",
      "\thospitalizations_age_18_29\n",
      "\thospitalizations_age_30_39\n",
      "\thospitalizations_age_40_49\n",
      "\thospitalizations_age_50_59\n",
      "\thospitalizations_age_60_69\n",
      "\thospitalizations_age_70_79\n",
      "\thospitalizations_age_80_\n",
      "\thospitalizations_age_unknown\n",
      "\thospitalizations_female\n",
      "\thospitalizations_male\n",
      "\thospitalizations_unknown_gender\n",
      "\thospitalizations_latinx\n",
      "\thospitalizations_asian_non_latinx\n",
      "\thospitalizations_black_non_latinx\n",
      "\thospitalizations_white_non_latinx\n",
      "\thospitalizations_other_race_non_latinx\n",
      "\thospitalizations_unknown_race_ethnicity\n",
      "\n",
      "holidays\n",
      "\tindex\n",
      "\tdate\n",
      "\tholiday\n",
      "\tyear\n",
      "\tmonth\n",
      "\tday\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(sql_fetch_tables(c, conn))\n",
    "\n",
    "\n",
    "\n",
    "def table_info(c, conn):\n",
    "    '''\n",
    "    prints out all of the columns of every table in db\n",
    "    c : cursor object\n",
    "    conn : database connection object\n",
    "    '''\n",
    "    tables = c.execute(\"SELECT name FROM sqlite_master WHERE type='table';\").fetchall()\n",
    "    for table_name in tables:\n",
    "        table_name = table_name[0]\n",
    "        table = pd.read_sql_query(\"SELECT * from {} LIMIT 0\".format(table_name), conn)\n",
    "        print(table_name)\n",
    "        for col in table.columns:\n",
    "            print('\\t' + col)\n",
    "        print()\n",
    "\n",
    "table_info(c, conn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query our data\n",
    "I would like to get hourly intersection data with the following columns:\n",
    "\n",
    "\n",
    "signal_crashes\n",
    "\t-crash_date\n",
    "\t-posted_speed_limit\n",
    "\t-device_condition\n",
    "\t-weather_condition\n",
    "\t-lighting_condition\n",
    "\t-first_crash_type\n",
    "\t-trafficway_type\n",
    "\t-alignment\n",
    "\t-roadway_surface_cond\n",
    "\t-road_defect\n",
    "\t-report_type\n",
    "\t-crash_type\n",
    "\t-damage\n",
    "\t-prim_contributory_cause\n",
    "\t-sec_contributory_cause\n",
    "\t-street_no\n",
    "\t-street_direction\n",
    "\t-street_name\n",
    "\t-most_severe_injury\n",
    "\t-injuries_total\n",
    "\t-injuries_fatal\n",
    "\t-injuries_incapacitating\n",
    "\t-injuries_non_incapacitating\n",
    "\t-injuries_reported_not_evident\n",
    "\t-injuries_no_indication\n",
    "\t-injuries_unknown\n",
    "\t-latitude\n",
    "\t-longitude\n",
    "\t-lane_cnt\n",
    "\t-work_zone_i\n",
    "\t-work_zone_type\n",
    "\t-workers_present_i\n",
    "\t-intersection\n",
    "\t-year\n",
    "\t-month\n",
    "\t-day\n",
    "\t-hour\n",
    "\t-region_id\n",
    "\t-time\n",
    "\t-weekday\n",
    "\n",
    "hourly_weather\n",
    "\t-temp\n",
    "\t-rain_1h\n",
    "\t-rain_3h\n",
    "\t-snow_1h\n",
    "\t-snow_3h\n",
    "\t-time\n",
    "\t-year\n",
    "\t-month\n",
    "\t-day\n",
    "\t-hour\n",
    "\t-weekday\n",
    "\n",
    "hourly_congestion\n",
    "\t-year\n",
    "\t-month\n",
    "\t-day\n",
    "\t-hour\n",
    "\t-region_id\n",
    "\t-bus_count\n",
    "\t-num_reads\n",
    "\t-speed\n",
    "\t-weekday\n",
    "    \n",
    "Tables will be queried to JOIN on year, month, day, hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WHAT I REALLY NEED HERE\n",
    "A single dataset with the following:\n",
    "- daily intersection chars (all the stuff I entered)\n",
    "- daily intersection crashes (injuries, deaths, number etc)\n",
    "- daily wx (temp, precip mainly)\n",
    "- daily congestion (might not need this)\n",
    "- daily violations (already in the format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "186009.75\n"
     ]
    }
   ],
   "source": [
    "# Approximately how many entries should I expect to be looking at after filtering my data\n",
    "# 3 years, 4 months x 153 intersections\n",
    "print((365.25*3 + 30*4) *153)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query my db to get a DataFrame with crashes and intersection\n",
    "We will be using the number of crashes and injuries to do some t-tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To change from citywide to signal crashes only, change cr query from all_crashes to signal_crashes (line 31)\n",
    "# Query takes 5+ minutes\n",
    "\n",
    "big_df = pd.read_sql_query('''\n",
    "WITH v AS(SELECT  SUM(violations) as violations,\n",
    "            year,\n",
    "            month,\n",
    "            day\n",
    "\n",
    "    FROM daily_violations\n",
    "    GROUP BY year, month, day\n",
    "    ),\n",
    "\n",
    "    ah AS(SELECT year,\n",
    "                month,\n",
    "                day,\n",
    "                hour,\n",
    "                datetime\n",
    "            FROM all_hours\n",
    "            GROUP BY year, month, day, hour\n",
    "        ), \n",
    "\n",
    "    cr AS(SELECT strftime('%m',crash_date) AS month,\n",
    "                strftime('%Y',crash_date) AS year,\n",
    "                strftime('%d',crash_date) AS day,\n",
    "                strftime('%H',crash_date) AS hour,\n",
    "                crash_record_id,\n",
    "                injuries_total,\n",
    "                injuries_fatal\n",
    "                \n",
    "         FROM all_crashes\n",
    "        ),\n",
    "\n",
    "    wx AS(SELECT MAX(temp) AS temp,\n",
    "                (SUM(snow_1h) + SUM(rain_1h)) AS precip,\n",
    "                SUM(snow_1h) AS snow_1h,\n",
    "                SUM(rain_1h) AS rain_1h,\n",
    "                year,\n",
    "                month,\n",
    "                day,\n",
    "                hour\n",
    "        FROM hourly_weather\n",
    "        GROUP BY year, month, day, hour\n",
    "        ),\n",
    "    \n",
    "    cov AS(SELECT strftime('%m',lab_report_date) AS month,\n",
    "                strftime('%Y',lab_report_date) AS year,\n",
    "                strftime('%d',lab_report_date) AS day,\n",
    "                lab_report_date,\n",
    "                cases_total\n",
    "            FROM daily_covid as dc\n",
    "            GROUP BY year, month, day\n",
    "            ),\n",
    "            \n",
    "     cg AS(SELECT \n",
    "             (100 - AVG(quantile_speed))/100 as congestion,\n",
    "             year,\n",
    "             month,\n",
    "             day,\n",
    "             hour\n",
    "         FROM hourly_congestion\n",
    "         GROUP BY year, month, day, hour\n",
    "     )\n",
    "            \n",
    "    SELECT  strftime('%W',ah.datetime) AS week,\n",
    "            strftime('%w',ah.datetime) AS weekday,\n",
    "            ah.datetime,\n",
    "            ah.year,\n",
    "            ah.month,\n",
    "            ah.day,\n",
    "            ah.hour,\n",
    "\n",
    "            COUNT(DISTINCT cr.crash_record_id) as n_crash,\n",
    "\n",
    "            SUM(cr.injuries_total) AS injuries,\n",
    "            SUM(cr.injuries_fatal) AS injuries_fatal,\n",
    "\n",
    "\n",
    "            wx.temp,\n",
    "            wx.precip,\n",
    "            wx.snow_1h,\n",
    "            wx.rain_1h,\n",
    "            \n",
    "            v.violations,\n",
    "            \n",
    "            cg.congestion,\n",
    "            \n",
    "            cov.cases_total\n",
    "            \n",
    "\n",
    "    FROM ah\n",
    "    LEFT JOIN wx\n",
    "        ON wx.year = ah.year\n",
    "        AND wx.month = ah.month\n",
    "        AND wx.day = ah.day  \n",
    "        AND wx.hour = ah.hour\n",
    "    LEFT JOIN cr\n",
    "        ON cr.year = ah.year\n",
    "        AND cr.month = ah.month\n",
    "        AND cr.day = ah.day\n",
    "        AND cr.hour = ah.hour\n",
    "    LEFT JOIN cg\n",
    "        ON cg.year = ah.year\n",
    "        AND cg.month = ah.month\n",
    "        AND cg.day = ah.day\n",
    "        AND cg.hour = ah.hour\n",
    "    LEFT JOIN v\n",
    "        ON v.year = ah.year\n",
    "        AND v.month = ah.month\n",
    "        AND v.day = ah.day\n",
    "    LEFT JOIN cov\n",
    "        ON cov.year = ah.year\n",
    "        AND cov.month = ah.month\n",
    "        AND cov.day = ah.day\n",
    "\n",
    "    WHERE ah.datetime >= \\'2017-09-01\\' AND ah.datetime <= \\'2021-01-31\\'\n",
    "    GROUP BY ah.year, ah.month, ah.day, ah.hour\n",
    "    ORDER BY ah.year, ah.month, ah.day, ah.hour;\n",
    "                                    ''', conn)\n",
    "\n",
    "# Change date to speed up, but put it back to sept 1, 2017 when done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = big_df.copy()\n",
    "all_df['cases_total'].fillna(0, inplace=True)\n",
    "all_df['cases_total'] = all_df['cases_total'].astype(int)\n",
    "all_df['violations'].fillna(0, inplace=True)\n",
    "all_df['congestion'].fillna(0.1, inplace=True)\n",
    "all_df['datetime'] = pd.to_datetime(all_df['datetime'])\n",
    "\n",
    "all_df['month'] = all_df['month'].astype(str)\n",
    "all_df['weekday'] = all_df['weekday'].astype(str)\n",
    "all_df['hour'] = all_df['hour'].astype(str)\n",
    "\n",
    "\n",
    "# all_df.columns\n",
    "all_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# treat data as bool (did we have a wreck that day at that intersection?)\n",
    "# multiple crash days will be treated as one.  Wll\n",
    "y = all_df['n_crash'].fillna(0).astype(int)\n",
    "\n",
    "drop_cols = ['day', 'injuries', \n",
    "             'injuries_fatal', 'n_crash', 'week', 'datetime']\n",
    "\n",
    "# categoricals: week, month, weekday\n",
    "\n",
    "X = all_df.drop(columns=drop_cols) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df['n_crash'].value_counts()\n",
    "#165550 / 5245\n",
    "#5245 / 137\n",
    "#137/10\n",
    "\n",
    "X_ = pd.get_dummies(X)\n",
    "\n",
    "drop_cols = ['snow_1h', 'hour_9', 'month_5', 'month_2', 'hour_23', 'month_8', \n",
    "             'month_7', 'month_1', 'hour_10', 'month_6', 'hour_21', 'month_10', \n",
    "             'hour_22', 'hour_20', 'month_4', 'hour_0']\n",
    "X_ = X_.drop(columns=drop_cols) \n",
    "\n",
    "\n",
    "X_.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_, y, test_size=0.4, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "tree_reg = DecisionTreeRegressor() \n",
    "tree_reg.fit(X_train, y_train)\n",
    "tree_reg.score(X_test, y_test)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My base tree model is worse than just taking the mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# SKIP THIS CELL UNLESS PERFORMING GRID Search\n",
    "\n",
    "\n",
    "\n",
    "# # Create the parameter grid based on the results of random search \n",
    "# param_grid = {\n",
    "#     'bootstrap': [True],\n",
    "#     'max_depth': [5, 8, 10],\n",
    "#     'max_features': [12, 9, 6],\n",
    "#     'min_samples_leaf': [3, 4, 5],\n",
    "#     'min_samples_split': [4, 8, 12],\n",
    "#     'n_estimators': [200, 400, 800]\n",
    "# }\n",
    "# # Create a based model\n",
    "# rf = RandomForestRegressor()\n",
    "# # Instantiate the grid search model\n",
    "# grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=3, n_jobs=-1, verbose=0)\n",
    "\n",
    "# grid_search.fit(X_train, y_train)\n",
    "# print(grid_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=30,\n",
    "                      max_features=15, max_leaf_nodes=None,\n",
    "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                      min_samples_leaf=10, min_samples_split=24,\n",
    "                      min_weight_fraction_leaf=0.0, n_estimators=1000,\n",
    "                      n_jobs=-1, oob_score=False, random_state=0,\n",
    "                      verbose=0, warm_start=False)\n",
    "\n",
    "forest.fit(X_train, y_train)\n",
    "print(forest.score(X_test, y_test))  # quick feedback score for tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importances(model, X_train):\n",
    "    n_features = X_train.shape[1]\n",
    "    \n",
    "    importance = model.feature_importances_\n",
    "    features = X_train.columns.values\n",
    "    df = pd.DataFrame()\n",
    "    df['imp'] = importance\n",
    "    df['feat'] = features\n",
    "    df = df.sort_values(by=['imp'], ascending=True)\n",
    "\n",
    "    plt.figure(figsize=(8,len(df)//2))\n",
    "    plt.barh(range(len(df)), df['imp'], align='center', color='purple') \n",
    "    plt.yticks(np.arange(len(df)), df['feat'])\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.title('Feature Importance')\n",
    "    plt.xlabel('Importance')\n",
    "    plt.ylabel('Feature')\n",
    "    return list(df['feat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "features = plot_feature_importances(forest, X_train)\n",
    "print(features[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot our results and prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an hourly plot of actual and predicted values.\n",
    "\n",
    "\n",
    "days = ('Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday')\n",
    "pred = forest.predict(X_)\n",
    "\n",
    "plotme = all_df.copy()[['datetime', 'n_crash', 'weekday', 'precip', 'congestion', 'cases_total', 'violations', 'injuries', 'temp']]\n",
    "\n",
    "plotme['pred'] = pred\n",
    "plotme['MA'] = plotme.n_crash.rolling(5, min_periods=1, center=True, win_type='triang').mean()\n",
    "plotme['error'] = abs(pred - plotme.n_crash)/plotme.n_crash\n",
    "\n",
    "plotme.temp = plotme.temp.apply(lambda x: (x-273.15)*9/5+32) # K to F conversion temp\n",
    "plotme.weekday = plotme.weekday.apply(lambda x: days[int(x)])\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=[30, 5])\n",
    "\n",
    "plotme_range = plotme[plotme['datetime'] > datetime(2017, 9, 1)]\n",
    "\n",
    "\n",
    "hover_list = ['Pred crash: %{customdata[8]:.2f}',\n",
    "              'Actual crash: %{customdata[10]}',\n",
    "              'Error: %{customdata[9]:.1%}',\n",
    "                    'Date: %{customdata[0]}',\n",
    "                    \"Weekday: %{customdata[1]}\",\n",
    "                    \"Injuries: %{customdata[2]}\",\n",
    "                    \"Precip (mm): %{customdata[3]:.1f}\",\n",
    "                    \"Temp (F): %{customdata[4]:.1f}\",\n",
    "                    \"Congestion: %{customdata[5]:.2f}\",\n",
    "                    \"Daily violations: %{customdata[6]}\",\n",
    "                    \"Covid cases: %{customdata[7]}\",   \n",
    "             ]\n",
    "\n",
    "\n",
    "\n",
    "fig = px.bar(plotme_range, \n",
    "             x='datetime', \n",
    "             y='n_crash', \n",
    "             title='Chicago Hourly Crash Model',\n",
    "             \n",
    "             )\n",
    "  \n",
    "\n",
    "fig.add_scatter(x=plotme_range['datetime'],\n",
    "                y=plotme_range['MA'],\n",
    "                mode='lines',\n",
    "                hoverinfo='skip',\n",
    "                name='moving avg.',\n",
    "                line=dict(\n",
    "                            color='rgba(220, 0, 0, 0.5)',\n",
    "                            width=2\n",
    "                        ),\n",
    "                \n",
    "    )\n",
    "               \n",
    "    \n",
    "fig.add_scatter(x=plotme_range['datetime'], \n",
    "                y=plotme_range['pred'],\n",
    "                mode='markers',\n",
    "                name='model prediction',\n",
    "                #marker_color='black',\n",
    "\n",
    "                marker=dict(\n",
    "                            color='rgb(0,255,0)',\n",
    "                            size=5,\n",
    "                            line=dict(width=1,\n",
    "                                    color='DarkSlateGray'),\n",
    "                            ),\n",
    "                \n",
    "                customdata=plotme_range[['datetime', 'weekday', 'injuries', 'precip', 'temp', 'congestion', 'violations', 'cases_total', 'pred', 'error', 'n_crash']],\n",
    "                hovertemplate=\"<br>\".join(hover_list),  # break between all items  \n",
    "\n",
    "               )\n",
    "\n",
    "\n",
    "\n",
    "fig.update_yaxes(range=[0, plotme_range['n_crash'].max()])\n",
    "fig.update_layout(width=1200, height=500, legend=dict(x=0, y=1), hovermode='closest')\n",
    "fig.show()\n",
    "\n",
    "#fig.write_html('citywide_signalcrash_model.html')\n",
    "fig.write_html('citywide_allcrash_model.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scoring metrics for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y.describe())\n",
    "print()\n",
    "print('Cross validation score: {}'.format(cross_val_score(forest, X_, y, cv=5).mean())) # 2min\n",
    "print('MAE: {:.2f}'.format(mean_absolute_error(forest.predict(X_), y)))\n",
    "print('RMSE: {:.2f}'.format(np.sqrt(mean_squared_error(forest.predict(X_), y))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "With Random Forest Regressaion, we were able to:\n",
    "- Achieve ~65% accuracy for daily crashes citywide (r2=60)\n",
    "- Achieve >29% accuracy for daily signal crashes (smaller dataset) with MAE of ~1\n",
    "- identify the most important variables in our model (congestion, violations, temp, year, covid_cases)\n",
    "\n",
    "We were NOT able to improve the results using SMOTE.  Both ROC/AUC and score were worse, but wanted the code available if we decide to try the hourly data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
