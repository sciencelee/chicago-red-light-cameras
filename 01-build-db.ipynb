{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a SQL database\n",
    "This notebook builds the necessary db files for the project using SQLite3.\n",
    "\n",
    "Most data is taken from Chicago Data Portal https://data.cityofchicago.org/ using Socrata library.\n",
    "The API endpoints for the data are:\n",
    "- Red Light Violations: https://data.cityofchicago.org/resource/spqx-js37.json\n",
    "- Congestion by Region 2018-Present: https://data.cityofchicago.org/resource/kf7e-cur8.json\n",
    "- Congestion by Region 2013-2018: https://data.cityofchicago.org/resource/emtn-qqdi.json\n",
    "- Traffic Crashes: https://data.cityofchicago.org/resource/85ca-t3if.json\n",
    "\n",
    "Weather data is taken from https://openweathermap.org/weather-data and is saved as csv in data folder\n",
    "\n",
    "Tables to build:\n",
    "- daily_violations (one entry for each camera each day with total violations)\n",
    "- intersection_locations (one entry for each intersection with lat/long)\n",
    "- intersection_cams (one entry for each intersection with camera_ids)\n",
    "- signal_crashes (one entry for each intersection crash with many columns)\n",
    "- cam_locations (one entry for each cam, with lat/long)\n",
    "- cam_startend (one entry for each cam with start end dates for min/max dates active)\n",
    "- hourly_congestion (one entry per hour with bus speed averages for each region)\n",
    "- hourly_weather (one entry per hour with many weather cols)\n",
    "- region_data (one entry per region with locations and descriptions to place intersections)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Required Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install \"dask[complete]\"\n",
    "# from dask.distributed import Client, progress\n",
    "# client = Client(n_workers=2, threads_per_worker=2, memory_limit='1GB')\n",
    "# client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sodapy import Socrata\n",
    "#import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from modules.myfuncs import *\n",
    "import warnings\n",
    "import numpy as np\n",
    "from geopy.geocoders import Nominatim\n",
    "# import dask\n",
    "# import dask.dataframe as dd\n",
    "import gc\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create/connect to db and build the TABLEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sqlite3 version: 2.6.0\n",
      "connected to database/rlc2.db\n"
     ]
    }
   ],
   "source": [
    "# Create a db\n",
    "conn = create_connection('database/rlc2.db')  # function I created in myfuncs file\n",
    "c = conn.cursor()\n",
    "#conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the Socrata client\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Requests made without an app_token will be subject to strict throttling limits.\n"
     ]
    }
   ],
   "source": [
    "# Unauthenticated client only works with public data sets. Note 'None'\n",
    "# in place of application token, and no username or password:\n",
    "\n",
    "url = \"data.cityofchicago.org\"\n",
    "client = Socrata(url, None)\n",
    "\n",
    "# Example authenticated client (needed for non-public datasets):\n",
    "# client = Socrata(data.cityofchicago.org,\n",
    "#                  MyAppToken,\n",
    "#                  userame=\"user@example.com\",\n",
    "#                  password=\"AFakePassword\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TABLE builds\n",
    "\n",
    "For every TABLE\n",
    "- Use a Socrata client query to get all relevant data\n",
    "- Preprocess data as needed\n",
    "- Create Table\n",
    "\n",
    "Our data\n",
    "- rlc_cam is up to 1M redlight cams from 2015 to 2020\n",
    "- crash_data is up to 1M crashes from 2015 to 2020\n",
    "- traffic_data is up to 10M from 2015 to 2020\n",
    "\n",
    "Weather data is taken from csv in data folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Build daily_violations TABLE  from rlc_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get red light violation data from Socrata query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Red light violations\n",
    "# Takes several minutes to run and holds about 500mb in memory to build\n",
    "\n",
    "# First 1000000 results, returned as JSON from API / converted to Python list of dictionaries by sodapy\n",
    "rlc_df = client.get(\"spqx-js37\", #speed cams are at 'hhkd-xvj4' if you want to investigate?\n",
    "                     #where='violation_date > 01-01-2020',\n",
    "                     where='violation_date BETWEEN \\'2015-01-01T00:00:00.000\\' AND \\'2020-12-31T00:00:00.000\\'',\n",
    "                     limit=1000000,\n",
    "                    )\n",
    "\n",
    "rlc_df = pd.DataFrame.from_records(rlc_df) # Convert to pandas DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Red Light Camera Data\n",
    "\n",
    "Data Columns of interest:\n",
    "\n",
    "INTERSECTION -\n",
    "Intersection of the location of the red light enforcement camera(s). There may be more than one camera at each intersection. Plain Text\n",
    "\n",
    "CAMERA ID -\n",
    "A unique ID for each physical camera at an intersection, which may contain more than one camera. Plain Text\n",
    "\n",
    "ADDRESS\t-\n",
    "The address of the physical camera (CAMERA ID). The address may be the same for all cameras or different, based on the physical installation of each camera. Plain Text\n",
    "\n",
    "VIOLATION DATE -\n",
    "The date of when the violations occurred. NOTE: The citation may be issued on a different date. Date & Time\n",
    "\n",
    "VIOLATIONS - \n",
    "Number of violations for each camera on a particular day. Number\n",
    "\n",
    "LATITUDE -\n",
    "The latitude of the physical location of the camera(s) based on the ADDRESS column. Geocoded using the WGS84. Number\n",
    "\n",
    "LONGITUDE -\n",
    "The longitude of the physical location of the camera(s) based on the ADDRESS column. Geocoded using the WGS84.\n",
    "Number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Investigate rlc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 572558 entries, 0 to 572557\n",
      "Data columns (total 10 columns):\n",
      "intersection      572558 non-null object\n",
      "camera_id         572324 non-null object\n",
      "address           572558 non-null object\n",
      "violation_date    572558 non-null object\n",
      "violations        572558 non-null object\n",
      "x_coordinate      542736 non-null object\n",
      "y_coordinate      542736 non-null object\n",
      "latitude          542736 non-null object\n",
      "longitude         542736 non-null object\n",
      "location          542736 non-null object\n",
      "dtypes: object(10)\n",
      "memory usage: 43.7+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "intersection          0\n",
       "camera_id           234\n",
       "address               0\n",
       "violation_date        0\n",
       "violations            0\n",
       "x_coordinate      29822\n",
       "y_coordinate      29822\n",
       "latitude          29822\n",
       "longitude         29822\n",
       "location          29822\n",
       "dtype: int64"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rlc_df.info()\n",
    "rlc_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop nan values and unnecessary columns\n",
    "We see that we have all text/non-null objects.  Need to convert first before manipulating for preprocess.\n",
    "\n",
    "There are a fair number of missing locations/lat/long.  Hope to be able to replace those missing values.\n",
    "This represents a large enough portion of dataset that we should look them up.\n",
    "\n",
    "The na values for camera_id will have to be dropped, since we don't know what they are.\n",
    "\n",
    "We will not be using x andy y_coordinate, so we drop those.  We will also drop location.  We already have lat long in other columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "intersection          0\n",
       "camera_id             0\n",
       "address               0\n",
       "violation_date        0\n",
       "violations            0\n",
       "latitude          29808\n",
       "longitude         29808\n",
       "dtype: int64"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#client_df.dropna(subset=['camera_id']).isna().sum()\n",
    "try:\n",
    "    # put this is a try in case we run it twice, it will skip it.\n",
    "    rlc_df.dropna(subset=['camera_id'], inplace=True)\n",
    "    \n",
    "    # drop xy coord and location columns\n",
    "    rlc_df = rlc_df.drop(columns=['x_coordinate', 'y_coordinate', 'location'], index=1)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "\n",
    "\n",
    "rlc_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Manipulate datatypes for preprocessing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intersection</th>\n",
       "      <th>camera_id</th>\n",
       "      <th>address</th>\n",
       "      <th>violation_date</th>\n",
       "      <th>violations</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>weekday</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>IRVING PARK AND KILPATRICK</td>\n",
       "      <td>2763</td>\n",
       "      <td>4700 W IRVING PARK ROA</td>\n",
       "      <td>2015-04-09</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>115TH AND HALSTED</td>\n",
       "      <td>2552</td>\n",
       "      <td>11500 S HALSTED STREE</td>\n",
       "      <td>2015-04-08</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>IRVING PARK AND KILPATRICK</td>\n",
       "      <td>2764</td>\n",
       "      <td>4700 W IRVING PARK ROA</td>\n",
       "      <td>2015-04-19</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>ELSTON AND IRVING PARK</td>\n",
       "      <td>1503</td>\n",
       "      <td>3700 W IRVING PARK ROA</td>\n",
       "      <td>2015-04-23</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>4700 WESTERN</td>\n",
       "      <td>2141</td>\n",
       "      <td>4700 S WESTERN AVENUE</td>\n",
       "      <td>2019-06-05</td>\n",
       "      <td>3</td>\n",
       "      <td>41.808378</td>\n",
       "      <td>-87.684571</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 intersection camera_id                 address  \\\n",
       "0  IRVING PARK AND KILPATRICK      2763  4700 W IRVING PARK ROA   \n",
       "2           115TH AND HALSTED      2552   11500 S HALSTED STREE   \n",
       "3  IRVING PARK AND KILPATRICK      2764  4700 W IRVING PARK ROA   \n",
       "4      ELSTON AND IRVING PARK      1503  3700 W IRVING PARK ROA   \n",
       "5                4700 WESTERN      2141   4700 S WESTERN AVENUE   \n",
       "\n",
       "  violation_date  violations   latitude  longitude  month  day  weekday  year  \n",
       "0     2015-04-09           4        NaN        NaN      4    9        3  2015  \n",
       "2     2015-04-08           5        NaN        NaN      4    8        2  2015  \n",
       "3     2015-04-19           4        NaN        NaN      4   19        6  2015  \n",
       "4     2015-04-23           3        NaN        NaN      4   23        3  2015  \n",
       "5     2019-06-05           3  41.808378 -87.684571      6    5        2  2019  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rlc_df['violations'] = rlc_df['violations'].apply(int)\n",
    "rlc_df['latitude'] = rlc_df['latitude'].apply(float)\n",
    "rlc_df['longitude'] = rlc_df['longitude'].apply(float)\n",
    "rlc_df['violation_date'] = pd.to_datetime(rlc_df['violation_date'])\n",
    "rlc_df['month'] = rlc_df['violation_date'].apply(lambda x: int(x.month))\n",
    "rlc_df['day'] = rlc_df['violation_date'].apply(lambda x: int(x.day))  # fixed from dat to day!\n",
    "\n",
    "rlc_df['weekday'] = rlc_df['violation_date'].apply(lambda x: int(datetime.weekday(x)))\n",
    "rlc_df['year'] = rlc_df['violation_date'].apply(lambda x: int(x.year))\n",
    "\n",
    "rlc_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write the daily_violations TABLE - from rlc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def make_table(df, table_name, c, conn):\n",
    "    '''\n",
    "    table_name string\n",
    "    c cursor object\n",
    "    conn sql connection object\n",
    "    '''\n",
    "    if table_name in sql_fetch_tables(c, conn):  # helper function in myfuncs\n",
    "        delete_all_entries(c, conn, table_name) # in myfuncs\n",
    "    \n",
    "    df.to_sql(table_name, conn, if_exists='replace', index = False)    \n",
    "    print(sql_fetch_tables(c, conn))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('cam_locations',), ('cam_startend',), ('intersection_cams',), ('all_crashes',), ('hourly_congestion',), ('hourly_weather',), ('region_data',), ('signal_crashes',), ('daily_violations',)]\n"
     ]
    }
   ],
   "source": [
    "make_table(rlc_df, 'daily_violations', c, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Build cam_locations TABLE - from cam_locs AND cam_startend TABLE from cam_startend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make a df with info for each camera\n",
    "Will contain the following:\n",
    "- camera_id\n",
    "- location\n",
    "- start date (when was the camera turned on)\n",
    "- end date (when was the camera turned off)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam_df = rlc_df.copy()\n",
    "cam_df['start'] = cam_df['camera_id'].apply(lambda x: None)\n",
    "cam_df['end'] = cam_df['camera_id'].apply(lambda x: None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NA values in cam_startend:\n",
      "camera_id    0\n",
      "start        0\n",
      "end          0\n",
      "dtype: int64\n",
      "\n",
      "Describe cam_startend:\n",
      "       camera_id                start                  end\n",
      "count        363                  363                  363\n",
      "unique       363                   18                   19\n",
      "top         1173  2015-01-01 00:00:00  2020-12-31 00:00:00\n",
      "freq           1                  285                  243\n",
      "first        NaN  2015-01-01 00:00:00  2015-03-02 00:00:00\n",
      "last         NaN  2018-03-05 00:00:00  2020-12-31 00:00:00\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>camera_id</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1002</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>2020-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1003</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>2020-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1011</td>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>2020-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1014</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>2020-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1023</td>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>2020-12-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  camera_id      start        end\n",
       "0      1002 2015-01-01 2020-12-31\n",
       "1      1003 2015-01-01 2020-12-31\n",
       "2      1011 2015-01-02 2020-12-31\n",
       "3      1014 2015-01-01 2020-12-31\n",
       "4      1023 2015-01-02 2020-12-31"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cam_start = cam_df.groupby(['camera_id'])['violation_date'].min().reset_index()\n",
    "cam_end = cam_df.groupby(['camera_id'])['violation_date'].max().reset_index()\n",
    "\n",
    "cam_startend = cam_start.copy()\n",
    "\n",
    "#print(cam_end[cam_end['camera_id']=='1503'].values[0][1])  # for testing output\n",
    "cam_startend['end'] = cam_start['camera_id'].apply(lambda x: cam_end[cam_end['camera_id']==x].values[0][1])\n",
    "\n",
    "cam_startend.rename(columns={\"violation_date\": \"start\"}, inplace=True)\n",
    "                                                   \n",
    "print('NA values in cam_startend:', cam_startend.isna().sum(), end='\\n\\n', sep='\\n')\n",
    "\n",
    "print('Describe cam_startend:', cam_startend.describe(), end='\\n\\n', sep='\\n')\n",
    "\n",
    "cam_startend.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a db table that has camera locations and intersections\n",
    "Intersections are present (and addresses), but we do not have lat/long info for all cams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "rlc_df.groupby('camera_id')['latitude'].max()  # Some cams do not have any data for lat long at all\n",
    "\n",
    "\n",
    "# Some of the addresses are truncated and not able to lookup with geocode\n",
    "\n",
    "address_fix = {'2400 W VAN BUREN STREE': '2400 W VAN BUREN STREET',\n",
    "               '4700 W IRVING PARK ROA': '4700 W IRVING PARK ROAD',\n",
    "               '11500 S HALSTED STREE': '11500 S HALSTED STREET',\n",
    "               '5500 S WENTWORTH AVEN': '5500 S WENTWORTH AVENUE',\n",
    "                '10300 S HALSTED STREE': '10300 S HALSTED STREET',\n",
    "               '3700 W IRVING PARK ROA': '3700 W IRVING PARK ROAD',\n",
    "               '1600 W IRVING PARK ROA': '1600 W IRVING PARK ROAD',\n",
    "               '7900 S JEFFERY BOULEV': '7900 S JEFFERY BOULEVARD',\n",
    "               '2800 W IRVING PARK ROA': '2800 W IRVING PARK ROAD',\n",
    "               '5200 W IRVING PARK ROA': '5200 W IRVING PARK ROAD',\n",
    "               '3100 S DR MARTIN L KING': '3100 S MARTIN KING DRIVE',\n",
    "               '1600 W DIVERSEY PARKWA': '1600 W DIVERSEY PARKWAY',\n",
    "               '140 W KINZIE': '140 W Kinzie St',\n",
    "                '150 N SACRAMENTO BOUL': '150 N SACRAMENTO BOUL',\n",
    "               '800 N SACRAMENTO AVEN':'800 N SACRAMENTO AVENUE',\n",
    "               '3200 N LAKESHORE DRIV':'3200 N LAKE SHORE DRIVE',\n",
    "               '6400 W FULLERTON AVENU':'6400 W FULLERTON AVENUE',\n",
    "               '6400 N MILWAUKEE AVEN':'6400 N MILWAUKEE AVENUE',\n",
    "               '7900 S STONEY ISLAND':'7900 S Stony Island Ave',  \n",
    "               '150 N SACRAMENTO BOUL':'150 N SACRAMENTO BOULEVARD',\n",
    "                '3200 N LAKESHORE DRIVE':'3200 N Lake Shore Dr',\n",
    "               '7900 S STONEY ISLAND AVENUE':'7900 S Stony Island Ave',\n",
    "               '5600 W FULLERTON AVENU':'5600 W FULLERTON AVENUE',\n",
    "               '8700 S LAFAYETTE AVEN':'8700 S LAFAYETTE AVENUE',\n",
    "               '4400 N MILWAUKEE AVEN':'4400 N MILWAUKEE AVENUE',\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two of them\n",
      "    camera_id           intersection                  address violation_date  \\\n",
      "83      1421     DAMEN AND DIVERSEY  2000 W DIVERSEY PARKWAY     2017-11-30   \n",
      "84      1421  LARAMIE AND FULLERTON    2400 N LARAMIE AVENUE     2020-12-31   \n",
      "\n",
      "    violations   latitude  longitude  month  day  weekday  year  \n",
      "83           1  41.932394 -87.678173     11   30        3  2017  \n",
      "84           6  41.924152 -87.756295     12   31        6  2020  \n",
      "\n",
      "Damen/Diversey 1\n",
      "Laramie/Fullerton: 1219\n",
      "Total cams 363\n"
     ]
    }
   ],
   "source": [
    "# we had some incorrect data in the code below, but have a creative fix.\n",
    "\n",
    "cam_locs = rlc_df.groupby(['camera_id', 'intersection']).max().reset_index()\n",
    "cam_locs.head()\n",
    "\n",
    "# we find there is a mismatch between lens, one of them is duplicated\n",
    "len(cam_locs)  # 364 total\n",
    "len(cam_locs['camera_id'].unique()) # 363\n",
    "\n",
    "cam_locs[cam_locs['camera_id'].duplicated()]  # 1421 is dupe\n",
    "print('Two of them\\n', cam_locs[cam_locs['camera_id'] == '1421'])  # we see two of them\n",
    "print()\n",
    "\n",
    "# Which one is it?\n",
    "print('Damen/Diversey', rlc_df[(rlc_df['camera_id']=='1421') & (rlc_df['intersection']=='DAMEN AND DIVERSEY')]['camera_id'].count())\n",
    "print('Laramie/Fullerton:', rlc_df[(rlc_df['camera_id']=='1421') & (rlc_df['intersection']=='LARAMIE AND FULLERTON')]['camera_id'].count())\n",
    "\n",
    "# Turns out that a camera has two locations. One was only used one time.  We drop it.\n",
    "cam_locs = cam_locs[(cam_locs['camera_id']!='1421') | (cam_locs['intersection']!='DAMEN AND DIVERSEY')]\n",
    "print(\"Total cams\", len(cam_locs))  # 363 total (got rid of the bad one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "camera_id          0\n",
       "intersection       0\n",
       "address            0\n",
       "violation_date     0\n",
       "violations         0\n",
       "latitude          19\n",
       "longitude         19\n",
       "month              0\n",
       "day                0\n",
       "weekday            0\n",
       "year               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cam_locs.isna().sum()  # missing location for 19 cameras.  Let's fix it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like we also are missing 19 of the 363 cam locations.  Let's look it up!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "This section goes through all of the rlc and assigns latlong\n",
    "Many lights are missing it.  \n",
    "For each light, there is an address though.\n",
    "We use geocoding to get the latlong\n",
    "'''\n",
    "\n",
    "# let's get all of the red light cameras with their gps location.  \n",
    "# This will aid in placing the accidents at rlc intersections later (if closer than threshold point to point)\n",
    "# Some RLCs are missing location data,  but have addresses.  I can use geocoding I guess to look them up.\n",
    "\n",
    "\n",
    "geolocator = Nominatim(user_agent=\"https://github.com/sciencelee/chicago_rlc\")  # please change to match repo\n",
    "\n",
    "# Some example code\n",
    "#location = geolocator.geocode(\"175 5th Avenue NYC\")\n",
    "#print(location.address)\n",
    "# out: Flatiron Building, 175, 5th Avenue, Flatiron, New York, NYC, New York, ...\n",
    "\n",
    "#print((location.latitude, location.longitude))\n",
    "# out: (40.7410861, -73.9896297241625)\n",
    "\n",
    "#print(location.raw)\n",
    "# out: {'place_id': '9167009604', 'type': 'attraction', ...}\n",
    "\n",
    "\n",
    "# CAN USE THIS TO FIGURE OUT MY LAT LONG FROM RLC ADDRESS (or crash later)   \n",
    " \n",
    "def get_geocode(lat, long, address):\n",
    "    if lat > 0:  # it's a location\n",
    "        return (lat, long)\n",
    "    else: # it's a proper location tuple, and assumed to be correct latlong\n",
    "        if address in address_fix.keys(): address = address_fix[address]  # errors in the dataset chars omitted\n",
    "        # if we make it this far, we have no record of this cam_id yet, and it doesn't have a proper location\n",
    "        location = geolocator.geocode(address + ', Chicago, IL')\n",
    "        if location == None:\n",
    "            print(address+':'+address+' : could not geolocate') # print it out if we can't find (address errors)\n",
    "        else:\n",
    "            return (location.latitude, location.longitude)\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "# Got it down to one-liner for this. Found out you can't extract and assign series like you can variables\n",
    "cam_locs['location'] = cam_locs.apply(lambda x: get_geocode(x.latitude, x.longitude, x.address), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam_locs['location'].head()\n",
    "cam_locs['latitude'] = cam_locs['location'].apply(lambda x: x[0])\n",
    "cam_locs['longitude'] = cam_locs['location'].apply(lambda x: x[1])\n",
    "\n",
    "cam_locs = cam_locs.drop(columns=['violation_date', 'violations', 'month', 'weekday', 'year', 'location'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 363 entries, 0 to 363\n",
      "Data columns (total 6 columns):\n",
      "camera_id       363 non-null object\n",
      "intersection    363 non-null object\n",
      "address         363 non-null object\n",
      "latitude        363 non-null float64\n",
      "longitude       363 non-null float64\n",
      "day             363 non-null int64\n",
      "dtypes: float64(2), int64(1), object(3)\n",
      "memory usage: 19.9+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "camera_id       0\n",
       "intersection    0\n",
       "address         0\n",
       "latitude        0\n",
       "longitude       0\n",
       "day             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cam_locs.info()\n",
    "cam_locs.isna().sum() # No longer missing location for 19 cameras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lat long fixes\n",
    "During EDA, we found out that five cameras were in completely wrong lat/long location.  \n",
    "Several others were located a little too far from the intersection to work properly.  When we rebuild the db, we will use bigger number than 30 m.\n",
    "\n",
    "Here are the fixes I found easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_camlocs = {'WENTWORTH AND GARFIELD': (41.79435532184194, -87.63114616279303),\n",
    "                   'KIMBALL AND LINCOLN': (41.99454797825689, -87.71403619467101),\n",
    "                    'IRVING PARK AND LARAMIE': (41.95330280770521, -87.75714705140294),\n",
    "                   'IRVING PARK AND KILPATRICK': (41.953454972337305, -87.74460631799197),\n",
    "                   '31ST ST AND MARTIN LUTHER KING DRIVE':(41.838438059816816, -87.61731906497867),\n",
    "                   '31ST AND CALIFORNIA':(41.83743605501678, -87.6950324427879),\n",
    "                   'ELSTON AND LAWRENCE': (41.96809435761252, -87.74010862196117),\n",
    "                   'OGDEN AND KOSTNER':(41.84767736575193, -87.73437725628261),\n",
    "                    'IRVING PARK AND CALIFORNIA':(41.95399037931945, -87.69821479681646),\n",
    "                   'LAKE SHORE DR AND BELMONT': (41.940128786177176, -87.63954362976928),\n",
    "                     }\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>camera_id</th>\n",
       "      <th>intersection</th>\n",
       "      <th>address</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1002</td>\n",
       "      <td>WESTERN AND CERMAK</td>\n",
       "      <td>2200 S WESTERN AVENUE</td>\n",
       "      <td>41.851984</td>\n",
       "      <td>-87.685786</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1003</td>\n",
       "      <td>WESTERN AND CERMAK</td>\n",
       "      <td>2400 W CERMAK ROAD</td>\n",
       "      <td>41.852141</td>\n",
       "      <td>-87.685753</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1011</td>\n",
       "      <td>PETERSON AND WESTERN</td>\n",
       "      <td>6000 N WESTERN AVE</td>\n",
       "      <td>41.990586</td>\n",
       "      <td>-87.689822</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1014</td>\n",
       "      <td>PETERSON AND WESTERN</td>\n",
       "      <td>2400 W PETERSON</td>\n",
       "      <td>41.990609</td>\n",
       "      <td>-87.689735</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1023</td>\n",
       "      <td>IRVING PARK AND NARRAGANSETT</td>\n",
       "      <td>6400 W IRVING PK</td>\n",
       "      <td>41.953025</td>\n",
       "      <td>-87.786683</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  camera_id                  intersection                address   latitude  \\\n",
       "0      1002            WESTERN AND CERMAK  2200 S WESTERN AVENUE  41.851984   \n",
       "1      1003            WESTERN AND CERMAK     2400 W CERMAK ROAD  41.852141   \n",
       "2      1011          PETERSON AND WESTERN     6000 N WESTERN AVE  41.990586   \n",
       "3      1014          PETERSON AND WESTERN        2400 W PETERSON  41.990609   \n",
       "4      1023  IRVING PARK AND NARRAGANSETT       6400 W IRVING PK  41.953025   \n",
       "\n",
       "   longitude  day  \n",
       "0 -87.685786   31  \n",
       "1 -87.685753   31  \n",
       "2 -87.689822   31  \n",
       "3 -87.689735   31  \n",
       "4 -87.786683   31  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cam_locs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['camera_id', 'intersection', 'address', 'latitude', 'longitude', 'day'], dtype='object')\n",
      "41.79435532184194\n",
      "dict_keys(['WENTWORTH AND GARFIELD', 'KIMBALL AND LINCOLN', 'IRVING PARK AND LARAMIE', 'IRVING PARK AND KILPATRICK', '31ST ST AND MARTIN LUTHER KING DRIVE', '31ST AND CALIFORNIA', 'ELSTON AND LAWRENCE', 'OGDEN AND KOSTNER', 'IRVING PARK AND CALIFORNIA', 'LAKE SHORE DR AND BELMONT'])\n",
      "True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>camera_id</th>\n",
       "      <th>intersection</th>\n",
       "      <th>address</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1002</td>\n",
       "      <td>WESTERN AND CERMAK</td>\n",
       "      <td>2200 S WESTERN AVENUE</td>\n",
       "      <td>41.851984</td>\n",
       "      <td>-87.685786</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1003</td>\n",
       "      <td>WESTERN AND CERMAK</td>\n",
       "      <td>2400 W CERMAK ROAD</td>\n",
       "      <td>41.852141</td>\n",
       "      <td>-87.685753</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1011</td>\n",
       "      <td>PETERSON AND WESTERN</td>\n",
       "      <td>6000 N WESTERN AVE</td>\n",
       "      <td>41.990586</td>\n",
       "      <td>-87.689822</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1014</td>\n",
       "      <td>PETERSON AND WESTERN</td>\n",
       "      <td>2400 W PETERSON</td>\n",
       "      <td>41.990609</td>\n",
       "      <td>-87.689735</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1023</td>\n",
       "      <td>IRVING PARK AND NARRAGANSETT</td>\n",
       "      <td>6400 W IRVING PK</td>\n",
       "      <td>41.953025</td>\n",
       "      <td>-87.786683</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  camera_id                  intersection                address   latitude  \\\n",
       "0      1002            WESTERN AND CERMAK  2200 S WESTERN AVENUE  41.851984   \n",
       "1      1003            WESTERN AND CERMAK     2400 W CERMAK ROAD  41.852141   \n",
       "2      1011          PETERSON AND WESTERN     6000 N WESTERN AVE  41.990586   \n",
       "3      1014          PETERSON AND WESTERN        2400 W PETERSON  41.990609   \n",
       "4      1023  IRVING PARK AND NARRAGANSETT       6400 W IRVING PK  41.953025   \n",
       "\n",
       "   longitude  day  \n",
       "0 -87.685786   31  \n",
       "1 -87.685753   31  \n",
       "2 -87.689822   31  \n",
       "3 -87.689735   31  \n",
       "4 -87.786683   31  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(cam_locs.columns)\n",
    "\n",
    "print(correct_camlocs['WENTWORTH AND GARFIELD'][0])\n",
    "print(correct_camlocs.keys())\n",
    "print('WENTWORTH AND GARFIELD' in correct_camlocs.keys())\n",
    "cam_locs['latitude'] = cam_locs.apply(lambda x: correct_camlocs[x['intersection']][0] if x['intersection'] in correct_camlocs.keys() else x['latitude'], axis=1)\n",
    "cam_locs['longitude'] = cam_locs.apply(lambda x: correct_camlocs[x['intersection']][1] if x['intersection'] in correct_camlocs.keys() else x['longitude'], axis=1)\n",
    "\n",
    "cam_locs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create cam_locations TABLE - from cam_locs AND cam_startend from cam_startend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('cam_startend',), ('intersection_cams',), ('all_crashes',), ('hourly_congestion',), ('hourly_weather',), ('region_data',), ('signal_crashes',), ('daily_violations',), ('cam_locations',)]\n",
      "[('intersection_cams',), ('all_crashes',), ('hourly_congestion',), ('hourly_weather',), ('region_data',), ('signal_crashes',), ('daily_violations',), ('cam_locations',), ('cam_startend',)]\n"
     ]
    }
   ],
   "source": [
    "make_table(cam_locs, 'cam_locations', c, conn)\n",
    "make_table(cam_startend, 'cam_startend', c, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  We still have missing lat/long info for our rlc_df.  Let's fix it\n",
    "Before moving on.  Now that we have cam_locs, we can fix our rlc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>camera_id</th>\n",
       "      <th>intersection</th>\n",
       "      <th>address</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1002</td>\n",
       "      <td>WESTERN AND CERMAK</td>\n",
       "      <td>2200 S WESTERN AVENUE</td>\n",
       "      <td>41.851984</td>\n",
       "      <td>-87.685786</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1003</td>\n",
       "      <td>WESTERN AND CERMAK</td>\n",
       "      <td>2400 W CERMAK ROAD</td>\n",
       "      <td>41.852141</td>\n",
       "      <td>-87.685753</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1011</td>\n",
       "      <td>PETERSON AND WESTERN</td>\n",
       "      <td>6000 N WESTERN AVE</td>\n",
       "      <td>41.990586</td>\n",
       "      <td>-87.689822</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1014</td>\n",
       "      <td>PETERSON AND WESTERN</td>\n",
       "      <td>2400 W PETERSON</td>\n",
       "      <td>41.990609</td>\n",
       "      <td>-87.689735</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1023</td>\n",
       "      <td>IRVING PARK AND NARRAGANSETT</td>\n",
       "      <td>6400 W IRVING PK</td>\n",
       "      <td>41.953025</td>\n",
       "      <td>-87.786683</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  camera_id                  intersection                address   latitude  \\\n",
       "0      1002            WESTERN AND CERMAK  2200 S WESTERN AVENUE  41.851984   \n",
       "1      1003            WESTERN AND CERMAK     2400 W CERMAK ROAD  41.852141   \n",
       "2      1011          PETERSON AND WESTERN     6000 N WESTERN AVE  41.990586   \n",
       "3      1014          PETERSON AND WESTERN        2400 W PETERSON  41.990609   \n",
       "4      1023  IRVING PARK AND NARRAGANSETT       6400 W IRVING PK  41.953025   \n",
       "\n",
       "   longitude  day  \n",
       "0 -87.685786   31  \n",
       "1 -87.685753   31  \n",
       "2 -87.689822   31  \n",
       "3 -87.689735   31  \n",
       "4 -87.786683   31  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rlc_df.isna().sum()  \n",
    "cam_locs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#⏳⏳⏳⏳⏳⏳\n",
    "# THIS TAKES SOME TIME (8min on my macbook pro)\n",
    "def read_loc(camloc_df, cam_id):\n",
    "    cam = camloc_df[camloc_df['camera_id']==cam_id]\n",
    "    return (float(cam['latitude']), float(cam['longitude']))\n",
    "        \n",
    "\n",
    "#read_loc(cam_locs, 45, 87, '1002')  # testing purposes\n",
    "#results_df[:5].apply(lambda x: x.latitude, axis=1)  # tsting purpose\n",
    "\n",
    "# create a location column so we only have to do it once\n",
    "rlc_df['location'] = rlc_df.apply(lambda x: read_loc(cam_locs, x.camera_id), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# then add in the new lat longs to the df\n",
    "rlc_df['latitude'] = rlc_df['location'].apply(lambda x: x[0])\n",
    "rlc_df['longitude'] = rlc_df['location'].apply(lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'location' in rlc_df.columns:\n",
    "    rlc_df.drop(columns=['location'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('intersection_cams',), ('all_crashes',), ('hourly_congestion',), ('hourly_weather',), ('region_data',), ('signal_crashes',), ('cam_locations',), ('cam_startend',), ('daily_violations',)]\n"
     ]
    }
   ],
   "source": [
    "make_table(rlc_df, 'daily_violations', c, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) intersection_locations TABLE - from intersection_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add a df of intersections with lat long\n",
    "This should help us later determine if crash is at intersection\n",
    "\n",
    "I chose to groupby the intersection and aggregate the most commonly occuring lat/long value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#results_df.groupby(['intersection', 'latitude', 'longitude']).reset_index()\n",
    "intersection_df = rlc_df.groupby(['intersection']).agg({'latitude':pd.Series.mode,'longitude':pd.Series.mode,}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 183 entries, 0 to 182\n",
      "Data columns (total 3 columns):\n",
      "intersection    183 non-null object\n",
      "latitude        183 non-null object\n",
      "longitude       183 non-null object\n",
      "dtypes: object(3)\n",
      "memory usage: 4.4+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intersection</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>111TH AND HALSTED</td>\n",
       "      <td>41.6923</td>\n",
       "      <td>-87.6425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>115TH AND HALSTED</td>\n",
       "      <td>41.6848</td>\n",
       "      <td>-87.6426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>119TH AND HALSTED</td>\n",
       "      <td>41.6777</td>\n",
       "      <td>-87.6421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>31ST AND CALIFORNIA</td>\n",
       "      <td>41.8374</td>\n",
       "      <td>-87.695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>31ST ST AND MARTIN LUTHER KING DRIVE</td>\n",
       "      <td>41.8384</td>\n",
       "      <td>-87.6173</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           intersection latitude longitude\n",
       "0                     111TH AND HALSTED  41.6923  -87.6425\n",
       "1                     115TH AND HALSTED  41.6848  -87.6426\n",
       "2                     119TH AND HALSTED  41.6777  -87.6421\n",
       "3                   31ST AND CALIFORNIA  41.8374   -87.695\n",
       "4  31ST ST AND MARTIN LUTHER KING DRIVE  41.8384  -87.6173"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intersection_df.info()\n",
    "intersection_df.head()  # that was easy!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create intersection_locations TABLE - from intersection_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('intersection_cams',), ('all_crashes',), ('hourly_congestion',), ('hourly_weather',), ('region_data',), ('signal_crashes',), ('cam_locations',), ('cam_startend',), ('daily_violations',), ('intersction_locations',)]\n"
     ]
    }
   ],
   "source": [
    "make_table(intersection_df, 'intersction_locations', c, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Create intersection_cams TABLE - from int_cams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will now focus on trying to bring rlc intersections to our crashes\n",
    "We find that we have 363 cameras at 183 intersections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 363 entries, 0 to 363\n",
      "Data columns (total 6 columns):\n",
      "camera_id       363 non-null object\n",
      "intersection    363 non-null object\n",
      "address         363 non-null object\n",
      "latitude        363 non-null float64\n",
      "longitude       363 non-null float64\n",
      "day             363 non-null int64\n",
      "dtypes: float64(2), int64(1), object(3)\n",
      "memory usage: 19.9+ KB\n"
     ]
    }
   ],
   "source": [
    "cam_locs.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intersection</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>cam1</th>\n",
       "      <th>cam2</th>\n",
       "      <th>cam3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>111TH AND HALSTED</td>\n",
       "      <td>41.692465</td>\n",
       "      <td>-87.642441</td>\n",
       "      <td>2422</td>\n",
       "      <td>2424</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>115TH AND HALSTED</td>\n",
       "      <td>41.685190</td>\n",
       "      <td>-87.642280</td>\n",
       "      <td>2552</td>\n",
       "      <td>2553</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>119TH AND HALSTED</td>\n",
       "      <td>41.677923</td>\n",
       "      <td>-87.641990</td>\n",
       "      <td>2402</td>\n",
       "      <td>2404</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>31ST AND CALIFORNIA</td>\n",
       "      <td>41.837436</td>\n",
       "      <td>-87.695032</td>\n",
       "      <td>2061</td>\n",
       "      <td>2064</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>31ST ST AND MARTIN LUTHER KING DRIVE</td>\n",
       "      <td>41.838438</td>\n",
       "      <td>-87.617319</td>\n",
       "      <td>2121</td>\n",
       "      <td>2123</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           intersection   latitude  longitude  cam1  cam2  \\\n",
       "0                     111TH AND HALSTED  41.692465 -87.642441  2422  2424   \n",
       "1                     115TH AND HALSTED  41.685190 -87.642280  2552  2553   \n",
       "2                     119TH AND HALSTED  41.677923 -87.641990  2402  2404   \n",
       "3                   31ST AND CALIFORNIA  41.837436 -87.695032  2061  2064   \n",
       "4  31ST ST AND MARTIN LUTHER KING DRIVE  41.838438 -87.617319  2121  2123   \n",
       "\n",
       "   cam3  \n",
       "0  None  \n",
       "1  None  \n",
       "2  None  \n",
       "3  None  \n",
       "4  None  "
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_cams = cam_locs.groupby(['intersection']) \\\n",
    "                    .agg({'latitude':pd.Series.max, 'longitude':pd.Series.max,}) \\\n",
    "                    .reset_index()\n",
    "\n",
    "int_cams['cam1'] = int_cams['intersection'] \\\n",
    "                            .apply(lambda x: cam_locs[cam_locs['intersection']==x]['camera_id'].iloc[0])\n",
    "\n",
    "int_cams['cam2'] = int_cams['intersection'].apply( \\\n",
    "                            lambda x: None if len(cam_locs[cam_locs['intersection']==x])==1 \\\n",
    "                            else cam_locs[cam_locs['intersection']==x]['camera_id'].iloc[1])\n",
    "\n",
    "int_cams['cam3'] = int_cams['intersection'].apply( \\\n",
    "                            lambda x: None if len(cam_locs[cam_locs['intersection']==x])<3 \\\n",
    "                            else cam_locs[cam_locs['intersection']==x]['camera_id'].iloc[2])                             \n",
    "\n",
    "int_cams.head()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Cameras 363\n",
      "Total Intersections 183\n"
     ]
    }
   ],
   "source": [
    "print('Total Cameras', len(cam_locs))\n",
    "print('Total Intersections', len(int_cams))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create intersection_cams TABLE - from int_cams\n",
    "first we add a column for region to each of my intersections\n",
    "#### Should come back and add this later.  Need to also bring in congestion data though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('all_crashes',), ('hourly_congestion',), ('hourly_weather',), ('region_data',), ('signal_crashes',), ('cam_locations',), ('cam_startend',), ('daily_violations',), ('intersction_locations',), ('intersection_cams',)]\n"
     ]
    }
   ],
   "source": [
    "make_table(int_cams, 'intersection_cams', c, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Create signal_crashes TABLE - from crash_df AND all_crashes - from crash_df (pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crash Data\n",
    "crash_data = client.get(\"85ca-t3if\", \n",
    "                     where=\"crash_date BETWEEN \\'2015-01-01T00:00:00.000\\' AND \\'2020-12-31T00:00:00.000\\'\",\n",
    "                     limit=1000000,\n",
    "                    )\n",
    "\n",
    "crash_df = pd.DataFrame.from_records(crash_data) # Convert to pandas DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crash data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop a few columns we don't need, including location (we have lat/long)\n",
    "dropme = ['statements_taken_i', 'private_property_i', 'photos_taken_i', 'dooring_i', 'date_police_notified','location']\n",
    "\n",
    "crash_df.drop(columns=dropme, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "crash_record_id                      0\n",
       "rd_no                                0\n",
       "crash_date                           0\n",
       "posted_speed_limit                   0\n",
       "traffic_control_device               0\n",
       "device_condition                     0\n",
       "weather_condition                    0\n",
       "lighting_condition                   0\n",
       "first_crash_type                     0\n",
       "trafficway_type                      0\n",
       "alignment                            0\n",
       "roadway_surface_cond                 0\n",
       "road_defect                          0\n",
       "report_type                       1784\n",
       "crash_type                           0\n",
       "hit_and_run_i                    48913\n",
       "damage                               0\n",
       "prim_contributory_cause              0\n",
       "sec_contributory_cause               0\n",
       "street_no                            0\n",
       "street_direction                     0\n",
       "street_name                          0\n",
       "beat_of_occurrence                   0\n",
       "num_units                            0\n",
       "most_severe_injury                  16\n",
       "injuries_total                      16\n",
       "injuries_fatal                      16\n",
       "injuries_incapacitating             16\n",
       "injuries_non_incapacitating         16\n",
       "injuries_reported_not_evident       16\n",
       "injuries_no_indication              16\n",
       "injuries_unknown                    16\n",
       "crash_hour                           0\n",
       "crash_day_of_week                    0\n",
       "crash_month                          0\n",
       "latitude                             0\n",
       "longitude                            0\n",
       "lane_cnt                         33264\n",
       "intersection_related_i               0\n",
       "crash_date_est_i                 57657\n",
       "work_zone_i                      59869\n",
       "work_zone_type                   59972\n",
       "workers_present_i                60236\n",
       "dtype: int64"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crash_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 2.5k entries that have no location.  Let's drop them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "crash_df.dropna(subset=['latitude',], inplace=True)  # get rid of na locations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's look at what is in the data   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "traffic_control_device ['TRAFFIC SIGNAL']\n",
      "device_condition ['FUNCTIONING PROPERLY' 'NO CONTROLS' 'UNKNOWN' 'NOT FUNCTIONING'\n",
      " 'FUNCTIONING IMPROPERLY' 'WORN REFLECTIVE MATERIAL' 'OTHER' 'MISSING']\n",
      "weather_condition ['CLEAR' 'RAIN' 'CLOUDY/OVERCAST' 'SNOW' 'FREEZING RAIN/DRIZZLE' 'UNKNOWN'\n",
      " 'FOG/SMOKE/HAZE' 'OTHER' 'SLEET/HAIL' 'BLOWING SNOW'\n",
      " 'SEVERE CROSS WIND GATE']\n",
      "lighting_condition ['DARKNESS, LIGHTED ROAD' 'DARKNESS' 'DAYLIGHT' 'DUSK' 'DAWN' 'UNKNOWN']\n",
      "first_crash_type ['ANGLE' 'SIDESWIPE SAME DIRECTION' 'TURNING' 'REAR END' 'PEDESTRIAN'\n",
      " 'REAR TO SIDE' 'FIXED OBJECT' 'HEAD ON' 'PEDALCYCLIST' 'OTHER OBJECT'\n",
      " 'SIDESWIPE OPPOSITE DIRECTION' 'REAR TO FRONT' 'OTHER NONCOLLISION'\n",
      " 'PARKED MOTOR VEHICLE' 'OVERTURNED' 'ANIMAL' 'TRAIN' 'REAR TO REAR']\n",
      "trafficway_type ['FOUR WAY' 'DIVIDED - W/MEDIAN (NOT RAISED)' 'NOT DIVIDED'\n",
      " 'DIVIDED - W/MEDIAN BARRIER' 'ONE-WAY' 'OTHER' 'T-INTERSECTION'\n",
      " 'CENTER TURN LANE' 'UNKNOWN' 'FIVE POINT, OR MORE' 'TRAFFIC ROUTE'\n",
      " 'PARKING LOT' 'NOT REPORTED' 'UNKNOWN INTERSECTION TYPE' 'RAMP'\n",
      " 'Y-INTERSECTION' 'ALLEY' 'DRIVEWAY' 'ROUNDABOUT' 'L-INTERSECTION']\n",
      "alignment ['STRAIGHT AND LEVEL' 'STRAIGHT ON GRADE' 'STRAIGHT ON HILLCREST'\n",
      " 'CURVE, LEVEL' 'CURVE ON GRADE' 'CURVE ON HILLCREST']\n",
      "roadway_surface_cond ['DRY' 'WET' 'SNOW OR SLUSH' 'UNKNOWN' 'ICE' 'OTHER' 'SAND, MUD, DIRT']\n",
      "road_defect ['NO DEFECTS' 'OTHER' 'UNKNOWN' 'RUT, HOLES' 'DEBRIS ON ROADWAY'\n",
      " 'WORN SURFACE' 'SHOULDER DEFECT']\n",
      "report_type ['ON SCENE' 'NOT ON SCENE (DESK REPORT)' nan 'AMENDED']\n",
      "crash_type ['INJURY AND / OR TOW DUE TO CRASH' 'NO INJURY / DRIVE AWAY']\n",
      "hit_and_run_i [nan 'Y' 'N']\n",
      "damage ['OVER $1,500' '$500 OR LESS' '$501 - $1,500']\n",
      "prim_contributory_cause ['DISREGARDING TRAFFIC SIGNALS' 'UNABLE TO DETERMINE'\n",
      " 'FOLLOWING TOO CLOSELY' 'FAILING TO REDUCE SPEED TO AVOID CRASH'\n",
      " 'FAILING TO YIELD RIGHT-OF-WAY' 'IMPROPER OVERTAKING/PASSING'\n",
      " 'DRIVING ON WRONG SIDE/WRONG WAY' 'IMPROPER TURNING/NO SIGNAL'\n",
      " 'CELL PHONE USE OTHER THAN TEXTING' 'IMPROPER LANE USAGE'\n",
      " 'EXCEEDING SAFE SPEED FOR CONDITIONS' 'EQUIPMENT - VEHICLE CONDITION'\n",
      " 'NOT APPLICABLE' 'DRIVING SKILLS/KNOWLEDGE/EXPERIENCE'\n",
      " 'DISREGARDING OTHER TRAFFIC SIGNS' 'IMPROPER BACKING' 'WEATHER'\n",
      " 'VISION OBSCURED (SIGNS, TREE LIMBS, BUILDINGS, ETC.)'\n",
      " 'PHYSICAL CONDITION OF DRIVER'\n",
      " 'UNDER THE INFLUENCE OF ALCOHOL/DRUGS (USE WHEN ARREST IS EFFECTED)'\n",
      " 'DISTRACTION - FROM OUTSIDE VEHICLE' 'DISREGARDING STOP SIGN'\n",
      " 'EVASIVE ACTION DUE TO ANIMAL, OBJECT, NONMOTORIST'\n",
      " 'DISTRACTION - FROM INSIDE VEHICLE' 'TURNING RIGHT ON RED'\n",
      " 'ROAD CONSTRUCTION/MAINTENANCE'\n",
      " 'ROAD ENGINEERING/SURFACE/MARKING DEFECTS'\n",
      " 'OPERATING VEHICLE IN ERRATIC, RECKLESS, CARELESS, NEGLIGENT OR AGGRESSIVE MANNER'\n",
      " 'DISTRACTION - OTHER ELECTRONIC DEVICE (NAVIGATION DEVICE, DVD PLAYER, ETC.)'\n",
      " 'EXCEEDING AUTHORIZED SPEED LIMIT'\n",
      " 'HAD BEEN DRINKING (USE WHEN ARREST IS NOT MADE)'\n",
      " 'DISREGARDING ROAD MARKINGS' 'RELATED TO BUS STOP' 'TEXTING' 'ANIMAL'\n",
      " 'DISREGARDING YIELD SIGN' 'OBSTRUCTED CROSSWALKS'\n",
      " 'BICYCLE ADVANCING LEGALLY ON RED LIGHT'\n",
      " 'MOTORCYCLE ADVANCING LEGALLY ON RED LIGHT' 'PASSING STOPPED SCHOOL BUS']\n",
      "sec_contributory_cause ['NOT APPLICABLE' 'UNABLE TO DETERMINE' 'FAILING TO YIELD RIGHT-OF-WAY'\n",
      " 'FAILING TO REDUCE SPEED TO AVOID CRASH' 'IMPROPER TURNING/NO SIGNAL'\n",
      " 'DRIVING SKILLS/KNOWLEDGE/EXPERIENCE'\n",
      " 'OPERATING VEHICLE IN ERRATIC, RECKLESS, CARELESS, NEGLIGENT OR AGGRESSIVE MANNER'\n",
      " 'IMPROPER LANE USAGE' 'DISREGARDING TRAFFIC SIGNALS'\n",
      " 'IMPROPER OVERTAKING/PASSING' 'EQUIPMENT - VEHICLE CONDITION'\n",
      " 'VISION OBSCURED (SIGNS, TREE LIMBS, BUILDINGS, ETC.)'\n",
      " 'DRIVING ON WRONG SIDE/WRONG WAY' 'WEATHER'\n",
      " 'DISREGARDING OTHER TRAFFIC SIGNS' 'FOLLOWING TOO CLOSELY'\n",
      " 'DISTRACTION - FROM INSIDE VEHICLE' 'EXCEEDING SAFE SPEED FOR CONDITIONS'\n",
      " 'ROAD ENGINEERING/SURFACE/MARKING DEFECTS' 'IMPROPER BACKING'\n",
      " 'DISREGARDING ROAD MARKINGS' 'TURNING RIGHT ON RED'\n",
      " 'OBSTRUCTED CROSSWALKS' 'HAD BEEN DRINKING (USE WHEN ARREST IS NOT MADE)'\n",
      " 'ROAD CONSTRUCTION/MAINTENANCE' 'PHYSICAL CONDITION OF DRIVER'\n",
      " 'EXCEEDING AUTHORIZED SPEED LIMIT' 'CELL PHONE USE OTHER THAN TEXTING'\n",
      " 'UNDER THE INFLUENCE OF ALCOHOL/DRUGS (USE WHEN ARREST IS EFFECTED)'\n",
      " 'DISTRACTION - FROM OUTSIDE VEHICLE'\n",
      " 'DISTRACTION - OTHER ELECTRONIC DEVICE (NAVIGATION DEVICE, DVD PLAYER, ETC.)'\n",
      " 'BICYCLE ADVANCING LEGALLY ON RED LIGHT' 'DISREGARDING YIELD SIGN'\n",
      " 'RELATED TO BUS STOP' 'DISREGARDING STOP SIGN'\n",
      " 'PASSING STOPPED SCHOOL BUS'\n",
      " 'EVASIVE ACTION DUE TO ANIMAL, OBJECT, NONMOTORIST' 'TEXTING' 'ANIMAL'\n",
      " 'MOTORCYCLE ADVANCING LEGALLY ON RED LIGHT']\n",
      "street_no ['1400' '7901' '3201' ... '7554' '7022' '7185']\n",
      "street_direction ['S' 'W' 'E' 'N']\n",
      "street_name ['CENTRAL PARK AVE' 'WESTERN AVE' 'DEVON AVE' 'CHICAGO AVE' 'PETERSON AVE'\n",
      " 'ASHLAND AVE' 'DAMEN AVE' 'LAWRENCE AVE' 'LA SALLE DR' 'STATE ST'\n",
      " 'HARRISON ST' 'LAKE ST' '59TH ST' 'FRANKLIN ST' 'LOGAN BLVD' 'HALSTED ST'\n",
      " 'FULLERTON AVE' 'GRAND AVE' 'MICHIGAN AVE' 'JEFFERY BLVD' 'SOUTHPORT AVE'\n",
      " 'LOOMIS BLVD' 'DR MARTIN LUTHER KING JR DR' '76TH ST' 'PULASKI RD'\n",
      " 'NORTH AVE' 'WALTON ST' 'FOSTER AVE' '87TH ST' 'CICERO AVE' 'LARAMIE AVE'\n",
      " 'COLUMBUS DR' 'DEARBORN ST' 'KEDZIE AVE' 'CLARK ST' 'SACRAMENTO BLVD'\n",
      " 'LAFAYETTE AVE' '43RD ST' 'JACKSON BLVD' '69TH ST' 'DIVISION ST'\n",
      " 'GARFIELD BLVD' 'CALIFORNIA BLVD' 'ORLEANS ST' 'ADDISON ST' '103RD ST'\n",
      " 'WENTWORTH AVE' 'SHERIDAN RD' 'WILSON AVE' 'DIVERSEY AVE' 'MONTROSE AVE'\n",
      " 'TOUHY AVE' 'EAST RIVER RD' 'SOUTH CHICAGO AVE' '75TH ST'\n",
      " 'STONY ISLAND AVE' '47TH ST' 'NAGLE AVE' 'JEFFERY AVE' 'HOMAN AVE'\n",
      " 'LOWER WACKER DR' '79TH ST' 'ARCHER AVE' 'WABASH AVE' '72ND ST' 'OHIO ST'\n",
      " 'IRVING PARK RD' 'WEBSTER AVE' 'OGDEN AVE' 'ILLINOIS ST' 'MARSHFIELD AVE'\n",
      " '83RD ST' 'RIDGE BLVD' 'ROOSEVELT RD' 'CERMAK RD' 'FULLERTON DR'\n",
      " '71ST ST' 'HARLEM AVE' 'ADAMS ST' 'CENTRAL AVE' '63RD ST' 'MADISON ST'\n",
      " '31ST ST' 'LOWER MICHIGAN AVE' '130TH ST' 'ST CLAIR ST' '115TH ST'\n",
      " 'WASHINGTON BLVD' 'GREENLEAF AVE' 'ROOSEVELT DR' 'AUGUSTA BLVD'\n",
      " 'BRYN MAWR AVE' '35TH ST' 'WELLS ST' 'WOOD ST' 'LINCOLN AVE'\n",
      " 'TORRENCE AVE' 'COTTAGE GROVE AVE' 'ASHLAND BLVD' 'CLYBOURN AVE'\n",
      " 'PARNELL AVE' 'HOLLYWOOD AVE' 'ERIE ST' 'INDEPENDENCE BLVD' 'MENARD AVE'\n",
      " 'INDIANA AVE' 'DOUGLAS BLVD' 'AUSTIN AVE' 'SAYRE AVE' '111TH ST'\n",
      " 'CONGRESS PKWY' 'CORTLAND ST' '18TH ST' '95TH ST' 'AINSLIE ST'\n",
      " 'MORGAN ST' 'BROADWAY' 'SOUTH SHORE DR' 'CALIFORNIA AVE' 'KOSTNER AVE'\n",
      " 'WESTERN BLVD' 'HYDE PARK BLVD' 'BEVERLY AVE' 'VAN BUREN ST' 'WACKER DR'\n",
      " 'MIDWAY PLAISANCE' 'FLOURNOY ST' 'OAKWOOD BLVD' 'BRAINARD AVE'\n",
      " 'BLOOMINGDALE AVE' 'WARREN BLVD' 'LEAVITT ST' 'RIDGE AVE' 'WASHINGTON ST'\n",
      " '11TH ST' 'EWING AVE' 'JEFFERSON ST' 'MARQUETTE RD' '127TH ST'\n",
      " 'PERSHING RD' 'AUSTIN BLVD' 'MARSHALL BLVD' 'CENTRAL PARK BLVD'\n",
      " 'LAKE SHORE DR SB' '65TH ST' '57TH DR' 'HOLLAND RD' 'INDIANAPOLIS AVE'\n",
      " 'NOBLE ST' 'SHEFFIELD AVE' '26TH ST' 'UNION AVE' 'NARRAGANSETT AVE'\n",
      " 'BELMONT AVE' 'VINCENNES AVE' 'LAKE SHORE DR' 'LAKE SHORE DR NB'\n",
      " 'ONTARIO ST' 'LAKE SHORE DR E' 'LAWRENCE DR' 'DIVERSEY PKWY' 'ELLIS AVE'\n",
      " 'RUBLE ST' 'LA SALLE ST' 'RANDOLPH ST' '33RD ST' 'ELSTON AVE'\n",
      " 'MILWAUKEE AVE' 'EXCHANGE AVE' 'COAST GUARD DR' 'LEXINGTON ST'\n",
      " 'CLINTON ST' 'COLUMBUS AVE' 'RACINE AVE' '74TH ST' 'SACRAMENTO AVE'\n",
      " 'ARMITAGE AVE' 'SEDGWICK ST' 'CANAL ST' 'HUBBARD ST'\n",
      " 'FOREST PRESERVE AVE' 'SUPERIOR ST' '98TH PL' 'NORMAL BLVD' 'ROGERS AVE'\n",
      " 'CORNELL DR' '109TH ST' 'HAMLIN AVE' 'MARQUETTE DR' 'KIMBALL AVE'\n",
      " 'HUMBOLDT DR' 'KEELER AVE' 'OAKLEY BLVD' 'LONGWOOD DR' 'TAYLOR ST'\n",
      " '37TH ST' '107TH ST' 'ANTHONY AVE' 'OAK ST' 'YATES BLVD' 'JACKSON DR'\n",
      " '99TH ST' 'COLFAX AVE' 'LAKE PARK AVE' 'HOWARD ST' '55TH ST' '47TH DR'\n",
      " 'HUMBOLDT BLVD' '29TH ST' 'CUMBERLAND AVE' '45TH ST' 'HAMLET AVE'\n",
      " 'OAK PARK AVE' '21ST ST' '53RD ST' 'NORTHWEST HWY' '119TH ST'\n",
      " 'CANALPORT AVE' 'MC CORMICK RD' '13TH ST' 'WOODLAWN AVE' 'RUSH ST'\n",
      " 'NORMAL AVE' 'HAMLIN BLVD' 'ROSCOE ST' '73RD ST' 'EMERALD AVE'\n",
      " 'HIGGINS AVE' 'ROCKWELL ST' 'LARRABEE ST' 'FULLERTON PKWY' 'AVENUE B'\n",
      " 'HURON ST' 'PRATT BLVD' 'LONG AVE' '51ST ST' 'LAKE SHORE DR W'\n",
      " 'LOOMIS ST' 'YALE AVE' 'WASHTENAW AVE' 'COMMERCIAL AVE' 'NASHVILLE AVE'\n",
      " '67TH ST' 'BALBO DR' 'GRANVILLE AVE' 'FARWELL AVE' 'LAWNDALE AVE'\n",
      " 'HERMITAGE AVE' 'MIES VAN DER ROHE WAY' 'KINGSBURY ST' 'DICKENS AVE'\n",
      " 'KILBOURN AVE' 'CONGRESS DR' 'DESPLAINES ST' 'CULLERTON ST' 'PALMER ST'\n",
      " 'AVENUE O' 'OHARE ST' 'CANNON DR' 'DOTY AVE E' '27TH ST' 'POLK ST'\n",
      " 'ZEMKE RD' 'FIFTH AVE' 'KINZIE ST' 'ALBANY AVE' 'CLARENDON AVE' '83RD PL'\n",
      " 'LAVERGNE AVE' 'PAULINA ST' '100TH ST' 'ARGYLE ST' 'CALDWELL AVE'\n",
      " 'CONSTANCE AVE' 'BUENA AVE' '81ST ST' 'POPE JOHN PAUL II DR' '89TH ST'\n",
      " '28TH ST' 'MONROE ST' 'EAST END AVE' '112TH PL' 'CORLISS AVE' '46TH ST'\n",
      " 'GLENWOOD AVE' 'RAVENSWOOD AVE' 'LOCK ST' 'MC CLURG CT' 'DREXEL BLVD'\n",
      " 'ROOT ST' 'BLUE ISLAND AVE' 'ANN LURIE PL' 'PROSPECT AVE' 'MONROE DR'\n",
      " '99TH PL' 'FAIRBANKS CT' 'KEEFE AVE' 'LEHIGH AVE' 'MAY ST' 'HYDE PARK DR'\n",
      " 'CORNELL AVE' 'BARRY AVE' 'SACRAMENTO DR' 'MARINE DR' 'CONGRESS PLAZA DR'\n",
      " 'COLUMBIA AVE' 'KILDARE AVE' '24TH ST' 'MANNHEIM RD' 'CHESTNUT ST'\n",
      " 'HIGGINS RD' 'LOWER COLUMBUS DR' 'SHERWIN AVE' 'PEARSON ST'\n",
      " 'IRVING PARK DR' 'CREGIER AVE' 'UNIVERSITY AVE' 'ESMOND ST' '45TH PL'\n",
      " 'WRIGHTWOOD AVE' 'FOREST GLEN AVE' 'FINANCIAL PL' 'BALBO AVE' 'HOYNE AVE'\n",
      " 'MARKETPLACE ACCESS RD' 'WALLACE ST' 'MONTEREY AVE' 'BERTEAU AVE'\n",
      " 'ST LOUIS AVE' '77TH ST' 'GREENWOOD AVE' 'ST LAWRENCE AVE' '61ST ST'\n",
      " 'DELAWARE PL' 'CENTRAL PARK DR' 'HAYES DR' 'KEELEY ST' '106TH ST'\n",
      " 'KEDZIE BLVD' '24TH PL' 'BERWYN AVE' 'PRINCETON AVE' 'MELVINA AVE'\n",
      " 'WILSON DR' 'DOBSON AVE' 'WABANSIA AVE' 'JAMES M ROCHFORD ST' 'LUNT AVE'\n",
      " 'BENNETT AVE' 'AVONDALE AVE' '91ST ST' 'GALE ST' 'BYRON ST' '93RD ST'\n",
      " '113TH ST' 'SHIELDS AVE' '56TH ST' 'GREEN ST' 'GARVEY CT' 'MAPLEWOOD AVE'\n",
      " 'GLENLAKE AVE' 'LOWER WACKER PL' 'GRACE ST' 'MAJOR AVE' 'BELL AVE'\n",
      " 'LANGLEY AVE' '57TH ST' 'KOLMAR AVE' 'KENNEDY EXPY IB' 'VERMONT ST'\n",
      " '60TH ST' 'CANFIELD AVE' '41ST PL' 'LECLAIRE AVE' 'LELAND AVE'\n",
      " 'NATOMA AVE' '8TH ST' 'THROOP ST' 'GREGORY ST' 'OGLESBY AVE'\n",
      " 'WINDSOR AVE' 'GENOA AVE' 'BALMORAL AVE' 'KENMORE AVE' 'LOWE AVE'\n",
      " 'RAVEN ST' 'FAIRFIELD AVE' 'OAKLEY AVE' 'NORTH WATER ST' 'STATE PKWY'\n",
      " '25TH ST' 'ALBION AVE' '19TH ST' '72ND PL' '11TH PL' 'DORCHESTER AVE'\n",
      " 'JERSEY AVE' '16TH ST' 'PINE GROVE AVE' 'WAVELAND AVE' 'STOCKTON DR'\n",
      " 'STEWART AVE' '15TH ST' 'MAYPOLE AVE' 'PROMONTORY DR' '31ST BLVD'\n",
      " 'FULTON BLVD' 'LOWER NORTH WATER ST' 'KILPATRICK AVE' 'GUNNISON ST'\n",
      " '9TH ST' 'HOMAN BLVD' 'FRANKLIN BLVD' '112TH ST' 'WOLCOTT AVE'\n",
      " 'GREENVIEW AVE' 'EGGLESTON AVE' 'LOYOLA AVE' '120TH ST' 'MC FETRIDGE DR'\n",
      " '114TH ST' 'ROBINSON ST' 'ARDMORE AVE' 'COLUMBUS SUB DR' 'SOUTH WATER ST'\n",
      " '73RD PL' 'THORNDALE AVE' 'KIMBARK AVE' 'TRUMBULL AVE' '126TH ST'\n",
      " 'WELLINGTON AVE' 'CORCORAN PL' 'MONTICELLO AVE' 'SPRINGFIELD AVE'\n",
      " 'PRAIRIE AVE' 'JEFFERY DR' 'BLACKSTONE AVE' 'HUDSON AVE' 'NORMANDY AVE'\n",
      " 'VICTORIA ST' 'LUELLA AVE' 'HARPER AVE' 'HIRSCH ST' 'WILLOW ST' '78TH ST'\n",
      " 'CATALPA AVE' 'FULTON ST' 'CARPENTER ST' 'FERDINAND ST' '68TH ST'\n",
      " '44TH ST' 'WARWICK AVE' 'WINSTON AVE' 'RICHMOND ST' 'WAYNE AVE'\n",
      " 'JUSTINE ST' '41ST ST' 'CATHERINE AVE' 'BELLE PLAINE AVE' 'TALCOTT AVE'\n",
      " 'CHARLES ST' 'RICHARDS DR' 'SCHOOL ST' 'SAUGANASH AVE' '92ND ST'\n",
      " 'STREETER DR' '35TH PL' 'MARCEY ST' 'SPAULDING AVE' 'WINNEMAC AVE'\n",
      " 'BIRCHWOOD AVE' 'WINTHROP AVE' 'SEELEY AVE' 'SAGINAW AVE' 'AVERS AVE'\n",
      " 'MIDWAY PLAISANCE N' '86TH PL' 'PEORIA ST' 'CLEVELAND AVE' 'MORSE AVE'\n",
      " 'HARDING AVE' 'PRATT AVE' 'KNOX AVE' 'BRIAR PL' 'BERENICE AVE' '31ST DR'\n",
      " 'BURTON PL' 'SUMMIT AVE' 'LEYDEN AVE' 'SAWYER AVE' 'SANGAMON ST'\n",
      " 'ABERDEEN ST' '58TH ST' 'PLYMOUTH CT' 'PALMER BLVD' 'OVERHILL AVE'\n",
      " 'FRANCISCO AVE' '14TH PL' 'RIDGEWAY AVE' 'KENNEDY EXPRESS RL'\n",
      " 'KENNEDY EXPY OB' 'FULTON MARKET' '118TH ST' '33RD PL'\n",
      " 'LOWER ILLINOIS ST' 'AVENUE L' 'LAKEVIEW AVE' 'CORNELIA AVE' 'TRIPP AVE'\n",
      " 'MOE DR' '84TH ST' 'MAPLE ST' '62ND ST' 'RIDGELAND AVE' 'HOUSTON AVE'\n",
      " 'DANTE AVE' 'LITHUANIAN PLAZA CT' 'LOCUST ST' '123RD ST' 'HONORE ST'\n",
      " 'KEDZIE SD' 'NORTH SHORE AVE' 'KERFOOT AVE' 'KENNETH AVE' 'KARLOV AVE'\n",
      " '66TH ST' 'LAMON AVE' 'NEWPORT AVE' '54TH ST' 'FEDERAL ST' 'BURLEY AVE'\n",
      " 'LOREL AVE' 'DREXEL AVE' '85TH ST' 'BELLEVUE PL' 'BLACKHAWK ST'\n",
      " '101ST ST' 'MINNEHAHA AVE' 'MONITOR AVE' 'LINCOLN PARK WEST' '65TH PL'\n",
      " 'TALMAN AVE' '82ND ST' 'ARTHINGTON ST' 'STETSON AVE' 'RAILROAD AVE'\n",
      " 'OCONTO AVE' 'SCHILLER ST' 'KEYSTONE AVE' '33RD BLVD' 'OGDEN'\n",
      " 'LOWER RANDOLPH ST' 'MUSKEGON AVE' 'WACKER RAMP' 'BEST DR' 'WEED ST'\n",
      " '36TH ST' 'MAYFIELD AVE' '107TH PL' 'STONY ISLAND EXT AVE' 'ELMDALE AVE'\n",
      " 'ELM ST' 'PAYNE DR' 'HASTINGS ST' 'ROSEMONT AVE' 'MUSEUM CAMPUS DR'\n",
      " 'LINDER AVE' 'GOETHE ST' 'SUNNYSIDE AVE' 'ADA ST' 'BISHOP ST'\n",
      " 'POTOMAC AVE' 'RHODES AVE' '138TH ST' 'MERCHANDISE MART PLZ'\n",
      " 'CALUMET AVE' 'WACKER SUB DR' '80TH ST' '64TH ST' 'VERNON AVE'\n",
      " 'MAXWELL ST' 'MELROSE ST' 'PIERCE AVE' '86TH ST' 'BEACON ST'\n",
      " 'MAGNOLIA AVE' 'FREMONT ST' 'OLMSTED AVE' 'CHAMPLAIN AVE' '49TH ST'\n",
      " 'LOCKWOOD AVE' 'WACKER RAMP DR' 'BELDEN AVE' '89TH PL' 'POST PL'\n",
      " 'EASTMAN ST' 'DELANO CT W' 'EUGENIE ST' 'MARYLAND AVE' 'MERRILL AVE'\n",
      " 'PARKSIDE AVE' 'ARTESIAN AVE' '38TH ST' '42ND ST' '66TH PL'\n",
      " '31ST ST OVERPASS' 'BUFFALO AVE' 'BRANDON AVE' '88TH ST' 'LOWELL AVE'\n",
      " '14TH ST' 'WARREN DR' 'WACKER PL' 'LENOX AVE' 'HOOD AVE' 'LAFLIN ST'\n",
      " '40TH PL' '24TH BLVD' 'CHRISTIANA AVE' 'SHORE DR' 'NORTH BRANCH ST'\n",
      " 'WALNUT ST' 'HARBOR DR' '129TH ST' 'JUNEWAY TER' 'WISCONSIN ST'\n",
      " 'GEORGE ST' 'JARVIS AVE' '48TH ST' 'STEVENSON EXPY IB' 'WENTWORTH ST'\n",
      " 'LAKE LOWER ST' 'PERRY AVE' 'RANDOLPH SD' '90TH ST' 'COMMODORE WHALEN DR'\n",
      " 'RIVERSIDE PLZ' 'PESHTIGO CT' '104TH ST' 'LAFAYETTE ST' 'MEADE AVE'\n",
      " 'EBERHART AVE' 'SCHUBERT AVE' 'MARBLE PL' 'LASALLE ST' '50TH ST'\n",
      " 'KEDVALE AVE' 'ALLPORT ST' 'LAKEWOOD AVE' 'HARBOR AVE' 'OSCEOLA AVE'\n",
      " 'NATCHEZ AVE' 'LAKE SHORE DR INNER' 'CITY FRONT PLAZA DR' '134TH ST'\n",
      " 'PALATINE AVE' 'EASTWOOD AVE' 'LAKE SHORE DR RAMP' 'ROSEHILL DR'\n",
      " 'DREXEL SQUARE DR' 'MARQUETTE AVE' '98TH ST' 'MACKINAW AVE'\n",
      " 'DICKENS BLVD' 'PAXTON AVE' 'MEDILL AVE' 'NORDICA AVE' 'CULLOM AVE'\n",
      " 'ELIZABETH ST' '23RD ST' '32ND ST' 'MOBILE AVE' 'ORCHARD ST'\n",
      " 'FRANKLIN ST XR' 'MASON AVE' '122ND ST' 'CLAREMONT AVE' 'LE MOYNE ST'\n",
      " 'LOWER SOUTH WATER ST' '40TH ST' 'FORD CITY DR' 'FARGO AVE' '130TH ST S'\n",
      " 'ALDINE AVE' 'IOWA ST' 'CAMPBELL AVE' 'MULLIGAN AVE' 'NEENAH AVE'\n",
      " 'LOWER WABASH AVE' 'SCHREIBER AVE' 'VANDERPOEL AVE' 'EISENHOWER EXPY IB'\n",
      " 'COLES AVE' 'CARMEN AVE' '113TH PL' 'KENWOOD AVE' 'GLADYS AVE'\n",
      " 'PHILLIPS AVE']\n",
      "beat_of_occurrence ['1011' '835' '2413' '1823' '1231' '1034' '1711' '2031' '1814' '322' '111'\n",
      " '712' '122' '1411' '2223' '1432' '1834' '225' '331' '1922' '612' '632'\n",
      " '624' '815' '1113' '1811' '1833' '1623' '634' '834' '1122' '1522' '2212'\n",
      " '114' '113' '833' '1022' '1124' '1024' '1131' '1212' '814' '2532' '2032'\n",
      " '724' '1822' '1831' '1924' '431' '915' '912' '2022' '614' '1913' '531'\n",
      " '1722' '2411' '2433' '1614' '925' '323' '1912' '324' '933' '412' '512'\n",
      " '1114' '1622' '934' '413' '1121' '131' '123' '813' '2534' '1433' '1532'\n",
      " '1832' '2535' '623' '1014' '2234' '622' '1523' '821' '124' '914' '1935'\n",
      " '1533' '931' '1613' '411' '825' '1222' '922' '133' '611' '434' '1414'\n",
      " '1123' '2423' '1221' '1921' '1531' '1612' '1235' '1031' '2221' '1713'\n",
      " '2011' '414' '911' '511' '2431' '1931' '1434' '935' '2521' '1233' '212'\n",
      " '1133' '1733' '1213' '1621' '1211' '723' '2514' '811' '1021' '2512' '822'\n",
      " '732' '1223' '823' '1914' '332' '2533' '633' '232' '2033' '1232' '2213'\n",
      " '1934' '1925' '831' '1215' '1214' '234' '1111' '2012' '2515' '735' '1225'\n",
      " '2232' '231' '711' '121' '214' '433' '1023' '1633' '631' '2531' '1224'\n",
      " '2432' '1524' '522' '731' '613' '621' '1134' '523' '722' '924' '1512'\n",
      " '423' '1033' '2523' '1712' '1234' '1724' '233' '1421' '812' '432' '725'\n",
      " '112' '824' '1923' '1824' '1723' '1632' '312' '1135' '1511' '132' '222'\n",
      " '213' '2024' '1812' '1032' '211' '1732' '1731' '1513' '726' '913' '424'\n",
      " '2013' '1611' '1915' '1423' '1132' '734' '921' '314' '932' '715' '1631'\n",
      " '1112' '1813' '1654' '1634' '2422' '1911' '2211' '1412' '1013' '1821'\n",
      " '334' '1932' '1115' '422' '311' '235' '532' '1424' '2412' '1624' '923'\n",
      " '2511' '333' '1422' '1431' '221' '733' '713' '2424' '215' '524' '2522'\n",
      " '2233' '513' '2525' '321' '714' '2222' '2513' '224' '2524' '1413' '1651'\n",
      " '1933' '2023' '421' '1125' '223' '832' '1012' '533' '313']\n",
      "num_units ['2' '3' '1' '4' '5' '6' '9' '7' '8' '10']\n",
      "most_severe_injury ['NO INDICATION OF INJURY' 'REPORTED, NOT EVIDENT'\n",
      " 'NONINCAPACITATING INJURY' 'INCAPACITATING INJURY' 'FATAL' nan]\n",
      "injuries_fatal ['0' '1' '2' nan '3']\n",
      "injuries_incapacitating ['0' '1' '2' '4' '3' '6' '5' nan]\n",
      "injuries_non_incapacitating ['0' '4' '1' '2' '3' '5' '6' '7' '18' nan '10' '21' '12' '8' '9' '16']\n",
      "injuries_reported_not_evident ['0' '1' '2' '5' '3' '4' '7' '10' '8' '6' nan '9' '11']\n",
      "injuries_no_indication ['3' '2' '7' '1' '4' '5' '0' '6' '8' '9' '11' '10' '16' '12' '21' '46'\n",
      " '17' '14' '27' '13' nan '42' '15' '20' '26' '19' '31' '37' '28']\n",
      "injuries_unknown ['0' nan]\n",
      "crash_hour ['2' '16' '20' '17' '8' '12' '13' '7' '11' '6' '22' '10' '14' '23' '19'\n",
      " '9' '4' '5' '0' '15' '18' '21' '1' '3']\n",
      "crash_day_of_week ['7' '4' '1' '6' '5' '2' '3']\n",
      "crash_month ['7' '11' '3' '8' '6' '10' '12' '4' '1' '5' '9' '2']\n",
      "latitude ['41.862315114' '41.750060363' '41.997278474' ... '41.883095977'\n",
      " '41.851424733' '41.92530411']\n",
      "longitude ['-87.715448345' '-87.682699127' '-87.709407357' ... '-87.635267687'\n",
      " '-87.618832705' '-87.640135841']\n",
      "lane_cnt [nan '4' '0' '6' '2' '3' '5' '1' '8' '7' '10' '12' '9' '16' '11' '15' '99'\n",
      " '41' '14']\n",
      "intersection_related_i ['Y']\n",
      "crash_date_est_i [nan 'Y' 'N']\n",
      "work_zone_i [nan 'Y' 'N']\n",
      "work_zone_type [nan 'MAINTENANCE' 'CONSTRUCTION' 'UNKNOWN' 'UTILITY']\n",
      "workers_present_i [nan 'Y' 'N']\n"
     ]
    }
   ],
   "source": [
    "# What's in this data?\n",
    "col_interest = ['traffic_control_device', 'device_condition', 'weather_condition',\n",
    "       'lighting_condition', 'first_crash_type', 'trafficway_type',\n",
    "       'alignment', 'roadway_surface_cond', 'road_defect', 'report_type',\n",
    "       'crash_type', 'hit_and_run_i', 'damage', 'prim_contributory_cause',\n",
    "       'sec_contributory_cause', 'street_no', 'street_direction',\n",
    "       'street_name', 'beat_of_occurrence', 'num_units', 'most_severe_injury', \n",
    "        'injuries_fatal', 'injuries_incapacitating',\n",
    "       'injuries_non_incapacitating', 'injuries_reported_not_evident',\n",
    "       'injuries_no_indication', 'injuries_unknown', 'crash_hour',\n",
    "       'crash_day_of_week', 'crash_month', 'latitude', 'longitude', 'lane_cnt',\n",
    "       'intersection_related_i', 'crash_date_est_i',\n",
    "       'work_zone_i', 'work_zone_type',\n",
    "       'workers_present_i']\n",
    "\n",
    "for col in col_interest:\n",
    "    print(col, crash_df[col].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter for desired crashes (intersections with signal)\n",
    "This helps us.  \n",
    "We can filter 'traffic_control_device' == 'TRAFFIC SIGNAL'.  \n",
    "We can filter 'intersection_related_i' == 'Y'\n",
    "\n",
    "This will leave us with only crashes that occurred at/because of intersections, and with a signal at the intersection.\n",
    "\n",
    "intersection_related_i: A field observation by the police officer whether an intersection played a role in the crash. Does not represent whether or not the crash occurred within the intersection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('hourly_congestion',), ('hourly_weather',), ('region_data',), ('signal_crashes',), ('cam_locations',), ('cam_startend',), ('daily_violations',), ('intersction_locations',), ('intersection_cams',), ('all_crashes',)]\n"
     ]
    }
   ],
   "source": [
    "make_table(crash_df, 'all_crashes', c, conn)\n",
    "\n",
    "crash_df = crash_df[(crash_df['traffic_control_device']=='TRAFFIC SIGNAL') & \\\n",
    "                    (crash_df['intersection_related_i']=='Y')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add the intersection to my crashes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WESTERN AND 79TH\n",
      "BLUE ISLAND AND DAMEN\n",
      "LAWRENCE AND WESTERN\n",
      "HALSTED AND 95TH\n",
      "WESTERN AND FULLERTON\n",
      "WESTERN AND ARMITAGE\n",
      "LAFAYETTE AND 87TH\n",
      "ASHLAND AND LAWRENCE\n",
      "WESTERN AND FULLERTON\n",
      "HOLLYWOOD AND SHERIDAN\n",
      "DIVERSEY AND WESTERN\n",
      "PULASKI AND MONTROSE\n",
      "BROADWAY/SHERIDAN AND DEVON\n",
      "CICERO AND 47TH\n",
      "PULASKI AND NORTH\n"
     ]
    }
   ],
   "source": [
    "#⏳⏳⏳⏳⏳\n",
    "# Now I am desperate.  This takes too long to process.  Let's simplify it and make it a box instead.\n",
    "box_side = 70  # effectively makes it check for crash being within 35m of interscection\n",
    "box_lat = box_side / 111070 / 2 # 111070 is meters in deg lat in Chicago\n",
    "box_long = box_side / 83000 / 2 # 83000 is meters in deg long in Chicago\n",
    "\n",
    "def box_check(lat, long, ints_df):\n",
    "    answer = (ints_df[  (ints_df['latitude'] > (lat - box_lat)) & \n",
    "                      (ints_df['latitude'] < (lat + box_lat)) &\n",
    "                      (ints_df['longitude'] > (long - box_long)) &\n",
    "                      (ints_df['longitude'] < (long + box_long))\n",
    "                     ])\n",
    "    if answer.empty: return None\n",
    "    return answer['intersection'].values[0]\n",
    "    \n",
    "# THIS SEEMS TO WORK WITH SPEED AND ELIMINATES MEMORY PROBLEM\n",
    "for i in range(100): #(len(df)):\n",
    "    intersect = box_check(float(crash_df.iloc[i]['latitude']), \n",
    "                          float(crash_df.iloc[i]['longitude']), \n",
    "                          int_cams)\n",
    "    if intersect: print(intersect)\n",
    "    \n",
    "    \n",
    "# MOMENT OF TRUTH (takes a few minutes, but at least it runs.  This caused me lots of trouble)\n",
    "crash_df['intersection'] = crash_df.apply(lambda x: box_check(float(x.latitude), \n",
    "                                                              float(x.longitude), \n",
    "                                                              int_cams), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Ex: df[['two', 'three']] = df[['two', 'three']].astype(float)\n",
    "crash_df['crash_date'] = pd.to_datetime(crash_df['crash_date'])\n",
    "crash_df['year'] = crash_df['crash_date'].apply(lambda x: int(x.year))\n",
    "crash_df['month'] = crash_df['crash_date'].apply(lambda x: int(x.month))\n",
    "crash_df['day'] = crash_df['crash_date'].apply(lambda x: int(x.day))\n",
    "crash_df['hour'] = crash_df['crash_date'].apply(lambda x: int(x.hour))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 60333 entries, 3 to 466341\n",
      "Data columns (total 48 columns):\n",
      "crash_record_id                  60333 non-null object\n",
      "rd_no                            60333 non-null object\n",
      "crash_date                       60333 non-null datetime64[ns]\n",
      "posted_speed_limit               60333 non-null object\n",
      "traffic_control_device           60333 non-null object\n",
      "device_condition                 60333 non-null object\n",
      "weather_condition                60333 non-null object\n",
      "lighting_condition               60333 non-null object\n",
      "first_crash_type                 60333 non-null object\n",
      "trafficway_type                  60333 non-null object\n",
      "alignment                        60333 non-null object\n",
      "roadway_surface_cond             60333 non-null object\n",
      "road_defect                      60333 non-null object\n",
      "report_type                      58549 non-null object\n",
      "crash_type                       60333 non-null object\n",
      "hit_and_run_i                    11420 non-null object\n",
      "damage                           60333 non-null object\n",
      "prim_contributory_cause          60333 non-null object\n",
      "sec_contributory_cause           60333 non-null object\n",
      "street_no                        60333 non-null object\n",
      "street_direction                 60333 non-null object\n",
      "street_name                      60333 non-null object\n",
      "beat_of_occurrence               60333 non-null object\n",
      "num_units                        60333 non-null object\n",
      "most_severe_injury               60317 non-null object\n",
      "injuries_total                   60317 non-null object\n",
      "injuries_fatal                   60317 non-null object\n",
      "injuries_incapacitating          60317 non-null object\n",
      "injuries_non_incapacitating      60317 non-null object\n",
      "injuries_reported_not_evident    60317 non-null object\n",
      "injuries_no_indication           60317 non-null object\n",
      "injuries_unknown                 60317 non-null object\n",
      "crash_hour                       60333 non-null object\n",
      "crash_day_of_week                60333 non-null object\n",
      "crash_month                      60333 non-null object\n",
      "latitude                         60333 non-null object\n",
      "longitude                        60333 non-null object\n",
      "lane_cnt                         27069 non-null object\n",
      "intersection_related_i           60333 non-null object\n",
      "crash_date_est_i                 2676 non-null object\n",
      "work_zone_i                      464 non-null object\n",
      "work_zone_type                   361 non-null object\n",
      "workers_present_i                97 non-null object\n",
      "intersection                     7777 non-null object\n",
      "year                             60333 non-null int64\n",
      "month                            60333 non-null int64\n",
      "day                              60333 non-null int64\n",
      "hour                             60333 non-null int64\n",
      "dtypes: datetime64[ns](1), int64(4), object(43)\n",
      "memory usage: 22.6+ MB\n"
     ]
    }
   ],
   "source": [
    "crash_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create signal_crashes TABLE - from crash_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('hourly_congestion',), ('hourly_weather',), ('region_data',), ('cam_locations',), ('cam_startend',), ('daily_violations',), ('intersction_locations',), ('intersection_cams',), ('all_crashes',), ('signal_crashes',)]\n"
     ]
    }
   ],
   "source": [
    "make_table(crash_df, 'signal_crashes', c, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Create hourly_congestion TABLE from all_traffic\n",
    "For this one, we have to combine two different datasets.  Chicago changed the way data was recorded in 2018.  Columns are similar, but more data collected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Congestion Data\n",
    "traffic_df = client.get(\"emtn-qqdi\", \n",
    "                     #where=\"TIME > \\'2015-01-01T00:00:00.000\\'\",\n",
    "                     where='TIME BETWEEN \\'2015-01-01T00:00:00.000\\' AND \\'2020-12-31T00:00:00.000\\'',\n",
    "                     limit=10000000,\n",
    "                    )\n",
    "\n",
    "traffic_df = pd.DataFrame.from_records(traffic_df) # Convert to pandas DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean up my datatypes before preprocessing\n",
    "Won't be able to table it until we get both datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic_df.rename(columns={'number_of_reads':'num_reads'}, inplace=True)\n",
    "traffic_df['time'] = pd.to_datetime(traffic_df['time'])\n",
    "traffic_df['bus_count'] = traffic_df['bus_count'].astype(int)\n",
    "traffic_df['num_reads'] = traffic_df['num_reads'].astype(int)\n",
    "traffic_df['speed'] = traffic_df['speed'].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On to the other dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Congestion data from later\n",
    "traffic_df2 = client.get(\"kf7e-cur8\", #2018 to present\n",
    "                     select='time, region_id, speed, bus_count, num_reads',  # this set is huge, so we won't get all       \n",
    "                     where=\"TIME < \\'2021-01-01T00:00:00.000\\'\",\n",
    "                     limit=10000000,\n",
    "                    )\n",
    "\n",
    "# Convert to pandas DataFrame\n",
    "traffic_df2 = pd.DataFrame.from_records(traffic_df2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "#traffic2_df.rename(columns={'number_of_reads':'num_reads'}, inplace=True)\n",
    "traffic_df2['time'] = pd.to_datetime(traffic_df2['time'])\n",
    "traffic_df2['bus_count'] = traffic_df2['bus_count'].astype(int)\n",
    "traffic_df2['num_reads'] = traffic_df2['num_reads'].astype(int)\n",
    "traffic_df2['speed'] = traffic_df2['speed'].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now get the congestion data processed\n",
    "We have two separate traffic_dfs.  There is data prior to 2018 and after in two different api endpoints.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3959185 entries, 0 to 3959184\n",
      "Data columns (total 5 columns):\n",
      "time         datetime64[ns]\n",
      "region_id    object\n",
      "speed        float64\n",
      "bus_count    int64\n",
      "num_reads    int64\n",
      "dtypes: datetime64[ns](1), float64(1), int64(2), object(1)\n",
      "memory usage: 151.0+ MB\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4168199 entries, 0 to 4168198\n",
      "Data columns (total 5 columns):\n",
      "time         datetime64[ns]\n",
      "region_id    object\n",
      "bus_count    int64\n",
      "num_reads    int64\n",
      "speed        float64\n",
      "dtypes: datetime64[ns](1), float64(1), int64(2), object(1)\n",
      "memory usage: 159.0+ MB\n"
     ]
    }
   ],
   "source": [
    "traffic_df.head()\n",
    "traffic_df2.head()\n",
    "traffic_df2.info()\n",
    "print()\n",
    "traffic_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "traffic dfs merged\n"
     ]
    }
   ],
   "source": [
    "# Merge my two data sets for congestion by region\n",
    "all_traffic = pd.merge(traffic_df, traffic_df2, how='outer')\n",
    "print('traffic dfs merged')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "added hour column\n",
      "added day column\n",
      "added month column\n",
      "added year column\n",
      "added weekday column\n"
     ]
    }
   ],
   "source": [
    "all_traffic['hour'] = all_traffic['time'].dt.hour\n",
    "print('added hour column')\n",
    "\n",
    "all_traffic['day'] = all_traffic.time.dt.day\n",
    "print('added day column')\n",
    "\n",
    "all_traffic['month'] = all_traffic.time.dt.month\n",
    "print('added month column')\n",
    "\n",
    "all_traffic['year'] = all_traffic.time.dt.year\n",
    "print('added year column')\n",
    "\n",
    "all_traffic['weekday'] = all_traffic.time.dt.weekday\n",
    "print('added weekday column')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7917308\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1331680 entries, 0 to 1331679\n",
      "Data columns (total 9 columns):\n",
      "year         1331680 non-null int64\n",
      "month        1331680 non-null int64\n",
      "day          1331680 non-null int64\n",
      "hour         1331680 non-null int64\n",
      "region_id    1331680 non-null object\n",
      "bus_count    1331680 non-null float64\n",
      "num_reads    1331680 non-null float64\n",
      "speed        1331680 non-null float64\n",
      "weekday      1331680 non-null float64\n",
      "dtypes: float64(4), int64(4), object(1)\n",
      "memory usage: 91.4+ MB\n"
     ]
    }
   ],
   "source": [
    "print(len(all_traffic))  # lots of dupes \n",
    "all_traffic = all_traffic.groupby(['year', 'month', 'day', 'hour', 'region_id']).mean().reset_index()\n",
    "all_traffic.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>region_id</th>\n",
       "      <th>bus_count</th>\n",
       "      <th>num_reads</th>\n",
       "      <th>speed</th>\n",
       "      <th>weekday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.333333</td>\n",
       "      <td>90.166667</td>\n",
       "      <td>27.455000</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>35.666667</td>\n",
       "      <td>386.666667</td>\n",
       "      <td>25.796667</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>15.833333</td>\n",
       "      <td>231.666667</td>\n",
       "      <td>25.816667</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>19.166667</td>\n",
       "      <td>259.500000</td>\n",
       "      <td>18.636667</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>367.833333</td>\n",
       "      <td>20.681667</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  month  day  hour region_id  bus_count   num_reads      speed  weekday\n",
       "0  2015      1    1     0         1   7.333333   90.166667  27.455000      3.0\n",
       "1  2015      1    1     0        10  35.666667  386.666667  25.796667      3.0\n",
       "2  2015      1    1     0        11  15.833333  231.666667  25.816667      3.0\n",
       "3  2015      1    1     0        12  19.166667  259.500000  18.636667      3.0\n",
       "4  2015      1    1     0        13  26.000000  367.833333  20.681667      3.0"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_traffic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('hourly_weather',), ('region_data',), ('cam_locations',), ('cam_startend',), ('daily_violations',), ('intersction_locations',), ('intersection_cams',), ('all_crashes',), ('signal_crashes',), ('hourly_congestion',)]\n"
     ]
    }
   ],
   "source": [
    "# couple minutes\n",
    "make_table(all_traffic, 'hourly_congestion', c, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speed fix for congestion\n",
    "Congestion is measured by average bus speed.\n",
    "\n",
    "The problem:\n",
    "- Overnight (between 11 and 5am) we have few bus routes.\n",
    "- Some regions have no buses overnight\n",
    "- Some regions have only a few buses \n",
    "- Some buses are ending routes and have only a few reads\n",
    "- Some buses are stationary (next morning staging)\n",
    "\n",
    "The fix:\n",
    "- replace speed for few buses/reads if speed is low\n",
    "- we assume low buses/reads to be overnight when congestion is minimal\n",
    "- replacement speed is a low congestion quantile speed (90% or so)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's get the 0.90 quantile for every region, and then use that to fill in missing data\n",
    "\n",
    "regions_90 = all_traffic.groupby(['region_id'])['speed'].quantile(0.9).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region_id</th>\n",
       "      <th>speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>25.058333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>26.385000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>26.803400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>23.070000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>24.091667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  region_id      speed\n",
       "0         1  25.058333\n",
       "1        10  26.385000\n",
       "2        11  26.803400\n",
       "3        12  23.070000\n",
       "4        13  24.091667"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regions_90.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 5 MINUTES OR SO\n",
    "\n",
    "#my read on this is that few buses run 24/7, so the data is unreliable.  \n",
    "# buses stage for next morning.  You can see them all along Clark, LSD etc.  \n",
    "# They have speed=0 and may be recording.  Could talk to owner of dataset.\n",
    "\n",
    "# I will draw the cutoff at 100 reads, 5 buses, speed < 10\n",
    "# in that case I will put in a quantile speed for the region\n",
    "\n",
    "\n",
    "def speed_check(bus, speed, reads, region_id, regions_90):\n",
    "    if (bus <= 5 or reads < 100) and speed < 25 or speed > 40:\n",
    "        return regions_90[regions_90['region_id']==region_id]['speed'].values[0]\n",
    "    else:\n",
    "        return speed\n",
    "    \n",
    "\n",
    "# apply is SLOOOOOOWWW, but not sure how else to accomplish this without iter\n",
    "all_traffic['speed'] = all_traffic.apply(lambda x: speed_check(x.bus_count, x.speed, x.num_reads, x.region_id, regions_90), axis=1)\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('hourly_weather',), ('region_data',), ('cam_locations',), ('cam_startend',), ('daily_violations',), ('intersction_locations',), ('intersection_cams',), ('all_crashes',), ('signal_crashes',), ('hourly_congestion',)]\n"
     ]
    }
   ],
   "source": [
    "make_table(all_traffic, 'hourly_congestion', c, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7) Create hourly_weather from wx_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import weather data from csv\n",
    "wx_df = pd.read_csv('data/chi_wx.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>dt_iso</th>\n",
       "      <th>timezone</th>\n",
       "      <th>city_name</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>temp</th>\n",
       "      <th>feels_like</th>\n",
       "      <th>temp_min</th>\n",
       "      <th>temp_max</th>\n",
       "      <th>...</th>\n",
       "      <th>wind_deg</th>\n",
       "      <th>rain_1h</th>\n",
       "      <th>rain_3h</th>\n",
       "      <th>snow_1h</th>\n",
       "      <th>snow_3h</th>\n",
       "      <th>clouds_all</th>\n",
       "      <th>weather_id</th>\n",
       "      <th>weather_main</th>\n",
       "      <th>weather_description</th>\n",
       "      <th>weather_icon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1420070400</td>\n",
       "      <td>2015-01-01 00:00:00 +0000 UTC</td>\n",
       "      <td>-21600</td>\n",
       "      <td>Chicago IL. USA</td>\n",
       "      <td>41.878114</td>\n",
       "      <td>-87.629798</td>\n",
       "      <td>265.96</td>\n",
       "      <td>258.16</td>\n",
       "      <td>264.85</td>\n",
       "      <td>267.708</td>\n",
       "      <td>...</td>\n",
       "      <td>230</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>800</td>\n",
       "      <td>Clear</td>\n",
       "      <td>sky is clear</td>\n",
       "      <td>01n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1420074000</td>\n",
       "      <td>2015-01-01 01:00:00 +0000 UTC</td>\n",
       "      <td>-21600</td>\n",
       "      <td>Chicago IL. USA</td>\n",
       "      <td>41.878114</td>\n",
       "      <td>-87.629798</td>\n",
       "      <td>266.13</td>\n",
       "      <td>256.52</td>\n",
       "      <td>265.35</td>\n",
       "      <td>267.926</td>\n",
       "      <td>...</td>\n",
       "      <td>230</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "      <td>801</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>few clouds</td>\n",
       "      <td>02n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1420077600</td>\n",
       "      <td>2015-01-01 02:00:00 +0000 UTC</td>\n",
       "      <td>-21600</td>\n",
       "      <td>Chicago IL. USA</td>\n",
       "      <td>41.878114</td>\n",
       "      <td>-87.629798</td>\n",
       "      <td>266.17</td>\n",
       "      <td>257.70</td>\n",
       "      <td>265.35</td>\n",
       "      <td>268.098</td>\n",
       "      <td>...</td>\n",
       "      <td>230</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "      <td>801</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>few clouds</td>\n",
       "      <td>02n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1420081200</td>\n",
       "      <td>2015-01-01 03:00:00 +0000 UTC</td>\n",
       "      <td>-21600</td>\n",
       "      <td>Chicago IL. USA</td>\n",
       "      <td>41.878114</td>\n",
       "      <td>-87.629798</td>\n",
       "      <td>266.39</td>\n",
       "      <td>257.56</td>\n",
       "      <td>265.35</td>\n",
       "      <td>268.157</td>\n",
       "      <td>...</td>\n",
       "      <td>240</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>800</td>\n",
       "      <td>Clear</td>\n",
       "      <td>sky is clear</td>\n",
       "      <td>01n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1420084800</td>\n",
       "      <td>2015-01-01 04:00:00 +0000 UTC</td>\n",
       "      <td>-21600</td>\n",
       "      <td>Chicago IL. USA</td>\n",
       "      <td>41.878114</td>\n",
       "      <td>-87.629798</td>\n",
       "      <td>266.47</td>\n",
       "      <td>256.50</td>\n",
       "      <td>265.35</td>\n",
       "      <td>268.121</td>\n",
       "      <td>...</td>\n",
       "      <td>240</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>800</td>\n",
       "      <td>Clear</td>\n",
       "      <td>sky is clear</td>\n",
       "      <td>01n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           dt                         dt_iso  timezone        city_name  \\\n",
       "0  1420070400  2015-01-01 00:00:00 +0000 UTC    -21600  Chicago IL. USA   \n",
       "1  1420074000  2015-01-01 01:00:00 +0000 UTC    -21600  Chicago IL. USA   \n",
       "2  1420077600  2015-01-01 02:00:00 +0000 UTC    -21600  Chicago IL. USA   \n",
       "3  1420081200  2015-01-01 03:00:00 +0000 UTC    -21600  Chicago IL. USA   \n",
       "4  1420084800  2015-01-01 04:00:00 +0000 UTC    -21600  Chicago IL. USA   \n",
       "\n",
       "         lat        lon    temp  feels_like  temp_min  temp_max  ...  \\\n",
       "0  41.878114 -87.629798  265.96      258.16    264.85   267.708  ...   \n",
       "1  41.878114 -87.629798  266.13      256.52    265.35   267.926  ...   \n",
       "2  41.878114 -87.629798  266.17      257.70    265.35   268.098  ...   \n",
       "3  41.878114 -87.629798  266.39      257.56    265.35   268.157  ...   \n",
       "4  41.878114 -87.629798  266.47      256.50    265.35   268.121  ...   \n",
       "\n",
       "   wind_deg  rain_1h  rain_3h  snow_1h  snow_3h  clouds_all  weather_id  \\\n",
       "0       230      NaN      NaN      NaN      NaN           1         800   \n",
       "1       230      NaN      NaN      NaN      NaN          20         801   \n",
       "2       230      NaN      NaN      NaN      NaN          20         801   \n",
       "3       240      NaN      NaN      NaN      NaN           1         800   \n",
       "4       240      NaN      NaN      NaN      NaN           1         800   \n",
       "\n",
       "   weather_main  weather_description  weather_icon  \n",
       "0         Clear         sky is clear           01n  \n",
       "1        Clouds           few clouds           02n  \n",
       "2        Clouds           few clouds           02n  \n",
       "3         Clear         sky is clear           01n  \n",
       "4         Clear         sky is clear           01n  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wx_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 55219 entries, 0 to 55218\n",
      "Data columns (total 26 columns):\n",
      "dt                     55219 non-null int64\n",
      "dt_iso                 55219 non-null object\n",
      "timezone               55219 non-null int64\n",
      "city_name              55219 non-null object\n",
      "lat                    55219 non-null float64\n",
      "lon                    55219 non-null float64\n",
      "temp                   55219 non-null float64\n",
      "feels_like             55219 non-null float64\n",
      "temp_min               55219 non-null float64\n",
      "temp_max               55219 non-null float64\n",
      "pressure               55219 non-null int64\n",
      "sea_level              0 non-null float64\n",
      "grnd_level             0 non-null float64\n",
      "humidity               55219 non-null int64\n",
      "wind_speed             55219 non-null float64\n",
      "wind_deg               55219 non-null int64\n",
      "rain_1h                6587 non-null float64\n",
      "rain_3h                816 non-null float64\n",
      "snow_1h                1538 non-null float64\n",
      "snow_3h                91 non-null float64\n",
      "clouds_all             55219 non-null int64\n",
      "weather_id             55219 non-null int64\n",
      "weather_main           55219 non-null object\n",
      "weather_description    55219 non-null object\n",
      "weather_icon           55219 non-null object\n",
      "time                   55219 non-null datetime64[ns, UTC]\n",
      "dtypes: datetime64[ns, UTC](1), float64(13), int64(7), object(5)\n",
      "memory usage: 11.0+ MB\n"
     ]
    }
   ],
   "source": [
    "wx_df['time'] = pd.to_datetime(wx_df['dt_iso'].apply(lambda x: x[:-4]))\n",
    "wx_df.head()\n",
    "wx_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "wx_df['rain_3h'] = wx_df['rain_3h'].fillna(0)\n",
    "wx_df['rain_1h'] = wx_df['rain_1h'].fillna(0)\n",
    "wx_df['snow_3h'] = wx_df['snow_3h'].fillna(0)\n",
    "wx_df['snow_1h'] = wx_df['snow_1h'].fillna(0)\n",
    "wx_df['temp'] = wx_df['temp_max']\n",
    "wx_df['year'] = wx_df.time.dt.year\n",
    "wx_df['month'] = wx_df.time.dt.month\n",
    "wx_df['day'] = wx_df.time.dt.day\n",
    "wx_df['hour'] = wx_df.time.dt.hour\n",
    "wx_df['weekday'] = wx_df.time.dt.weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>timezone</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>temp</th>\n",
       "      <th>feels_like</th>\n",
       "      <th>temp_min</th>\n",
       "      <th>temp_max</th>\n",
       "      <th>pressure</th>\n",
       "      <th>sea_level</th>\n",
       "      <th>...</th>\n",
       "      <th>rain_3h</th>\n",
       "      <th>snow_1h</th>\n",
       "      <th>snow_3h</th>\n",
       "      <th>clouds_all</th>\n",
       "      <th>weather_id</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>weekday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>5.521900e+04</td>\n",
       "      <td>55219.000000</td>\n",
       "      <td>5.521900e+04</td>\n",
       "      <td>5.521900e+04</td>\n",
       "      <td>55219.000000</td>\n",
       "      <td>55219.000000</td>\n",
       "      <td>55219.000000</td>\n",
       "      <td>55219.000000</td>\n",
       "      <td>55219.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>55219.000000</td>\n",
       "      <td>55219.000000</td>\n",
       "      <td>55219.000000</td>\n",
       "      <td>55219.000000</td>\n",
       "      <td>55219.000000</td>\n",
       "      <td>55219.000000</td>\n",
       "      <td>55219.000000</td>\n",
       "      <td>55219.000000</td>\n",
       "      <td>55219.000000</td>\n",
       "      <td>55219.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>1.513951e+09</td>\n",
       "      <td>-19252.525399</td>\n",
       "      <td>4.187811e+01</td>\n",
       "      <td>-8.762980e+01</td>\n",
       "      <td>285.518514</td>\n",
       "      <td>280.257647</td>\n",
       "      <td>281.898104</td>\n",
       "      <td>285.518514</td>\n",
       "      <td>1016.055542</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.047967</td>\n",
       "      <td>0.013533</td>\n",
       "      <td>0.001809</td>\n",
       "      <td>61.031294</td>\n",
       "      <td>750.721907</td>\n",
       "      <td>2017.485087</td>\n",
       "      <td>6.395969</td>\n",
       "      <td>15.782557</td>\n",
       "      <td>11.455894</td>\n",
       "      <td>2.998443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>5.388285e+07</td>\n",
       "      <td>1714.737534</td>\n",
       "      <td>7.105492e-15</td>\n",
       "      <td>4.263295e-14</td>\n",
       "      <td>11.064564</td>\n",
       "      <td>13.182997</td>\n",
       "      <td>10.354815</td>\n",
       "      <td>11.064564</td>\n",
       "      <td>7.584028</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.708266</td>\n",
       "      <td>0.123137</td>\n",
       "      <td>0.066962</td>\n",
       "      <td>32.047140</td>\n",
       "      <td>112.093082</td>\n",
       "      <td>1.695629</td>\n",
       "      <td>3.444176</td>\n",
       "      <td>8.817962</td>\n",
       "      <td>6.908119</td>\n",
       "      <td>1.999746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>1.420070e+09</td>\n",
       "      <td>-21600.000000</td>\n",
       "      <td>4.187811e+01</td>\n",
       "      <td>-8.762980e+01</td>\n",
       "      <td>245.370000</td>\n",
       "      <td>233.180000</td>\n",
       "      <td>242.150000</td>\n",
       "      <td>245.370000</td>\n",
       "      <td>965.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>2015.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>1.467211e+09</td>\n",
       "      <td>-21600.000000</td>\n",
       "      <td>4.187811e+01</td>\n",
       "      <td>-8.762980e+01</td>\n",
       "      <td>276.480000</td>\n",
       "      <td>269.890000</td>\n",
       "      <td>274.150000</td>\n",
       "      <td>276.480000</td>\n",
       "      <td>1011.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>800.000000</td>\n",
       "      <td>2016.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>1.514524e+09</td>\n",
       "      <td>-18000.000000</td>\n",
       "      <td>4.187811e+01</td>\n",
       "      <td>-8.762980e+01</td>\n",
       "      <td>285.193000</td>\n",
       "      <td>279.250000</td>\n",
       "      <td>281.161000</td>\n",
       "      <td>285.193000</td>\n",
       "      <td>1016.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>802.000000</td>\n",
       "      <td>2017.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>1.560530e+09</td>\n",
       "      <td>-18000.000000</td>\n",
       "      <td>4.187811e+01</td>\n",
       "      <td>-8.762980e+01</td>\n",
       "      <td>295.150000</td>\n",
       "      <td>291.900000</td>\n",
       "      <td>290.950000</td>\n",
       "      <td>295.150000</td>\n",
       "      <td>1021.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>803.000000</td>\n",
       "      <td>2019.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>1.606864e+09</td>\n",
       "      <td>-18000.000000</td>\n",
       "      <td>4.187811e+01</td>\n",
       "      <td>-8.762980e+01</td>\n",
       "      <td>311.480000</td>\n",
       "      <td>309.890000</td>\n",
       "      <td>306.132000</td>\n",
       "      <td>311.480000</td>\n",
       "      <td>1044.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>8.400000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>804.000000</td>\n",
       "      <td>2020.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 dt      timezone           lat           lon          temp  \\\n",
       "count  5.521900e+04  55219.000000  5.521900e+04  5.521900e+04  55219.000000   \n",
       "mean   1.513951e+09 -19252.525399  4.187811e+01 -8.762980e+01    285.518514   \n",
       "std    5.388285e+07   1714.737534  7.105492e-15  4.263295e-14     11.064564   \n",
       "min    1.420070e+09 -21600.000000  4.187811e+01 -8.762980e+01    245.370000   \n",
       "25%    1.467211e+09 -21600.000000  4.187811e+01 -8.762980e+01    276.480000   \n",
       "50%    1.514524e+09 -18000.000000  4.187811e+01 -8.762980e+01    285.193000   \n",
       "75%    1.560530e+09 -18000.000000  4.187811e+01 -8.762980e+01    295.150000   \n",
       "max    1.606864e+09 -18000.000000  4.187811e+01 -8.762980e+01    311.480000   \n",
       "\n",
       "         feels_like      temp_min      temp_max      pressure  sea_level  ...  \\\n",
       "count  55219.000000  55219.000000  55219.000000  55219.000000        0.0  ...   \n",
       "mean     280.257647    281.898104    285.518514   1016.055542        NaN  ...   \n",
       "std       13.182997     10.354815     11.064564      7.584028        NaN  ...   \n",
       "min      233.180000    242.150000    245.370000    965.000000        NaN  ...   \n",
       "25%      269.890000    274.150000    276.480000   1011.000000        NaN  ...   \n",
       "50%      279.250000    281.161000    285.193000   1016.000000        NaN  ...   \n",
       "75%      291.900000    290.950000    295.150000   1021.000000        NaN  ...   \n",
       "max      309.890000    306.132000    311.480000   1044.000000        NaN  ...   \n",
       "\n",
       "            rain_3h       snow_1h       snow_3h    clouds_all    weather_id  \\\n",
       "count  55219.000000  55219.000000  55219.000000  55219.000000  55219.000000   \n",
       "mean       0.047967      0.013533      0.001809     61.031294    750.721907   \n",
       "std        0.708266      0.123137      0.066962     32.047140    112.093082   \n",
       "min        0.000000      0.000000      0.000000      0.000000    200.000000   \n",
       "25%        0.000000      0.000000      0.000000     40.000000    800.000000   \n",
       "50%        0.000000      0.000000      0.000000     75.000000    802.000000   \n",
       "75%        0.000000      0.000000      0.000000     90.000000    803.000000   \n",
       "max       35.000000      8.400000      6.000000    100.000000    804.000000   \n",
       "\n",
       "               year         month           day          hour       weekday  \n",
       "count  55219.000000  55219.000000  55219.000000  55219.000000  55219.000000  \n",
       "mean    2017.485087      6.395969     15.782557     11.455894      2.998443  \n",
       "std        1.695629      3.444176      8.817962      6.908119      1.999746  \n",
       "min     2015.000000      1.000000      1.000000      0.000000      0.000000  \n",
       "25%     2016.000000      3.000000      8.000000      5.000000      1.000000  \n",
       "50%     2017.000000      6.000000     16.000000     11.000000      3.000000  \n",
       "75%     2019.000000      9.000000     23.000000     17.000000      5.000000  \n",
       "max     2020.000000     12.000000     31.000000     23.000000      6.000000  \n",
       "\n",
       "[8 rows x 25 columns]"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wx_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    wx_df = wx_df.drop(columns=['dt', \n",
    "                        'dt_iso', \n",
    "                        'timezone', \n",
    "                        'city_name', \n",
    "                        'lat', \n",
    "                        'lon', \n",
    "                        'feels_like', \n",
    "                        'temp_min', \n",
    "                        'temp_max',\n",
    "                        'pressure',\n",
    "                        'sea_level',\n",
    "                        'grnd_level',\n",
    "                        'humidity',\n",
    "                        'wind_speed',\n",
    "                        'wind_deg',\n",
    "                        'clouds_all',\n",
    "                        'weather_description',\n",
    "                        'weather_icon',\n",
    "                        'weather_id',\n",
    "                        'weather_main',\n",
    "                       ], axis=1)\n",
    "except:\n",
    "    print('Failed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55219\n",
      "3331\n",
      "Total hours in 6 years: 52596.0\n",
      "Unique entries: 51888\n",
      "\n",
      "2015-01-01 00:00:00+00:00 2020-12-01 23:00:00+00:00\n",
      "Total hours in 6 years (-1 mos): 51852.0\n"
     ]
    }
   ],
   "source": [
    "print(len(wx_df))\n",
    "print(wx_df.duplicated().sum())\n",
    "\n",
    "\n",
    "print('Total hours in 6 years:', 365.25 * 24 * 6)\n",
    "print('Unique entries:', len(wx_df.drop_duplicates()))  \n",
    "# missing a few entries (700+ out of 52k)  Am I missing a month??\n",
    "\n",
    "print()\n",
    "print(wx_df.time.min(), wx_df.time.max())  # OH!!!!  I am missin last month\n",
    "print('Total hours in 6 years (-1 mos):', 365.25 * 24 * 6 - 31 * 24)  # okay, we are only missing a few\n",
    "\n",
    "\n",
    "wx_df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('region_data',), ('cam_locations',), ('cam_startend',), ('daily_violations',), ('intersction_locations',), ('intersection_cams',), ('all_crashes',), ('signal_crashes',), ('hourly_congestion',), ('hourly_weather',)]\n"
     ]
    }
   ],
   "source": [
    "make_table(wx_df, 'hourly_weather', c, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8) Create TABLE region_data from region_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THis time we only grab what we need\n",
    "\n",
    "region_df = client.get(\"kf7e-cur8\", # regional congestion current data\n",
    "                         select='region_id, region, description, north, south, east, west',\n",
    "                         limit=1000\n",
    "                    )\n",
    "\n",
    "# Convert to pandas DataFrame\n",
    "region_df = pd.DataFrame.from_records(region_df)  # should only return most recent for each region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_df = region_df.groupby('region_id').max().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 29 entries, 0 to 28\n",
      "Data columns (total 7 columns):\n",
      "region_id      29 non-null object\n",
      "region         29 non-null object\n",
      "description    29 non-null object\n",
      "north          29 non-null float64\n",
      "south          29 non-null float64\n",
      "east           29 non-null float64\n",
      "west           29 non-null float64\n",
      "dtypes: float64(4), object(3)\n",
      "memory usage: 1.7+ KB\n"
     ]
    }
   ],
   "source": [
    "# need these as floats so we can compare them\n",
    "region_df[['north', 'south', 'east', 'west']] = region_df[['north', 'south', 'east', 'west']].astype(float)\n",
    "region_df.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add region to my crash df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 60333 entries, 3 to 466341\n",
      "Data columns (total 51 columns):\n",
      "crash_record_id                  60333 non-null object\n",
      "rd_no                            60333 non-null object\n",
      "crash_date                       60333 non-null datetime64[ns]\n",
      "posted_speed_limit               60333 non-null object\n",
      "traffic_control_device           60333 non-null object\n",
      "device_condition                 60333 non-null object\n",
      "weather_condition                60333 non-null object\n",
      "lighting_condition               60333 non-null object\n",
      "first_crash_type                 60333 non-null object\n",
      "trafficway_type                  60333 non-null object\n",
      "alignment                        60333 non-null object\n",
      "roadway_surface_cond             60333 non-null object\n",
      "road_defect                      60333 non-null object\n",
      "report_type                      58549 non-null object\n",
      "crash_type                       60333 non-null object\n",
      "hit_and_run_i                    11420 non-null object\n",
      "damage                           60333 non-null object\n",
      "prim_contributory_cause          60333 non-null object\n",
      "sec_contributory_cause           60333 non-null object\n",
      "street_no                        60333 non-null object\n",
      "street_direction                 60333 non-null object\n",
      "street_name                      60333 non-null object\n",
      "beat_of_occurrence               60333 non-null object\n",
      "num_units                        60333 non-null object\n",
      "most_severe_injury               60317 non-null object\n",
      "injuries_total                   60317 non-null object\n",
      "injuries_fatal                   60317 non-null object\n",
      "injuries_incapacitating          60317 non-null object\n",
      "injuries_non_incapacitating      60317 non-null object\n",
      "injuries_reported_not_evident    60317 non-null object\n",
      "injuries_no_indication           60317 non-null object\n",
      "injuries_unknown                 60317 non-null object\n",
      "crash_hour                       60333 non-null object\n",
      "crash_day_of_week                60333 non-null object\n",
      "crash_month                      60333 non-null object\n",
      "latitude                         60333 non-null float64\n",
      "longitude                        60333 non-null float64\n",
      "lane_cnt                         27069 non-null object\n",
      "intersection_related_i           60333 non-null object\n",
      "crash_date_est_i                 2676 non-null object\n",
      "work_zone_i                      464 non-null object\n",
      "work_zone_type                   361 non-null object\n",
      "workers_present_i                97 non-null object\n",
      "intersection                     7777 non-null object\n",
      "year                             60333 non-null int64\n",
      "month                            60333 non-null int64\n",
      "day                              60333 non-null int64\n",
      "hour                             60333 non-null int64\n",
      "region_id                        0 non-null float64\n",
      "time                             60333 non-null datetime64[ns]\n",
      "weekday                          60333 non-null int64\n",
      "dtypes: datetime64[ns](2), float64(3), int64(5), object(41)\n",
      "memory usage: 23.9+ MB\n"
     ]
    }
   ],
   "source": [
    "crash_df[['latitude', 'longitude']] = crash_df[['latitude', 'longitude']].astype(float)\n",
    "crash_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add in the region for my crashes\n",
    "# Resource hog\n",
    "crash_df.columns\n",
    "\n",
    "\n",
    "def which_region(lat, long, region_df):\n",
    "    #print(lat, long)\n",
    "    row = region_df[(region_df['east'] >= long) &\n",
    "                    (region_df['west'] < long) &\n",
    "                    (region_df['north'] >= lat) &\n",
    "                    (region_df['south'] < lat)]['region_id'].max()\n",
    "    return row\n",
    "\n",
    "#df.iloc[:5]\n",
    "# takes some 5min\n",
    "crash_df['region_id'] = crash_df.apply(lambda x: which_region(x.latitude, x.longitude, region_df), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(crash_df)\n",
    "crash_df.columns\n",
    "\n",
    "crash_df['time'] = pd.to_datetime(crash_df.crash_date)\n",
    "crash_df['year'] = crash_df.time.dt.year\n",
    "crash_df['month'] = crash_df.time.dt.month\n",
    "crash_df['day'] = crash_df.time.dt.day\n",
    "crash_df['hour'] = crash_df.time.dt.hour\n",
    "crash_df['weekday'] = crash_df.time.dt.weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('cam_locations',), ('cam_startend',), ('daily_violations',), ('intersction_locations',), ('intersection_cams',), ('all_crashes',), ('hourly_congestion',), ('hourly_weather',), ('signal_crashes',), ('region_data',)]\n",
      "\n",
      "[('cam_locations',), ('cam_startend',), ('daily_violations',), ('intersction_locations',), ('intersection_cams',), ('all_crashes',), ('hourly_congestion',), ('hourly_weather',), ('region_data',), ('signal_crashes',)]\n"
     ]
    }
   ],
   "source": [
    "make_table(region_df, 'region_data', c, conn)\n",
    "print()\n",
    "make_table(crash_df, 'signal_crashes', c, conn)  # also update my crash data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add region_id to intersection_cams\n",
    "While I'm here and I have the function ready.\n",
    "I would like to add region_id number to my red light camera (daily_violations TABLE)\n",
    "The region there will help me link the daily_violations and hourly_congestion TABLEs\n",
    "\n",
    "*** NOTE: Makes more sense to come back and put the region into the intersection_cameras table to speed this up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10 minutes\n",
    "#rlc['region_id'] = \n",
    "int_cams['region_id'] = int_cams.apply(lambda x: which_region(x.latitude, x.longitude, region_df), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('cam_locations',), ('cam_startend',), ('daily_violations',), ('intersction_locations',), ('all_crashes',), ('hourly_congestion',), ('hourly_weather',), ('region_data',), ('signal_crashes',), ('intersection_cams',)]\n"
     ]
    }
   ],
   "source": [
    "## commit my change\n",
    "make_table(int_cams, 'intersection_cams', c, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use this code to test any of your tables for proper data storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('2121', 19), ('1533', 2), ('1503', 2), ('2764', 3), ('1234', 1)]\n",
      "572323\n"
     ]
    }
   ],
   "source": [
    "query = c.execute(\"SELECT camera_id, violations FROM daily_violations;\").fetchall()\n",
    "print(query[:5])\n",
    "print(len(query))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before I go, I want to add intersections to my crashes to link the db tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cam_locations',),\n",
       " ('cam_startend',),\n",
       " ('daily_violations',),\n",
       " ('intersction_locations',),\n",
       " ('all_crashes',),\n",
       " ('hourly_congestion',),\n",
       " ('hourly_weather',),\n",
       " ('region_data',),\n",
       " ('signal_crashes',),\n",
       " ('intersection_cams',)]"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql_fetch_tables(c, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_sql_query(\"SELECT * FROM signal_crashes\", conn)\n",
    "camloc_df = pd.read_sql_query('SELECT * FROM cam_locations', conn)\n",
    "ints_df = pd.read_sql_query('SELECT * FROM intersection_cams', conn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ints_df.astype({'longitude':float})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "WESTERN AND 79TH\n",
      "None\n",
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Now I am desperate.  This takes too long to process.  Let's simplify it and make it a box instead.\n",
    "box_side = 50  # effectively makes it check for crash being within 25m of interscection\n",
    "box_lat = box_side / 111070 / 2 # 111070 is meters in deg lat in Chicago\n",
    "box_long = box_side / 83000 / 2 # 83000 is meters in deg long in Chicago\n",
    "\n",
    "def box_check(lat, long, ints_df):\n",
    "    answer = (ints_df[  (ints_df['latitude'] > (lat - box_lat)) & \n",
    "                      (ints_df['latitude'] < (lat + box_lat)) &\n",
    "                      (ints_df['longitude'] > (long - box_long)) &\n",
    "                      (ints_df['longitude'] < (long + box_long))\n",
    "                     ])\n",
    "    if answer.empty: return None\n",
    "    return answer['intersection'].values[0]\n",
    "    \n",
    "# THIS SEEMS TO WORK WITH SPEED AND ELIMINATES MEMORY PROBLEM\n",
    "for i in range(5): #(len(df)):\n",
    "    intersect = box_check(float(df.iloc[i]['latitude']), float(df.iloc[i]['longitude']), ints_df)\n",
    "    print(intersect)\n",
    "    \n",
    "    \n",
    "# MOMENT OF TRUTH\n",
    "#df['intersection'] = df.apply(lambda x: box_check(float(x.latitude), float(x.longitude), camloc_df), axis=1)\n",
    "\n",
    "df['intersection'] = df.apply(lambda x: box_check(float(x.latitude), float(x.longitude), ints_df), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('cam_locations',), ('cam_startend',), ('daily_violations',), ('intersction_locations',), ('all_crashes',), ('hourly_congestion',), ('hourly_weather',), ('region_data',), ('intersection_cams',), ('signal_crashes',)]\n"
     ]
    }
   ],
   "source": [
    "make_table(df, 'signal_crashes', c, conn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['crash_record_id', 'rd_no', 'crash_date', 'posted_speed_limit',\n",
       "       'traffic_control_device', 'device_condition', 'weather_condition',\n",
       "       'lighting_condition', 'first_crash_type', 'trafficway_type',\n",
       "       'alignment', 'roadway_surface_cond', 'road_defect', 'report_type',\n",
       "       'crash_type', 'hit_and_run_i', 'damage', 'prim_contributory_cause',\n",
       "       'sec_contributory_cause', 'street_no', 'street_direction',\n",
       "       'street_name', 'beat_of_occurrence', 'num_units', 'most_severe_injury',\n",
       "       'injuries_total', 'injuries_fatal', 'injuries_incapacitating',\n",
       "       'injuries_non_incapacitating', 'injuries_reported_not_evident',\n",
       "       'injuries_no_indication', 'injuries_unknown', 'crash_hour',\n",
       "       'crash_day_of_week', 'crash_month', 'latitude', 'longitude', 'lane_cnt',\n",
       "       'intersection_related_i', 'crash_date_est_i', 'work_zone_i',\n",
       "       'work_zone_type', 'workers_present_i', 'intersection', 'year', 'month',\n",
       "       'day', 'hour', 'region_id', 'time', 'weekday'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
