{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a SQL database\n",
    "This notebook builds the necessary db files for the project using SQLite3.\n",
    "\n",
    "Most data is taken from Chicago Data Portal https://data.cityofchicago.org/ using Socrata library.\n",
    "The API endpoints for the data are:\n",
    "- Red Light Violations: https://data.cityofchicago.org/resource/spqx-js37.json\n",
    "- Congestion by Region 2018-Present: https://data.cityofchicago.org/resource/kf7e-cur8.json\n",
    "- Congestion by Region 2013-2018: https://data.cityofchicago.org/resource/emtn-qqdi.json\n",
    "- Traffic Crashes: https://data.cityofchicago.org/resource/85ca-t3if.json\n",
    "\n",
    "Weather data is taken from https://openweathermap.org/weather-data and is saved as csv in data folder\n",
    "\n",
    "Tables to build:\n",
    "- daily_violations (one entry for each camera each day with total violations)\n",
    "- intersection_locations (one entry for each intersection with lat/long)\n",
    "- intersection_cams (one entry for each intersection with camera_ids)\n",
    "- signal_crashes (one entry for each intersection crash with many columns)\n",
    "- cam_locations (one entry for each cam, with lat/long)\n",
    "- cam_startend (one entry for each cam with start end dates for min/max dates active)\n",
    "- hourly_congestion (one entry per hour with bus speed averages for each region)\n",
    "- hourly_weather (one entry per hour with many weather cols)\n",
    "- region_data (one entry per region with locations and descriptions to place intersections)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Required Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install \"dask[complete]\"\n",
    "# from dask.distributed import Client, progress\n",
    "# client = Client(n_workers=2, threads_per_worker=2, memory_limit='1GB')\n",
    "# client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sodapy import Socrata\n",
    "#import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from modules.myfuncs import *\n",
    "import warnings\n",
    "import numpy as np\n",
    "from geopy.geocoders import Nominatim\n",
    "# import dask\n",
    "# import dask.dataframe as dd\n",
    "import gc\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create/connect to db and build the TABLEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sqlite3 version: 2.6.0\n",
      "connected to database/rlc2.db\n"
     ]
    }
   ],
   "source": [
    "# Create a db\n",
    "conn = create_connection('database/rlc2.db')  # function I created in myfuncs file\n",
    "c = conn.cursor()\n",
    "#conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the Socrata client\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Requests made without an app_token will be subject to strict throttling limits.\n"
     ]
    }
   ],
   "source": [
    "# Unauthenticated client only works with public data sets. Note 'None'\n",
    "# in place of application token, and no username or password:\n",
    "\n",
    "url = \"data.cityofchicago.org\"\n",
    "client = Socrata(url, None)\n",
    "\n",
    "# Example authenticated client (needed for non-public datasets):\n",
    "# client = Socrata(data.cityofchicago.org,\n",
    "#                  MyAppToken,\n",
    "#                  userame=\"user@example.com\",\n",
    "#                  password=\"AFakePassword\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TABLE builds\n",
    "\n",
    "For every TABLE\n",
    "- Use a Socrata client query to get all relevant data\n",
    "- Preprocess data as needed\n",
    "- Create Table\n",
    "\n",
    "Our data\n",
    "- rlc_cam is up to 1M redlight cams from 2015 to 2020\n",
    "- crash_data is up to 1M crashes from 2015 to 2020\n",
    "- traffic_data is up to 10M from 2015 to 2020\n",
    "\n",
    "Weather data is taken from csv in data folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Build intersection_chars TABLE from int_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "roads              0\n",
       "protected_turn     0\n",
       "total_lanes        0\n",
       "medians            0\n",
       "exit               0\n",
       "split              0\n",
       "way                0\n",
       "underpass          0\n",
       "no_left            0\n",
       "angled             0\n",
       "triangle           0\n",
       "one_way           45\n",
       "turn_lanes        83\n",
       "lat               83\n",
       "long              83\n",
       "rlc               83\n",
       "intersection       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from modules.int_chars import *\n",
    "import pandas as pd\n",
    "\n",
    "int_chars.keys()\n",
    "int_df = pd.DataFrame.from_dict(int_chars, orient='index')\n",
    "int_df['intersection'] = int_chars.keys()\n",
    "int_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['roads', 'protected_turn', 'total_lanes', 'medians', 'exit', 'split',\n",
       "       'way', 'underpass', 'no_left', 'angled', 'triangle', 'one_way',\n",
       "       'turn_lanes', 'lat', 'long', 'rlc'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_df = int_df[int_df['rlc']==1]\n",
    "int_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 100 entries, 111TH AND HALSTED to WESTERN AND TOUHY\n",
      "Data columns (total 16 columns):\n",
      "roads             100 non-null object\n",
      "protected_turn    100 non-null int64\n",
      "total_lanes       100 non-null int64\n",
      "medians           100 non-null int64\n",
      "exit              100 non-null int64\n",
      "split             100 non-null int64\n",
      "way               100 non-null int64\n",
      "underpass         100 non-null int64\n",
      "no_left           100 non-null int64\n",
      "angled            100 non-null int64\n",
      "triangle          100 non-null int64\n",
      "one_way           100 non-null int64\n",
      "turn_lanes        100 non-null int64\n",
      "lat               100 non-null float64\n",
      "long              100 non-null float64\n",
      "rlc               100 non-null int64\n",
      "dtypes: float64(2), int64(13), object(1)\n",
      "memory usage: 13.3+ KB\n"
     ]
    }
   ],
   "source": [
    "cols_toint = ['protected_turn', 'total_lanes', 'medians', 'exit', 'split',\n",
    "       'way', 'underpass', 'no_left', 'angled', 'triangle', 'one_way',\n",
    "       'turn_lanes', 'rlc']\n",
    "cols_tofloat = ['lat', 'long',]\n",
    "\n",
    "int_df[cols_toint] = int_df[cols_toint].astype(int)\n",
    "int_df[cols_tofloat] = int_df[cols_tofloat].astype(float)\n",
    "int_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now bring in my count information "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "daily_traffic = client.get(\"pfsx-4n4m\", \n",
    "                     limit=2000,\n",
    "                    )\n",
    "\n",
    "daily_traffic = pd.DataFrame.from_records(daily_traffic) # Convert to pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1279 entries, 0 to 1278\n",
      "Data columns (total 15 columns):\n",
      "id                                             1279 non-null object\n",
      "traffic_volume_count_location_address          1279 non-null object\n",
      "street                                         1279 non-null object\n",
      "date_of_count                                  1279 non-null object\n",
      "total_passing_vehicle_volume                   1279 non-null object\n",
      "vehicle_volume_by_each_direction_of_traffic    1279 non-null object\n",
      "latitude                                       1279 non-null object\n",
      "longitude                                      1279 non-null object\n",
      "location                                       1279 non-null object\n",
      ":@computed_region_rpca_8um6                    1266 non-null object\n",
      ":@computed_region_vrxf_vc4k                    1266 non-null object\n",
      ":@computed_region_6mkv_f3dw                    1279 non-null object\n",
      ":@computed_region_bdys_3d7i                    1265 non-null object\n",
      ":@computed_region_43wa_7qmu                    1266 non-null object\n",
      ":@computed_region_awaf_s7ux                    1266 non-null object\n",
      "dtypes: object(15)\n",
      "memory usage: 150.0+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>traffic_volume_count_location_address</th>\n",
       "      <th>total_passing_vehicle_volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5838 West</td>\n",
       "      <td>7100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>320 East</td>\n",
       "      <td>8600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1730 East</td>\n",
       "      <td>53500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>125 East</td>\n",
       "      <td>700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2924 East</td>\n",
       "      <td>4200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  traffic_volume_count_location_address total_passing_vehicle_volume\n",
       "0                             5838 West                         7100\n",
       "1                              320 East                         8600\n",
       "2                             1730 East                        53500\n",
       "3                              125 East                          700\n",
       "4                             2924 East                         4200"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_traffic.info()\n",
    "cols_tokeep = ['traffic_volume_count_location_address', 'total_passing_vehicle_volume',]\n",
    "daily_traffic = daily_traffic[cols_tokeep]\n",
    "daily_traffic.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_traffic.total_passing_vehicle_volume = daily_traffic.total_passing_vehicle_volume.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine my characteristics with my daily_traffic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#int_chars.merge(daily_traffic, left_on='intersection', right_on='rkey')\n",
    "def look_up_roads(road_list):\n",
    "    total = 0\n",
    "    #print(road_list)\n",
    "    for road in road_list:\n",
    "        count = daily_traffic[daily_traffic['traffic_volume_count_location_address']==road]['total_passing_vehicle_volume'].sum()\n",
    "        total += count\n",
    "        #print(count)\n",
    "    return total\n",
    "\n",
    "int_df['daily_traffic'] = int_df['roads'].apply(look_up_roads)\n",
    "int_df.drop(columns=['roads'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>protected_turn</th>\n",
       "      <th>total_lanes</th>\n",
       "      <th>medians</th>\n",
       "      <th>exit</th>\n",
       "      <th>split</th>\n",
       "      <th>way</th>\n",
       "      <th>underpass</th>\n",
       "      <th>no_left</th>\n",
       "      <th>angled</th>\n",
       "      <th>triangle</th>\n",
       "      <th>one_way</th>\n",
       "      <th>turn_lanes</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>rlc</th>\n",
       "      <th>daily_traffic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>111TH AND HALSTED</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>41.692362</td>\n",
       "      <td>-87.642423</td>\n",
       "      <td>1</td>\n",
       "      <td>43100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>115TH AND HALSTED</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>41.685089</td>\n",
       "      <td>-87.642094</td>\n",
       "      <td>1</td>\n",
       "      <td>42500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>119TH AND HALSTED</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>41.677774</td>\n",
       "      <td>-87.641930</td>\n",
       "      <td>1</td>\n",
       "      <td>41800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31ST AND CALIFORNIA</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>41.837424</td>\n",
       "      <td>-87.695022</td>\n",
       "      <td>1</td>\n",
       "      <td>43100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31ST ST AND MARTIN LUTHER KING DRIVE</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>41.838441</td>\n",
       "      <td>-87.617338</td>\n",
       "      <td>1</td>\n",
       "      <td>46100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>WESTERN AND FULLERTON</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>41.924928</td>\n",
       "      <td>-87.687626</td>\n",
       "      <td>1</td>\n",
       "      <td>69600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>WESTERN AND MARQUETTE</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>41.771987</td>\n",
       "      <td>-87.683404</td>\n",
       "      <td>1</td>\n",
       "      <td>54000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>WESTERN AND NORTH</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>41.910318</td>\n",
       "      <td>-87.687195</td>\n",
       "      <td>1</td>\n",
       "      <td>73300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>WESTERN AND PRATT</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>42.005026</td>\n",
       "      <td>-87.690118</td>\n",
       "      <td>1</td>\n",
       "      <td>54100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>WESTERN AND TOUHY</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>42.012234</td>\n",
       "      <td>-87.690206</td>\n",
       "      <td>1</td>\n",
       "      <td>42200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      protected_turn  total_lanes  medians  \\\n",
       "111TH AND HALSTED                                  2            6        2   \n",
       "115TH AND HALSTED                                  4            6        2   \n",
       "119TH AND HALSTED                                  4            6        2   \n",
       "31ST AND CALIFORNIA                                2            6        0   \n",
       "31ST ST AND MARTIN LUTHER KING DRIVE               2           10        2   \n",
       "...                                              ...          ...      ...   \n",
       "WESTERN AND FULLERTON                              2            8        0   \n",
       "WESTERN AND MARQUETTE                              0            6        0   \n",
       "WESTERN AND NORTH                                  4            8        0   \n",
       "WESTERN AND PRATT                                  2            6        0   \n",
       "WESTERN AND TOUHY                                  4            6        0   \n",
       "\n",
       "                                      exit  split  way  underpass  no_left  \\\n",
       "111TH AND HALSTED                        0      0    4          0        0   \n",
       "115TH AND HALSTED                        0      0    4          0        0   \n",
       "119TH AND HALSTED                        0      0    4          0        0   \n",
       "31ST AND CALIFORNIA                      0      0    4          0        0   \n",
       "31ST ST AND MARTIN LUTHER KING DRIVE     0      1    4          0        2   \n",
       "...                                    ...    ...  ...        ...      ...   \n",
       "WESTERN AND FULLERTON                    0      0    4          0        0   \n",
       "WESTERN AND MARQUETTE                    0      0    4          0        0   \n",
       "WESTERN AND NORTH                        0      0    4          0        0   \n",
       "WESTERN AND PRATT                        0      0    4          0        0   \n",
       "WESTERN AND TOUHY                        0      0    4          0        0   \n",
       "\n",
       "                                      angled  triangle  one_way  turn_lanes  \\\n",
       "111TH AND HALSTED                          1         0        0           2   \n",
       "115TH AND HALSTED                          0         0        0           4   \n",
       "119TH AND HALSTED                          0         0        0           4   \n",
       "31ST AND CALIFORNIA                        0         0        0           4   \n",
       "31ST ST AND MARTIN LUTHER KING DRIVE       0         0        0           0   \n",
       "...                                      ...       ...      ...         ...   \n",
       "WESTERN AND FULLERTON                      0         0        0           4   \n",
       "WESTERN AND MARQUETTE                      0         0        0           4   \n",
       "WESTERN AND NORTH                          0         0        0           4   \n",
       "WESTERN AND PRATT                          0         0        0           4   \n",
       "WESTERN AND TOUHY                          0         0        0           4   \n",
       "\n",
       "                                            lat       long  rlc  daily_traffic  \n",
       "111TH AND HALSTED                     41.692362 -87.642423    1          43100  \n",
       "115TH AND HALSTED                     41.685089 -87.642094    1          42500  \n",
       "119TH AND HALSTED                     41.677774 -87.641930    1          41800  \n",
       "31ST AND CALIFORNIA                   41.837424 -87.695022    1          43100  \n",
       "31ST ST AND MARTIN LUTHER KING DRIVE  41.838441 -87.617338    1          46100  \n",
       "...                                         ...        ...  ...            ...  \n",
       "WESTERN AND FULLERTON                 41.924928 -87.687626    1          69600  \n",
       "WESTERN AND MARQUETTE                 41.771987 -87.683404    1          54000  \n",
       "WESTERN AND NORTH                     41.910318 -87.687195    1          73300  \n",
       "WESTERN AND PRATT                     42.005026 -87.690118    1          54100  \n",
       "WESTERN AND TOUHY                     42.012234 -87.690206    1          42200  \n",
       "\n",
       "[100 rows x 16 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "int_df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def make_table(df, table_name, c, conn):\n",
    "    '''\n",
    "    table_name string\n",
    "    c cursor object\n",
    "    conn sql connection object\n",
    "    '''\n",
    "    if table_name in sql_fetch_tables(c, conn):  # helper function in myfuncs\n",
    "        delete_all_entries(c, conn, table_name) # in myfuncs\n",
    "    \n",
    "    df.to_sql(table_name, conn, if_exists='replace', index = False)    \n",
    "    print(sql_fetch_tables(c, conn))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('hourly_congestion',), ('hourly_weather',), ('region_data',), ('int_chars',), ('intersection_counts',), ('cam_locations',), ('cam_startend',), ('daily_violations',), ('intersction_locations',), ('intersection_cams',), ('all_crashes',), ('signal_crashes',), ('intersection_chars',)]\n"
     ]
    }
   ],
   "source": [
    "make_table(int_df, 'intersection_chars', c, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Build daily_violations TABLE  from rlc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get red light violation data from Socrata query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Red light violations\n",
    "# Takes several minutes to run and holds about 500mb in memory to build\n",
    "\n",
    "# First 1000000 results, returned as JSON from API / converted to Python list of dictionaries by sodapy\n",
    "rlc_df = client.get(\"spqx-js37\", #speed cams are at 'hhkd-xvj4' if you want to investigate?\n",
    "                     #where='violation_date > 01-01-2020',\n",
    "                     where='violation_date BETWEEN \\'2015-01-01T00:00:00.000\\' AND \\'2020-12-31T00:00:00.000\\'',\n",
    "                     limit=1000000,\n",
    "                    )\n",
    "\n",
    "rlc_df = pd.DataFrame.from_records(rlc_df) # Convert to pandas DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Red Light Camera Data\n",
    "\n",
    "Data Columns of interest:\n",
    "\n",
    "INTERSECTION -\n",
    "Intersection of the location of the red light enforcement camera(s). There may be more than one camera at each intersection. Plain Text\n",
    "\n",
    "CAMERA ID -\n",
    "A unique ID for each physical camera at an intersection, which may contain more than one camera. Plain Text\n",
    "\n",
    "ADDRESS\t-\n",
    "The address of the physical camera (CAMERA ID). The address may be the same for all cameras or different, based on the physical installation of each camera. Plain Text\n",
    "\n",
    "VIOLATION DATE -\n",
    "The date of when the violations occurred. NOTE: The citation may be issued on a different date. Date & Time\n",
    "\n",
    "VIOLATIONS - \n",
    "Number of violations for each camera on a particular day. Number\n",
    "\n",
    "LATITUDE -\n",
    "The latitude of the physical location of the camera(s) based on the ADDRESS column. Geocoded using the WGS84. Number\n",
    "\n",
    "LONGITUDE -\n",
    "The longitude of the physical location of the camera(s) based on the ADDRESS column. Geocoded using the WGS84.\n",
    "Number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Investigate rlc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 572559 entries, 0 to 572558\n",
      "Data columns (total 10 columns):\n",
      "intersection      572559 non-null object\n",
      "camera_id         572325 non-null object\n",
      "address           572559 non-null object\n",
      "violation_date    572559 non-null object\n",
      "violations        572559 non-null object\n",
      "x_coordinate      542736 non-null object\n",
      "y_coordinate      542736 non-null object\n",
      "latitude          542736 non-null object\n",
      "longitude         542736 non-null object\n",
      "location          542736 non-null object\n",
      "dtypes: object(10)\n",
      "memory usage: 43.7+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "intersection          0\n",
       "camera_id           234\n",
       "address               0\n",
       "violation_date        0\n",
       "violations            0\n",
       "x_coordinate      29823\n",
       "y_coordinate      29823\n",
       "latitude          29823\n",
       "longitude         29823\n",
       "location          29823\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rlc_df.info()\n",
    "rlc_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop nan values and unnecessary columns\n",
    "We see that we have all text/non-null objects.  Need to convert first before manipulating for preprocess.\n",
    "\n",
    "There are a fair number of missing locations/lat/long.  Hope to be able to replace those missing values.\n",
    "This represents a large enough portion of dataset that we should look them up.\n",
    "\n",
    "The na values for camera_id will have to be dropped, since we don't know what they are.\n",
    "\n",
    "We will not be using x andy y_coordinate, so we drop those.  We will also drop location.  We already have lat long in other columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "intersection          0\n",
       "camera_id             0\n",
       "address               0\n",
       "violation_date        0\n",
       "violations            0\n",
       "latitude          29809\n",
       "longitude         29809\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#client_df.dropna(subset=['camera_id']).isna().sum()\n",
    "try:\n",
    "    # put this is a try in case we run it twice, it will skip it.\n",
    "    rlc_df.dropna(subset=['camera_id'], inplace=True)\n",
    "    \n",
    "    # drop xy coord and location columns\n",
    "    rlc_df = rlc_df.drop(columns=['x_coordinate', 'y_coordinate', 'location'], index=1)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "\n",
    "\n",
    "rlc_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Manipulate datatypes for preprocessing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intersection</th>\n",
       "      <th>camera_id</th>\n",
       "      <th>address</th>\n",
       "      <th>violation_date</th>\n",
       "      <th>violations</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>weekday</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>31ST ST AND MARTIN LUTHER KING DRIVE</td>\n",
       "      <td>2121</td>\n",
       "      <td>3100 S DR MARTIN L KING</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>IRVING PARK AND LARAMIE</td>\n",
       "      <td>1533</td>\n",
       "      <td>5200 W IRVING PARK ROA</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>ELSTON AND IRVING PARK</td>\n",
       "      <td>1503</td>\n",
       "      <td>3700 W IRVING PARK ROA</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>IRVING PARK AND KILPATRICK</td>\n",
       "      <td>2764</td>\n",
       "      <td>4700 W IRVING PARK ROA</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>IRVING PARK AND CALIFORNIA</td>\n",
       "      <td>1234</td>\n",
       "      <td>2800 W IRVING PARK ROA</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           intersection camera_id                  address  \\\n",
       "0  31ST ST AND MARTIN LUTHER KING DRIVE      2121  3100 S DR MARTIN L KING   \n",
       "2               IRVING PARK AND LARAMIE      1533   5200 W IRVING PARK ROA   \n",
       "3                ELSTON AND IRVING PARK      1503   3700 W IRVING PARK ROA   \n",
       "4            IRVING PARK AND KILPATRICK      2764   4700 W IRVING PARK ROA   \n",
       "5            IRVING PARK AND CALIFORNIA      1234   2800 W IRVING PARK ROA   \n",
       "\n",
       "  violation_date  violations  latitude  longitude  month  day  weekday  year  \n",
       "0     2015-01-01          19       NaN        NaN      1    1        3  2015  \n",
       "2     2015-01-01           2       NaN        NaN      1    1        3  2015  \n",
       "3     2015-01-01           2       NaN        NaN      1    1        3  2015  \n",
       "4     2015-01-01           3       NaN        NaN      1    1        3  2015  \n",
       "5     2015-01-01           1       NaN        NaN      1    1        3  2015  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rlc_df['violations'] = rlc_df['violations'].apply(int)\n",
    "rlc_df['latitude'] = rlc_df['latitude'].apply(float)\n",
    "rlc_df['longitude'] = rlc_df['longitude'].apply(float)\n",
    "rlc_df['violation_date'] = pd.to_datetime(rlc_df['violation_date'])\n",
    "rlc_df['month'] = rlc_df['violation_date'].apply(lambda x: int(x.month))\n",
    "rlc_df['day'] = rlc_df['violation_date'].apply(lambda x: int(x.day))  # fixed from dat to day!\n",
    "\n",
    "rlc_df['weekday'] = rlc_df['violation_date'].apply(lambda x: int(datetime.weekday(x)))\n",
    "rlc_df['year'] = rlc_df['violation_date'].apply(lambda x: int(x.year))\n",
    "\n",
    "rlc_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write the daily_violations TABLE - from rlc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def make_table(df, table_name, c, conn):\n",
    "    '''\n",
    "    table_name string\n",
    "    c cursor object\n",
    "    conn sql connection object\n",
    "    '''\n",
    "    if table_name in sql_fetch_tables(c, conn):  # helper function in myfuncs\n",
    "        delete_all_entries(c, conn, table_name) # in myfuncs\n",
    "    \n",
    "    df.to_sql(table_name, conn, if_exists='replace', index = False)    \n",
    "    print(sql_fetch_tables(c, conn))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('hourly_congestion',), ('hourly_weather',), ('region_data',), ('int_chars',), ('intersection_counts',), ('cam_locations',), ('cam_startend',), ('intersction_locations',), ('intersection_cams',), ('all_crashes',), ('signal_crashes',), ('intersection_chars',), ('daily_violations',)]\n"
     ]
    }
   ],
   "source": [
    "make_table(rlc_df, 'daily_violations', c, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Build cam_locations TABLE - from cam_locs AND cam_startend TABLE from cam_startend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make a df with info for each camera\n",
    "Will contain the following:\n",
    "- camera_id\n",
    "- location\n",
    "- start date (when was the camera turned on)\n",
    "- end date (when was the camera turned off)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam_df = rlc_df.copy()\n",
    "cam_df['start'] = cam_df['camera_id'].apply(lambda x: None)\n",
    "cam_df['end'] = cam_df['camera_id'].apply(lambda x: None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NA values in cam_startend:\n",
      "camera_id    0\n",
      "start        0\n",
      "end          0\n",
      "dtype: int64\n",
      "\n",
      "Describe cam_startend:\n",
      "       camera_id                start                  end\n",
      "count        363                  363                  363\n",
      "unique       363                   18                   19\n",
      "top         1534  2015-01-01 00:00:00  2020-12-31 00:00:00\n",
      "freq           1                  284                  243\n",
      "first        NaN  2015-01-01 00:00:00  2015-03-02 00:00:00\n",
      "last         NaN  2018-03-05 00:00:00  2020-12-31 00:00:00\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>camera_id</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1002</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>2020-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1003</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>2020-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1011</td>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>2020-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1014</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>2020-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1023</td>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>2020-12-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  camera_id      start        end\n",
       "0      1002 2015-01-01 2020-12-31\n",
       "1      1003 2015-01-01 2020-12-31\n",
       "2      1011 2015-01-02 2020-12-31\n",
       "3      1014 2015-01-01 2020-12-31\n",
       "4      1023 2015-01-02 2020-12-31"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cam_start = cam_df.groupby(['camera_id'])['violation_date'].min().reset_index()\n",
    "cam_end = cam_df.groupby(['camera_id'])['violation_date'].max().reset_index()\n",
    "\n",
    "cam_startend = cam_start.copy()\n",
    "\n",
    "#print(cam_end[cam_end['camera_id']=='1503'].values[0][1])  # for testing output\n",
    "cam_startend['end'] = cam_start['camera_id'].apply(lambda x: cam_end[cam_end['camera_id']==x].values[0][1])\n",
    "\n",
    "cam_startend.rename(columns={\"violation_date\": \"start\"}, inplace=True)\n",
    "                                                   \n",
    "print('NA values in cam_startend:', cam_startend.isna().sum(), end='\\n\\n', sep='\\n')\n",
    "\n",
    "print('Describe cam_startend:', cam_startend.describe(), end='\\n\\n', sep='\\n')\n",
    "\n",
    "cam_startend.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a db table that has camera locations and intersections\n",
    "Intersections are present (and addresses), but we do not have lat/long info for all cams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "rlc_df.groupby('camera_id')['latitude'].max()  # Some cams do not have any data for lat long at all\n",
    "\n",
    "\n",
    "# Some of the addresses are truncated and not able to lookup with geocode\n",
    "\n",
    "address_fix = {'2400 W VAN BUREN STREE': '2400 W VAN BUREN STREET',\n",
    "               '4700 W IRVING PARK ROA': '4700 W IRVING PARK ROAD',\n",
    "               '11500 S HALSTED STREE': '11500 S HALSTED STREET',\n",
    "               '5500 S WENTWORTH AVEN': '5500 S WENTWORTH AVENUE',\n",
    "                '10300 S HALSTED STREE': '10300 S HALSTED STREET',\n",
    "               '3700 W IRVING PARK ROA': '3700 W IRVING PARK ROAD',\n",
    "               '1600 W IRVING PARK ROA': '1600 W IRVING PARK ROAD',\n",
    "               '7900 S JEFFERY BOULEV': '7900 S JEFFERY BOULEVARD',\n",
    "               '2800 W IRVING PARK ROA': '2800 W IRVING PARK ROAD',\n",
    "               '5200 W IRVING PARK ROA': '5200 W IRVING PARK ROAD',\n",
    "               '3100 S DR MARTIN L KING': '3100 S MARTIN KING DRIVE',\n",
    "               '1600 W DIVERSEY PARKWA': '1600 W DIVERSEY PARKWAY',\n",
    "               '140 W KINZIE': '140 W Kinzie St',\n",
    "                '150 N SACRAMENTO BOUL': '150 N SACRAMENTO BOUL',\n",
    "               '800 N SACRAMENTO AVEN':'800 N SACRAMENTO AVENUE',\n",
    "               '3200 N LAKESHORE DRIV':'3200 N LAKE SHORE DRIVE',\n",
    "               '6400 W FULLERTON AVENU':'6400 W FULLERTON AVENUE',\n",
    "               '6400 N MILWAUKEE AVEN':'6400 N MILWAUKEE AVENUE',\n",
    "               '7900 S STONEY ISLAND':'7900 S Stony Island Ave',  \n",
    "               '150 N SACRAMENTO BOUL':'150 N SACRAMENTO BOULEVARD',\n",
    "                '3200 N LAKESHORE DRIVE':'3200 N Lake Shore Dr',\n",
    "               '7900 S STONEY ISLAND AVENUE':'7900 S Stony Island Ave',\n",
    "               '5600 W FULLERTON AVENU':'5600 W FULLERTON AVENUE',\n",
    "               '8700 S LAFAYETTE AVEN':'8700 S LAFAYETTE AVENUE',\n",
    "               '4400 N MILWAUKEE AVEN':'4400 N MILWAUKEE AVENUE',\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two of them\n",
      "    camera_id           intersection                  address violation_date  \\\n",
      "83      1421     DAMEN AND DIVERSEY  2000 W DIVERSEY PARKWAY     2017-11-30   \n",
      "84      1421  LARAMIE AND FULLERTON    2400 N LARAMIE AVENUE     2020-12-31   \n",
      "\n",
      "    violations   latitude  longitude  month  day  weekday  year  \n",
      "83           1  41.932394 -87.678173     11   30        3  2017  \n",
      "84           6  41.924152 -87.756295     12   31        6  2020  \n",
      "\n",
      "Damen/Diversey 1\n",
      "Laramie/Fullerton: 1219\n",
      "Total cams 363\n"
     ]
    }
   ],
   "source": [
    "# we had some incorrect data in the code below, but have a creative fix.\n",
    "\n",
    "cam_locs = rlc_df.groupby(['camera_id', 'intersection']).max().reset_index()\n",
    "cam_locs.head()\n",
    "\n",
    "# we find there is a mismatch between lens, one of them is duplicated\n",
    "len(cam_locs)  # 364 total\n",
    "len(cam_locs['camera_id'].unique()) # 363\n",
    "\n",
    "cam_locs[cam_locs['camera_id'].duplicated()]  # 1421 is dupe\n",
    "print('Two of them\\n', cam_locs[cam_locs['camera_id'] == '1421'])  # we see two of them\n",
    "print()\n",
    "\n",
    "# Which one is it?\n",
    "print('Damen/Diversey', rlc_df[(rlc_df['camera_id']=='1421') & (rlc_df['intersection']=='DAMEN AND DIVERSEY')]['camera_id'].count())\n",
    "print('Laramie/Fullerton:', rlc_df[(rlc_df['camera_id']=='1421') & (rlc_df['intersection']=='LARAMIE AND FULLERTON')]['camera_id'].count())\n",
    "\n",
    "# Turns out that a camera has two locations. One was only used one time.  We drop it.\n",
    "cam_locs = cam_locs[(cam_locs['camera_id']!='1421') | (cam_locs['intersection']!='DAMEN AND DIVERSEY')]\n",
    "print(\"Total cams\", len(cam_locs))  # 363 total (got rid of the bad one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "camera_id          0\n",
       "intersection       0\n",
       "address            0\n",
       "violation_date     0\n",
       "violations         0\n",
       "latitude          19\n",
       "longitude         19\n",
       "month              0\n",
       "day                0\n",
       "weekday            0\n",
       "year               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cam_locs.isna().sum()  # missing location for 19 cameras.  Let's fix it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like we also are missing 19 of the 363 cam locations.  Let's look it up!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "This section goes through all of the rlc and assigns latlong\n",
    "Many lights are missing it.  \n",
    "For each light, there is an address though.\n",
    "We use geocoding to get the latlong\n",
    "'''\n",
    "\n",
    "# let's get all of the red light cameras with their gps location.  \n",
    "# This will aid in placing the accidents at rlc intersections later (if closer than threshold point to point)\n",
    "# Some RLCs are missing location data,  but have addresses.  I can use geocoding I guess to look them up.\n",
    "\n",
    "\n",
    "geolocator = Nominatim(user_agent=\"https://github.com/sciencelee/chicago_rlc\")  # please change to match repo\n",
    "\n",
    "# Some example code\n",
    "#location = geolocator.geocode(\"175 5th Avenue NYC\")\n",
    "#print(location.address)\n",
    "# out: Flatiron Building, 175, 5th Avenue, Flatiron, New York, NYC, New York, ...\n",
    "\n",
    "#print((location.latitude, location.longitude))\n",
    "# out: (40.7410861, -73.9896297241625)\n",
    "\n",
    "#print(location.raw)\n",
    "# out: {'place_id': '9167009604', 'type': 'attraction', ...}\n",
    "\n",
    "\n",
    "# CAN USE THIS TO FIGURE OUT MY LAT LONG FROM RLC ADDRESS (or crash later)   \n",
    " \n",
    "def get_geocode(lat, long, address):\n",
    "    if lat > 0:  # it's a location\n",
    "        return (lat, long)\n",
    "    else: # it's a proper location tuple, and assumed to be correct latlong\n",
    "        if address in address_fix.keys(): address = address_fix[address]  # errors in the dataset chars omitted\n",
    "        # if we make it this far, we have no record of this cam_id yet, and it doesn't have a proper location\n",
    "        location = geolocator.geocode(address + ', Chicago, IL')\n",
    "        if location == None:\n",
    "            print(address+':'+address+' : could not geolocate') # print it out if we can't find (address errors)\n",
    "        else:\n",
    "            return (location.latitude, location.longitude)\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "# Got it down to one-liner for this. Found out you can't extract and assign series like you can variables\n",
    "cam_locs['location'] = cam_locs.apply(lambda x: get_geocode(x.latitude, x.longitude, x.address), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam_locs['location'].head()\n",
    "cam_locs['latitude'] = cam_locs['location'].apply(lambda x: x[0])\n",
    "cam_locs['longitude'] = cam_locs['location'].apply(lambda x: x[1])\n",
    "\n",
    "cam_locs = cam_locs.drop(columns=['violation_date', 'violations', 'month', 'weekday', 'year', 'location'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 363 entries, 0 to 363\n",
      "Data columns (total 6 columns):\n",
      "camera_id       363 non-null object\n",
      "intersection    363 non-null object\n",
      "address         363 non-null object\n",
      "latitude        363 non-null float64\n",
      "longitude       363 non-null float64\n",
      "day             363 non-null int64\n",
      "dtypes: float64(2), int64(1), object(3)\n",
      "memory usage: 19.9+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "camera_id       0\n",
       "intersection    0\n",
       "address         0\n",
       "latitude        0\n",
       "longitude       0\n",
       "day             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cam_locs.info()\n",
    "cam_locs.isna().sum() # No longer missing location for 19 cameras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lat long fixes\n",
    "During EDA, we found out that five cameras were in completely wrong lat/long location.  \n",
    "Several others were located a little too far from the intersection to work properly.  When we rebuild the db, we will use bigger number than 30 m.\n",
    "\n",
    "Here are the fixes I found easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_camlocs = {'WENTWORTH AND GARFIELD': (41.79435532184194, -87.63114616279303),\n",
    "                   'KIMBALL AND LINCOLN': (41.99454797825689, -87.71403619467101),\n",
    "                    'IRVING PARK AND LARAMIE': (41.95330280770521, -87.75714705140294),\n",
    "                   'IRVING PARK AND KILPATRICK': (41.953454972337305, -87.74460631799197),\n",
    "                   '31ST ST AND MARTIN LUTHER KING DRIVE':(41.838438059816816, -87.61731906497867),\n",
    "                   '31ST AND CALIFORNIA':(41.83743605501678, -87.6950324427879),\n",
    "                   'ELSTON AND LAWRENCE': (41.96809435761252, -87.74010862196117),\n",
    "                   'OGDEN AND KOSTNER':(41.84767736575193, -87.73437725628261),\n",
    "                    'IRVING PARK AND CALIFORNIA':(41.95399037931945, -87.69821479681646),\n",
    "                   'LAKE SHORE DR AND BELMONT': (41.940128786177176, -87.63954362976928),\n",
    "                     }\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>camera_id</th>\n",
       "      <th>intersection</th>\n",
       "      <th>address</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1002</td>\n",
       "      <td>WESTERN AND CERMAK</td>\n",
       "      <td>2200 S WESTERN AVENUE</td>\n",
       "      <td>41.851984</td>\n",
       "      <td>-87.685786</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1003</td>\n",
       "      <td>WESTERN AND CERMAK</td>\n",
       "      <td>2400 W CERMAK ROAD</td>\n",
       "      <td>41.852141</td>\n",
       "      <td>-87.685753</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1011</td>\n",
       "      <td>PETERSON AND WESTERN</td>\n",
       "      <td>6000 N WESTERN AVE</td>\n",
       "      <td>41.990586</td>\n",
       "      <td>-87.689822</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1014</td>\n",
       "      <td>PETERSON AND WESTERN</td>\n",
       "      <td>2400 W PETERSON</td>\n",
       "      <td>41.990609</td>\n",
       "      <td>-87.689735</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1023</td>\n",
       "      <td>IRVING PARK AND NARRAGANSETT</td>\n",
       "      <td>6400 W IRVING PK</td>\n",
       "      <td>41.953025</td>\n",
       "      <td>-87.786683</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  camera_id                  intersection                address   latitude  \\\n",
       "0      1002            WESTERN AND CERMAK  2200 S WESTERN AVENUE  41.851984   \n",
       "1      1003            WESTERN AND CERMAK     2400 W CERMAK ROAD  41.852141   \n",
       "2      1011          PETERSON AND WESTERN     6000 N WESTERN AVE  41.990586   \n",
       "3      1014          PETERSON AND WESTERN        2400 W PETERSON  41.990609   \n",
       "4      1023  IRVING PARK AND NARRAGANSETT       6400 W IRVING PK  41.953025   \n",
       "\n",
       "   longitude  day  \n",
       "0 -87.685786   31  \n",
       "1 -87.685753   31  \n",
       "2 -87.689822   31  \n",
       "3 -87.689735   31  \n",
       "4 -87.786683   31  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cam_locs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['camera_id', 'intersection', 'address', 'latitude', 'longitude', 'day'], dtype='object')\n",
      "41.79435532184194\n",
      "dict_keys(['WENTWORTH AND GARFIELD', 'KIMBALL AND LINCOLN', 'IRVING PARK AND LARAMIE', 'IRVING PARK AND KILPATRICK', '31ST ST AND MARTIN LUTHER KING DRIVE', '31ST AND CALIFORNIA', 'ELSTON AND LAWRENCE', 'OGDEN AND KOSTNER', 'IRVING PARK AND CALIFORNIA', 'LAKE SHORE DR AND BELMONT'])\n",
      "True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>camera_id</th>\n",
       "      <th>intersection</th>\n",
       "      <th>address</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1002</td>\n",
       "      <td>WESTERN AND CERMAK</td>\n",
       "      <td>2200 S WESTERN AVENUE</td>\n",
       "      <td>41.851984</td>\n",
       "      <td>-87.685786</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1003</td>\n",
       "      <td>WESTERN AND CERMAK</td>\n",
       "      <td>2400 W CERMAK ROAD</td>\n",
       "      <td>41.852141</td>\n",
       "      <td>-87.685753</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1011</td>\n",
       "      <td>PETERSON AND WESTERN</td>\n",
       "      <td>6000 N WESTERN AVE</td>\n",
       "      <td>41.990586</td>\n",
       "      <td>-87.689822</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1014</td>\n",
       "      <td>PETERSON AND WESTERN</td>\n",
       "      <td>2400 W PETERSON</td>\n",
       "      <td>41.990609</td>\n",
       "      <td>-87.689735</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1023</td>\n",
       "      <td>IRVING PARK AND NARRAGANSETT</td>\n",
       "      <td>6400 W IRVING PK</td>\n",
       "      <td>41.953025</td>\n",
       "      <td>-87.786683</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  camera_id                  intersection                address   latitude  \\\n",
       "0      1002            WESTERN AND CERMAK  2200 S WESTERN AVENUE  41.851984   \n",
       "1      1003            WESTERN AND CERMAK     2400 W CERMAK ROAD  41.852141   \n",
       "2      1011          PETERSON AND WESTERN     6000 N WESTERN AVE  41.990586   \n",
       "3      1014          PETERSON AND WESTERN        2400 W PETERSON  41.990609   \n",
       "4      1023  IRVING PARK AND NARRAGANSETT       6400 W IRVING PK  41.953025   \n",
       "\n",
       "   longitude  day  \n",
       "0 -87.685786   31  \n",
       "1 -87.685753   31  \n",
       "2 -87.689822   31  \n",
       "3 -87.689735   31  \n",
       "4 -87.786683   31  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(cam_locs.columns)\n",
    "\n",
    "print(correct_camlocs['WENTWORTH AND GARFIELD'][0])\n",
    "print(correct_camlocs.keys())\n",
    "print('WENTWORTH AND GARFIELD' in correct_camlocs.keys())\n",
    "cam_locs['latitude'] = cam_locs.apply(lambda x: correct_camlocs[x['intersection']][0] if x['intersection'] in correct_camlocs.keys() else x['latitude'], axis=1)\n",
    "cam_locs['longitude'] = cam_locs.apply(lambda x: correct_camlocs[x['intersection']][1] if x['intersection'] in correct_camlocs.keys() else x['longitude'], axis=1)\n",
    "\n",
    "cam_locs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create cam_locations TABLE - from cam_locs AND cam_startend from cam_startend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('hourly_congestion',), ('hourly_weather',), ('region_data',), ('int_chars',), ('intersection_counts',), ('cam_startend',), ('intersction_locations',), ('intersection_cams',), ('all_crashes',), ('signal_crashes',), ('intersection_chars',), ('daily_violations',), ('cam_locations',)]\n",
      "[('hourly_congestion',), ('hourly_weather',), ('region_data',), ('int_chars',), ('intersection_counts',), ('intersction_locations',), ('intersection_cams',), ('all_crashes',), ('signal_crashes',), ('intersection_chars',), ('daily_violations',), ('cam_locations',), ('cam_startend',)]\n"
     ]
    }
   ],
   "source": [
    "make_table(cam_locs, 'cam_locations', c, conn)\n",
    "make_table(cam_startend, 'cam_startend', c, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  We still have missing lat/long info for our rlc_df.  Let's fix it\n",
    "Before moving on.  Now that we have cam_locs, we can fix our rlc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>camera_id</th>\n",
       "      <th>intersection</th>\n",
       "      <th>address</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1002</td>\n",
       "      <td>WESTERN AND CERMAK</td>\n",
       "      <td>2200 S WESTERN AVENUE</td>\n",
       "      <td>41.851984</td>\n",
       "      <td>-87.685786</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1003</td>\n",
       "      <td>WESTERN AND CERMAK</td>\n",
       "      <td>2400 W CERMAK ROAD</td>\n",
       "      <td>41.852141</td>\n",
       "      <td>-87.685753</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1011</td>\n",
       "      <td>PETERSON AND WESTERN</td>\n",
       "      <td>6000 N WESTERN AVE</td>\n",
       "      <td>41.990586</td>\n",
       "      <td>-87.689822</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1014</td>\n",
       "      <td>PETERSON AND WESTERN</td>\n",
       "      <td>2400 W PETERSON</td>\n",
       "      <td>41.990609</td>\n",
       "      <td>-87.689735</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1023</td>\n",
       "      <td>IRVING PARK AND NARRAGANSETT</td>\n",
       "      <td>6400 W IRVING PK</td>\n",
       "      <td>41.953025</td>\n",
       "      <td>-87.786683</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  camera_id                  intersection                address   latitude  \\\n",
       "0      1002            WESTERN AND CERMAK  2200 S WESTERN AVENUE  41.851984   \n",
       "1      1003            WESTERN AND CERMAK     2400 W CERMAK ROAD  41.852141   \n",
       "2      1011          PETERSON AND WESTERN     6000 N WESTERN AVE  41.990586   \n",
       "3      1014          PETERSON AND WESTERN        2400 W PETERSON  41.990609   \n",
       "4      1023  IRVING PARK AND NARRAGANSETT       6400 W IRVING PK  41.953025   \n",
       "\n",
       "   longitude  day  \n",
       "0 -87.685786   31  \n",
       "1 -87.685753   31  \n",
       "2 -87.689822   31  \n",
       "3 -87.689735   31  \n",
       "4 -87.786683   31  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rlc_df.isna().sum()  \n",
    "cam_locs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decided to eliminate cam position in favor of intersection lat/long\n",
    "I hope this makes all of my position data consistent for gathering crash info.\n",
    "When using cam location, it is sometimes up to 35 m up road where cam position is.  This would cause us to misidentify crashes from other intersections or miss some in the intersection of interest.  R\n",
    "\n",
    "Remedy: Use center point of intersection for all cams.\n",
    "\n",
    "How to do it:  I will change cam_locs data to match intersection instead of individual camera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['protected_turn', 'total_lanes', 'medians', 'exit', 'split', 'way',\n",
       "       'underpass', 'no_left', 'angled', 'triangle', 'one_way', 'turn_lanes',\n",
       "       'lat', 'long', 'rlc', 'daily_traffic'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def location_correction(int_df, intersect, latlong):\n",
    "    # lookup function from intersection df to get the lat long\n",
    "    # int_df is the intersection characteristic frame from 1) above\n",
    "    # intersect is the intersection name used to link tables/df\n",
    "    # latlong is either 'lat' or 'long'\n",
    "    if latlong == 'lat':\n",
    "        lat = int_df[int_df['intersection']==intersect]['lat'].values[0]\n",
    "        return lat\n",
    "    else:\n",
    "        long = int_df[int_df['intersection']==intersect]['long'].values[0]\n",
    "\n",
    "cam_locs['latitude'] = cam_locs['intersection'].apply(lambda x: location_correction(int_df, x, 'lat'))\n",
    "cam_locs['longitude'] = cam_locs['intersection'].apply(lambda x: location_correction(int_df, x, 'long'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intersection</th>\n",
       "      <th>camera_id</th>\n",
       "      <th>address</th>\n",
       "      <th>violation_date</th>\n",
       "      <th>violations</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>weekday</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>31ST ST AND MARTIN LUTHER KING DRIVE</td>\n",
       "      <td>2121</td>\n",
       "      <td>3100 S DR MARTIN L KING</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>IRVING PARK AND LARAMIE</td>\n",
       "      <td>1533</td>\n",
       "      <td>5200 W IRVING PARK ROA</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>ELSTON AND IRVING PARK</td>\n",
       "      <td>1503</td>\n",
       "      <td>3700 W IRVING PARK ROA</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>IRVING PARK AND KILPATRICK</td>\n",
       "      <td>2764</td>\n",
       "      <td>4700 W IRVING PARK ROA</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>IRVING PARK AND CALIFORNIA</td>\n",
       "      <td>1234</td>\n",
       "      <td>2800 W IRVING PARK ROA</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           intersection camera_id                  address  \\\n",
       "0  31ST ST AND MARTIN LUTHER KING DRIVE      2121  3100 S DR MARTIN L KING   \n",
       "2               IRVING PARK AND LARAMIE      1533   5200 W IRVING PARK ROA   \n",
       "3                ELSTON AND IRVING PARK      1503   3700 W IRVING PARK ROA   \n",
       "4            IRVING PARK AND KILPATRICK      2764   4700 W IRVING PARK ROA   \n",
       "5            IRVING PARK AND CALIFORNIA      1234   2800 W IRVING PARK ROA   \n",
       "\n",
       "  violation_date  violations  latitude  longitude  month  day  weekday  year  \n",
       "0     2015-01-01          19       NaN        NaN      1    1        3  2015  \n",
       "2     2015-01-01           2       NaN        NaN      1    1        3  2015  \n",
       "3     2015-01-01           2       NaN        NaN      1    1        3  2015  \n",
       "4     2015-01-01           3       NaN        NaN      1    1        3  2015  \n",
       "5     2015-01-01           1       NaN        NaN      1    1        3  2015  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#⏳⏳⏳⏳⏳⏳\n",
    "# THIS TAKES SOME TIME (8min on my macbook pro)\n",
    "def read_loc(int_df, intersection):\n",
    "    cam = int_df[int_df['intersection']==intersection]\n",
    "    #print(cam)\n",
    "    return (float(cam['lat']), float(cam['long']))\n",
    "        \n",
    "\n",
    "\n",
    "# create a location column so we only have to do it once\n",
    "#rlc_df['location'] = \n",
    "rlc_df['intersection'][:5].apply(lambda x: read_loc(int_df, x))\n",
    "rlc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# then add in the new lat longs to the df\n",
    "rlc_df['latitude'] = rlc_df['location'].apply(lambda x: x[0])\n",
    "rlc_df['longitude'] = rlc_df['location'].apply(lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intersection</th>\n",
       "      <th>camera_id</th>\n",
       "      <th>address</th>\n",
       "      <th>violation_date</th>\n",
       "      <th>violations</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>weekday</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>31ST ST AND MARTIN LUTHER KING DRIVE</td>\n",
       "      <td>2121</td>\n",
       "      <td>3100 S DR MARTIN L KING</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>IRVING PARK AND LARAMIE</td>\n",
       "      <td>1533</td>\n",
       "      <td>5200 W IRVING PARK ROA</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>ELSTON AND IRVING PARK</td>\n",
       "      <td>1503</td>\n",
       "      <td>3700 W IRVING PARK ROA</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>IRVING PARK AND KILPATRICK</td>\n",
       "      <td>2764</td>\n",
       "      <td>4700 W IRVING PARK ROA</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>IRVING PARK AND CALIFORNIA</td>\n",
       "      <td>1234</td>\n",
       "      <td>2800 W IRVING PARK ROA</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           intersection camera_id                  address  \\\n",
       "0  31ST ST AND MARTIN LUTHER KING DRIVE      2121  3100 S DR MARTIN L KING   \n",
       "2               IRVING PARK AND LARAMIE      1533   5200 W IRVING PARK ROA   \n",
       "3                ELSTON AND IRVING PARK      1503   3700 W IRVING PARK ROA   \n",
       "4            IRVING PARK AND KILPATRICK      2764   4700 W IRVING PARK ROA   \n",
       "5            IRVING PARK AND CALIFORNIA      1234   2800 W IRVING PARK ROA   \n",
       "\n",
       "  violation_date  violations  latitude  longitude  month  day  weekday  year  \n",
       "0     2015-01-01          19       NaN        NaN      1    1        3  2015  \n",
       "2     2015-01-01           2       NaN        NaN      1    1        3  2015  \n",
       "3     2015-01-01           2       NaN        NaN      1    1        3  2015  \n",
       "4     2015-01-01           3       NaN        NaN      1    1        3  2015  \n",
       "5     2015-01-01           1       NaN        NaN      1    1        3  2015  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rlc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'location' in rlc_df.columns:\n",
    "    rlc_df.drop(columns=['location'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('hourly_congestion',), ('hourly_weather',), ('region_data',), ('int_chars',), ('intersection_counts',), ('intersction_locations',), ('intersection_cams',), ('all_crashes',), ('signal_crashes',), ('intersection_chars',), ('cam_locations',), ('cam_startend',), ('daily_violations',)]\n"
     ]
    }
   ],
   "source": [
    "make_table(rlc_df, 'daily_violations', c, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) intersection_locations TABLE - from intersection_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add a df of intersections with lat long\n",
    "This should help us later determine if crash is at intersection\n",
    "\n",
    "I chose to groupby the intersection and aggregate the most commonly occuring lat/long value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#results_df.groupby(['intersection', 'latitude', 'longitude']).reset_index()\n",
    "intersection_df = rlc_df.groupby(['intersection']).agg({'latitude':pd.Series.mode,'longitude':pd.Series.mode,}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersection_df.info()\n",
    "intersection_df.head()  # that was easy!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create intersection_locations TABLE - from intersection_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_table(intersection_df, 'intersction_locations', c, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Create intersection_cams TABLE - from int_cams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will now focus on trying to bring rlc intersections to our crashes\n",
    "We find that we have 363 cameras at 183 intersections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam_locs.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_cams = cam_locs.groupby(['intersection']) \\\n",
    "                    .agg({'latitude':pd.Series.max, 'longitude':pd.Series.max,}) \\\n",
    "                    .reset_index()\n",
    "\n",
    "int_cams['cam1'] = int_cams['intersection'] \\\n",
    "                            .apply(lambda x: cam_locs[cam_locs['intersection']==x]['camera_id'].iloc[0])\n",
    "\n",
    "int_cams['cam2'] = int_cams['intersection'].apply( \\\n",
    "                            lambda x: None if len(cam_locs[cam_locs['intersection']==x])==1 \\\n",
    "                            else cam_locs[cam_locs['intersection']==x]['camera_id'].iloc[1])\n",
    "\n",
    "int_cams['cam3'] = int_cams['intersection'].apply( \\\n",
    "                            lambda x: None if len(cam_locs[cam_locs['intersection']==x])<3 \\\n",
    "                            else cam_locs[cam_locs['intersection']==x]['camera_id'].iloc[2])                             \n",
    "\n",
    "int_cams.head()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Total Cameras', len(cam_locs))\n",
    "print('Total Intersections', len(int_cams))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create intersection_cams TABLE - from int_cams\n",
    "first we add a column for region to each of my intersections\n",
    "#### Should come back and add this later.  Need to also bring in congestion data though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_table(int_cams, 'intersection_cams', c, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Create signal_crashes TABLE - from crash_df AND all_crashes - from crash_df (pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crash Data\n",
    "crash_data = client.get(\"85ca-t3if\", \n",
    "                     where=\"crash_date BETWEEN \\'2015-01-01T00:00:00.000\\' AND \\'2020-12-31T00:00:00.000\\'\",\n",
    "                     limit=1000000,\n",
    "                    )\n",
    "\n",
    "crash_df = pd.DataFrame.from_records(crash_data) # Convert to pandas DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crash data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop a few columns we don't need, including location (we have lat/long)\n",
    "dropme = ['statements_taken_i', 'private_property_i', 'photos_taken_i', 'dooring_i', 'date_police_notified','location']\n",
    "\n",
    "crash_df.drop(columns=dropme, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crash_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 2.5k entries that have no location.  Let's drop them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crash_df.dropna(subset=['latitude',], inplace=True)  # get rid of na locations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's look at what is in the data   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What's in this data?\n",
    "col_interest = ['traffic_control_device', 'device_condition', 'weather_condition',\n",
    "       'lighting_condition', 'first_crash_type', 'trafficway_type',\n",
    "       'alignment', 'roadway_surface_cond', 'road_defect', 'report_type',\n",
    "       'crash_type', 'hit_and_run_i', 'damage', 'prim_contributory_cause',\n",
    "       'sec_contributory_cause', 'street_no', 'street_direction',\n",
    "       'street_name', 'beat_of_occurrence', 'num_units', 'most_severe_injury', \n",
    "        'injuries_fatal', 'injuries_incapacitating',\n",
    "       'injuries_non_incapacitating', 'injuries_reported_not_evident',\n",
    "       'injuries_no_indication', 'injuries_unknown', 'crash_hour',\n",
    "       'crash_day_of_week', 'crash_month', 'latitude', 'longitude', 'lane_cnt',\n",
    "       'intersection_related_i', 'crash_date_est_i',\n",
    "       'work_zone_i', 'work_zone_type',\n",
    "       'workers_present_i']\n",
    "\n",
    "for col in col_interest:\n",
    "    print(col, crash_df[col].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter for desired crashes (intersections with signal)\n",
    "This helps us.  \n",
    "We can filter 'traffic_control_device' == 'TRAFFIC SIGNAL'.  \n",
    "We can filter 'intersection_related_i' == 'Y'\n",
    "\n",
    "This will leave us with only crashes that occurred at/because of intersections, and with a signal at the intersection.\n",
    "\n",
    "intersection_related_i: A field observation by the police officer whether an intersection played a role in the crash. Does not represent whether or not the crash occurred within the intersection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_table(crash_df, 'all_crashes', c, conn)\n",
    "\n",
    "crash_df = crash_df[(crash_df['traffic_control_device']=='TRAFFIC SIGNAL') & \\\n",
    "                    (crash_df['intersection_related_i']=='Y')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add the intersection to my crashes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#⏳⏳⏳⏳⏳\n",
    "# Now I am desperate.  This takes too long to process.  Let's simplify it and make it a box instead.\n",
    "box_side = 70  # effectively makes it check for crash being within 35m of interscection\n",
    "box_lat = box_side / 111070 / 2 # 111070 is meters in deg lat in Chicago\n",
    "box_long = box_side / 83000 / 2 # 83000 is meters in deg long in Chicago\n",
    "\n",
    "def box_check(lat, long, ints_df):\n",
    "    answer = (ints_df[  (ints_df['latitude'] > (lat - box_lat)) & \n",
    "                      (ints_df['latitude'] < (lat + box_lat)) &\n",
    "                      (ints_df['longitude'] > (long - box_long)) &\n",
    "                      (ints_df['longitude'] < (long + box_long))\n",
    "                     ])\n",
    "    if answer.empty: return None\n",
    "    return answer['intersection'].values[0]\n",
    "    \n",
    "# THIS SEEMS TO WORK WITH SPEED AND ELIMINATES MEMORY PROBLEM\n",
    "for i in range(100): #(len(df)):\n",
    "    intersect = box_check(float(crash_df.iloc[i]['latitude']), \n",
    "                          float(crash_df.iloc[i]['longitude']), \n",
    "                          int_cams)\n",
    "    if intersect: print(intersect)\n",
    "    \n",
    "    \n",
    "# MOMENT OF TRUTH (takes a few minutes, but at least it runs.  This caused me lots of trouble)\n",
    "crash_df['intersection'] = crash_df.apply(lambda x: box_check(float(x.latitude), \n",
    "                                                              float(x.longitude), \n",
    "                                                              int_cams), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Ex: df[['two', 'three']] = df[['two', 'three']].astype(float)\n",
    "crash_df['crash_date'] = pd.to_datetime(crash_df['crash_date'])\n",
    "crash_df['year'] = crash_df['crash_date'].apply(lambda x: int(x.year))\n",
    "crash_df['month'] = crash_df['crash_date'].apply(lambda x: int(x.month))\n",
    "crash_df['day'] = crash_df['crash_date'].apply(lambda x: int(x.day))\n",
    "crash_df['hour'] = crash_df['crash_date'].apply(lambda x: int(x.hour))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crash_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create signal_crashes TABLE - from crash_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_table(crash_df, 'signal_crashes', c, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Create hourly_congestion TABLE from all_traffic\n",
    "For this one, we have to combine two different datasets.  Chicago changed the way data was recorded in 2018.  Columns are similar, but more data collected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Congestion Data\n",
    "traffic_df = client.get(\"emtn-qqdi\", \n",
    "                     #where=\"TIME > \\'2015-01-01T00:00:00.000\\'\",\n",
    "                     where='TIME BETWEEN \\'2015-01-01T00:00:00.000\\' AND \\'2020-12-31T00:00:00.000\\'',\n",
    "                     limit=10000000,\n",
    "                    )\n",
    "\n",
    "traffic_df = pd.DataFrame.from_records(traffic_df) # Convert to pandas DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean up my datatypes before preprocessing\n",
    "Won't be able to table it until we get both datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic_df.rename(columns={'number_of_reads':'num_reads'}, inplace=True)\n",
    "traffic_df['time'] = pd.to_datetime(traffic_df['time'])\n",
    "traffic_df['bus_count'] = traffic_df['bus_count'].astype(int)\n",
    "traffic_df['num_reads'] = traffic_df['num_reads'].astype(int)\n",
    "traffic_df['speed'] = traffic_df['speed'].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On to the other dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Congestion data from later\n",
    "traffic_df2 = client.get(\"kf7e-cur8\", #2018 to present\n",
    "                     select='time, region_id, speed, bus_count, num_reads',  # this set is huge, so we won't get all       \n",
    "                     where=\"TIME < \\'2021-01-01T00:00:00.000\\'\",\n",
    "                     limit=10000000,\n",
    "                    )\n",
    "\n",
    "# Convert to pandas DataFrame\n",
    "traffic_df2 = pd.DataFrame.from_records(traffic_df2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#traffic2_df.rename(columns={'number_of_reads':'num_reads'}, inplace=True)\n",
    "traffic_df2['time'] = pd.to_datetime(traffic_df2['time'])\n",
    "traffic_df2['bus_count'] = traffic_df2['bus_count'].astype(int)\n",
    "traffic_df2['num_reads'] = traffic_df2['num_reads'].astype(int)\n",
    "traffic_df2['speed'] = traffic_df2['speed'].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now get the congestion data processed\n",
    "We have two separate traffic_dfs.  There is data prior to 2018 and after in two different api endpoints.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic_df.head()\n",
    "traffic_df2.head()\n",
    "traffic_df2.info()\n",
    "print()\n",
    "traffic_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge my two data sets for congestion by region\n",
    "all_traffic = pd.merge(traffic_df, traffic_df2, how='outer')\n",
    "print('traffic dfs merged')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_traffic['hour'] = all_traffic['time'].dt.hour\n",
    "print('added hour column')\n",
    "\n",
    "all_traffic['day'] = all_traffic.time.dt.day\n",
    "print('added day column')\n",
    "\n",
    "all_traffic['month'] = all_traffic.time.dt.month\n",
    "print('added month column')\n",
    "\n",
    "all_traffic['year'] = all_traffic.time.dt.year\n",
    "print('added year column')\n",
    "\n",
    "all_traffic['weekday'] = all_traffic.time.dt.weekday\n",
    "print('added weekday column')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(all_traffic))  # lots of dupes \n",
    "all_traffic = all_traffic.groupby(['year', 'month', 'day', 'hour', 'region_id']).mean().reset_index()\n",
    "all_traffic.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_traffic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# couple minutes\n",
    "make_table(all_traffic, 'hourly_congestion', c, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speed fix for congestion\n",
    "Congestion is measured by average bus speed.\n",
    "\n",
    "The problem:\n",
    "- Overnight (between 11 and 5am) we have few bus routes.\n",
    "- Some regions have no buses overnight\n",
    "- Some regions have only a few buses \n",
    "- Some buses are ending routes and have only a few reads\n",
    "- Some buses are stationary (next morning staging)\n",
    "\n",
    "The fix:\n",
    "- replace speed for few buses/reads if speed is low\n",
    "- we assume low buses/reads to be overnight when congestion is minimal\n",
    "- replacement speed is a low congestion quantile speed (90% or so)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's get the 0.90 quantile for every region, and then use that to fill in missing data\n",
    "\n",
    "regions_90 = all_traffic.groupby(['region_id'])['speed'].quantile(0.9).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions_90.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 5 MINUTES OR SO\n",
    "\n",
    "#my read on this is that few buses run 24/7, so the data is unreliable.  \n",
    "# buses stage for next morning.  You can see them all along Clark, LSD etc.  \n",
    "# They have speed=0 and may be recording.  Could talk to owner of dataset.\n",
    "\n",
    "# I will draw the cutoff at 100 reads, 5 buses, speed < 10\n",
    "# in that case I will put in a quantile speed for the region\n",
    "\n",
    "\n",
    "def speed_check(bus, speed, reads, region_id, regions_90):\n",
    "    if (bus <= 5 or reads < 100) and speed < 25 or speed > 40:\n",
    "        return regions_90[regions_90['region_id']==region_id]['speed'].values[0]\n",
    "    else:\n",
    "        return speed\n",
    "    \n",
    "\n",
    "# apply is SLOOOOOOWWW, but not sure how else to accomplish this without iter\n",
    "all_traffic['speed'] = all_traffic.apply(lambda x: speed_check(x.bus_count, x.speed, x.num_reads, x.region_id, regions_90), axis=1)\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_table(all_traffic, 'hourly_congestion', c, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7) Create hourly_weather from wx_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import weather data from csv\n",
    "wx_df = pd.read_csv('data/chi_wx.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wx_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wx_df['time'] = pd.to_datetime(wx_df['dt_iso'].apply(lambda x: x[:-4]))\n",
    "wx_df.head()\n",
    "wx_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wx_df['rain_3h'] = wx_df['rain_3h'].fillna(0)\n",
    "wx_df['rain_1h'] = wx_df['rain_1h'].fillna(0)\n",
    "wx_df['snow_3h'] = wx_df['snow_3h'].fillna(0)\n",
    "wx_df['snow_1h'] = wx_df['snow_1h'].fillna(0)\n",
    "wx_df['temp'] = wx_df['temp_max']\n",
    "wx_df['year'] = wx_df.time.dt.year\n",
    "wx_df['month'] = wx_df.time.dt.month\n",
    "wx_df['day'] = wx_df.time.dt.day\n",
    "wx_df['hour'] = wx_df.time.dt.hour\n",
    "wx_df['weekday'] = wx_df.time.dt.weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wx_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    wx_df = wx_df.drop(columns=['dt', \n",
    "                        'dt_iso', \n",
    "                        'timezone', \n",
    "                        'city_name', \n",
    "                        'lat', \n",
    "                        'lon', \n",
    "                        'feels_like', \n",
    "                        'temp_min', \n",
    "                        'temp_max',\n",
    "                        'pressure',\n",
    "                        'sea_level',\n",
    "                        'grnd_level',\n",
    "                        'humidity',\n",
    "                        'wind_speed',\n",
    "                        'wind_deg',\n",
    "                        'clouds_all',\n",
    "                        'weather_description',\n",
    "                        'weather_icon',\n",
    "                        'weather_id',\n",
    "                        'weather_main',\n",
    "                       ], axis=1)\n",
    "except:\n",
    "    print('Failed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(wx_df))\n",
    "print(wx_df.duplicated().sum())\n",
    "\n",
    "\n",
    "print('Total hours in 6 years:', 365.25 * 24 * 6)\n",
    "print('Unique entries:', len(wx_df.drop_duplicates()))  \n",
    "# missing a few entries (700+ out of 52k)  Am I missing a month??\n",
    "\n",
    "print()\n",
    "print(wx_df.time.min(), wx_df.time.max())  # OH!!!!  I am missin last month\n",
    "print('Total hours in 6 years (-1 mos):', 365.25 * 24 * 6 - 31 * 24)  # okay, we are only missing a few\n",
    "\n",
    "\n",
    "wx_df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_table(wx_df, 'hourly_weather', c, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8) Create TABLE region_data from region_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THis time we only grab what we need\n",
    "\n",
    "region_df = client.get(\"kf7e-cur8\", # regional congestion current data\n",
    "                         select='region_id, region, description, north, south, east, west',\n",
    "                         limit=1000\n",
    "                    )\n",
    "\n",
    "# Convert to pandas DataFrame\n",
    "region_df = pd.DataFrame.from_records(region_df)  # should only return most recent for each region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_df = region_df.groupby('region_id').max().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need these as floats so we can compare them\n",
    "region_df[['north', 'south', 'east', 'west']] = region_df[['north', 'south', 'east', 'west']].astype(float)\n",
    "region_df.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add region to my crash df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crash_df[['latitude', 'longitude']] = crash_df[['latitude', 'longitude']].astype(float)\n",
    "crash_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add in the region for my crashes\n",
    "# Resource hog\n",
    "crash_df.columns\n",
    "\n",
    "\n",
    "def which_region(lat, long, region_df):\n",
    "    #print(lat, long)\n",
    "    row = region_df[(region_df['east'] >= long) &\n",
    "                    (region_df['west'] < long) &\n",
    "                    (region_df['north'] >= lat) &\n",
    "                    (region_df['south'] < lat)]['region_id'].max()\n",
    "    return row\n",
    "\n",
    "#df.iloc[:5]\n",
    "# takes some 5min\n",
    "crash_df['region_id'] = crash_df.apply(lambda x: which_region(x.latitude, x.longitude, region_df), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(crash_df)\n",
    "crash_df.columns\n",
    "\n",
    "crash_df['time'] = pd.to_datetime(crash_df.crash_date)\n",
    "crash_df['year'] = crash_df.time.dt.year\n",
    "crash_df['month'] = crash_df.time.dt.month\n",
    "crash_df['day'] = crash_df.time.dt.day\n",
    "crash_df['hour'] = crash_df.time.dt.hour\n",
    "crash_df['weekday'] = crash_df.time.dt.weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_table(region_df, 'region_data', c, conn)\n",
    "print()\n",
    "make_table(crash_df, 'signal_crashes', c, conn)  # also update my crash data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add region_id to intersection_cams\n",
    "While I'm here and I have the function ready.\n",
    "I would like to add region_id number to my red light camera (daily_violations TABLE)\n",
    "The region there will help me link the daily_violations and hourly_congestion TABLEs\n",
    "\n",
    "*** NOTE: Makes more sense to come back and put the region into the intersection_cameras table to speed this up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10 minutes\n",
    "#rlc['region_id'] = \n",
    "int_cams['region_id'] = int_cams.apply(lambda x: which_region(x.latitude, x.longitude, region_df), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## commit my change\n",
    "make_table(int_cams, 'intersection_cams', c, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use this code to test any of your tables for proper data storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = c.execute(\"SELECT camera_id, violations FROM daily_violations;\").fetchall()\n",
    "print(query[:5])\n",
    "print(len(query))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before I go, I want to add intersections to my crashes to link the db tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_fetch_tables(c, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_sql_query(\"SELECT * FROM signal_crashes\", conn)\n",
    "camloc_df = pd.read_sql_query('SELECT * FROM cam_locations', conn)\n",
    "ints_df = pd.read_sql_query('SELECT * FROM intersection_cams', conn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ints_df.astype({'longitude':float})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now I am desperate.  This takes too long to process.  Let's simplify it and make it a box instead.\n",
    "box_side = 50  # effectively makes it check for crash being within 25m of interscection\n",
    "box_lat = box_side / 111070 / 2 # 111070 is meters in deg lat in Chicago\n",
    "box_long = box_side / 83000 / 2 # 83000 is meters in deg long in Chicago\n",
    "\n",
    "def box_check(lat, long, ints_df):\n",
    "    answer = (ints_df[  (ints_df['latitude'] > (lat - box_lat)) & \n",
    "                      (ints_df['latitude'] < (lat + box_lat)) &\n",
    "                      (ints_df['longitude'] > (long - box_long)) &\n",
    "                      (ints_df['longitude'] < (long + box_long))\n",
    "                     ])\n",
    "    if answer.empty: return None\n",
    "    return answer['intersection'].values[0]\n",
    "    \n",
    "# THIS SEEMS TO WORK WITH SPEED AND ELIMINATES MEMORY PROBLEM\n",
    "for i in range(5): #(len(df)):\n",
    "    intersect = box_check(float(df.iloc[i]['latitude']), float(df.iloc[i]['longitude']), ints_df)\n",
    "    print(intersect)\n",
    "    \n",
    "    \n",
    "# MOMENT OF TRUTH\n",
    "#df['intersection'] = df.apply(lambda x: box_check(float(x.latitude), float(x.longitude), camloc_df), axis=1)\n",
    "\n",
    "df['intersection'] = df.apply(lambda x: box_check(float(x.latitude), float(x.longitude), ints_df), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_table(df, 'signal_crashes', c, conn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## traffic_count TABLE from traffic_count\n",
    "Congestion did not work in the model.  It is by region, and the regions added very little.\n",
    "We have data from a traffic study that gives average volume of traffic by street segment.\n",
    "We will try to match up the segment(s) to the cameras.  This might be tricky."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# traffic study\n",
    "# Takes several minutes to run and holds about 500mb in memory to build\n",
    "\n",
    "# returned as JSON from API / converted to Python list of dictionaries by sodapy\n",
    "traffic_count = client.get(\"pfsx-4n4m\", #speed cams are at 'hhkd-xvj4' if you want to investigate?\n",
    "                     #where='violation_date > 01-01-2020',\n",
    "                    )\n",
    "\n",
    "traffic_count = pd.DataFrame.from_records(df_traf) # Convert to pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_count = intersection_df.copy()\n",
    "traffic_count.head()\n",
    "print(int_count.columns)\n",
    "\n",
    "#int_count[['latitude', 'longitude']] = int_count[['latitude', 'longitude']].astype(float)\n",
    "#int_count['latitude'] = int_count['latitude'].astype(float)\n",
    "pd.options.display.max_rows = 200\n",
    "#int_count['latitude']\n",
    "\n",
    "\n",
    "traffic_count.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "latlong_ratio = 100000 # about how much a lat/long is meters in deg lat in Chicago.  It's imprecise approximation, but within 10% of answer\n",
    "\n",
    "\n",
    "def get_closest(lat, long, traffic_count):\n",
    "    if type(lat) == list:\n",
    "        lat=lat[0]\n",
    "    if type(long) == list:\n",
    "        long=long[0]\n",
    "    lat = float(lat)\n",
    "    long= float(long)\n",
    "    #dist = traffic_count.apply(lambda x: [(lat-float(x['latitude']))**2 + (long-float(x['longitude']))**2, x], axis=1)\n",
    "    dist = traffic_count.apply(lambda x: math.sqrt((lat-float(x['latitude']))**2 + (long-float(x['longitude']))**2), axis=1) * latlong_ratio\n",
    "    \n",
    "    dist = dist.sort_values(ascending=True)\n",
    "    print(dist[:5])\n",
    "\n",
    "int_count[:5].apply(lambda x: get_closest(x.latitude, x.longitude, traffic_count), axis=1)\n",
    "int_count[:5] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
