{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis\n",
    "Will look at some or all of:\n",
    "- red light camera data vs\n",
    "    - temporal (year, month, weekday)\n",
    "    - weather\n",
    "    - intersection characteristics\n",
    "    - region\n",
    "    - by congestion\n",
    "- crash data\n",
    "     - crash type\n",
    "     - temporal (year, month, weekday, hour)\n",
    "     - intersection characteristics\n",
    "     - camera on / camera off\n",
    "     - covid numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from modules.myfuncs import *\n",
    "import warnings\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "# import dask\n",
    "# import dask.dataframe as dd\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file rlc2.db can be downloaded from \n",
    "# https://drive.google.com/file/d/1qIwCtdU1G7FtK4fCaB5mwa4QUGQNesKa/view?usp=sharing\n",
    "conn = create_connection('database/rlc2.db')  # function from myfuncs file\n",
    "c = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# available tables\n",
    "sql_fetch_tables(c, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions_df = pd.read_sql_query(\"SELECT * FROM region_data\", conn)\n",
    "weather_df = pd.read_sql_query(\"SELECT * FROM hourly_weather\", conn)\n",
    "crash_df = pd.read_sql_query(\"SELECT * FROM signal_crashes\", conn)\n",
    "signal_df = pd.read_sql_query(\"SELECT * FROM daily_violations\", conn)\n",
    "\n",
    "weather_df['precip'] = weather_df['snow_1h'] + weather_df['rain_1h']\n",
    "wx_daily = weather_df.groupby(['year', 'month', 'day']).agg({'temp':'max', 'precip':'sum', 'snow_1h':'sum'}).reset_index()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Violations EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will look at how the number of violations are affected by:\n",
    "- day of week\n",
    "- year\n",
    "- month\n",
    "- weekday\n",
    "- intersection\n",
    "- region"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Violations by day of week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_df = signal_df[signal_df['year']>2016]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn-white')\n",
    "\n",
    "# Weekday plot\n",
    "df_weekday = signal_df.groupby(['weekday'])['violations'].sum().reset_index()\n",
    "print(df_weekday.head())\n",
    "\n",
    "\n",
    "ax = df_weekday.plot.bar('weekday', 'violations', figsize=[8,6])\n",
    "labels = ['Sun', 'Mon', 'Tues', 'Wed', 'Thur', 'Fri', 'Sat']\n",
    "ax.set_xticklabels(labels)\n",
    "ax.set_title(\"Violations by Day of Week\")\n",
    "ax.set_yticklabels(['{:,}'.format(int(x)) for x in ax.get_yticks().tolist()])\n",
    "\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Violations by month\n",
    "Does the month of the year have any effect on violations?\n",
    "Note: Not all months have same days.  I will normalize it by using average daily violations instead of total violations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Month plot\n",
    "df_month = signal_df.groupby(['month'])['violations'].mean().reset_index()\n",
    "\n",
    "ax2 = df_month.plot.bar('month', 'violations', figsize=[8,6])\n",
    "labels = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "ax2.set_xticklabels(labels)\n",
    "ax2.set_title(\"Mean Daily Violations by Month (per camera)\", fontsize=14)\n",
    "ax2.set_xlabel('Mean Daily Violations')\n",
    "ax2.set_ylabel('Violations')\n",
    "ax2.get_legend().remove()\n",
    "\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Violations by year\n",
    "Did the violations change over the long term.\n",
    "This could also be affected by number of cameras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Year plot\n",
    "df_year = signal_df.groupby(['year'])['violations'].sum().reset_index()\n",
    "df_year = df_year[df_year['year'] < 2021]\n",
    "\n",
    "ax4 = df_year.plot.bar('year', 'violations', figsize=[8,6])\n",
    "ax4.set_title(\"Total violations by Year\", fontsize=16)\n",
    "ax4.set_ylabel(\"Violations\", fontsize=14)\n",
    "ax4.set_yticklabels(['{:,}'.format(int(x)) for x in ax.get_yticks().tolist()])  # add commas to y\n",
    "ax4.get_legend().remove()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotly is not supported with boxplot\n",
    "plt.figure(figsize=[10,8])\n",
    "#signal_df.groupby(['camera_id'])['violations'].sum().reset_index().boxplot('violations')\n",
    "#signaldf.groupby(['year', 'camera_id']).sum().reset_index().boxplot(by='year')\n",
    "\n",
    "#signal_df.groupbyboxplot(column=['SepalLength'], by='Name', ax=ax)\n",
    "ax5 = signal_df[signal_df['year']<2021].groupby(['year', 'camera_id']).sum().reset_index()[['year', 'violations']].boxplot(by='year', vert=False, figsize=[14,6])\n",
    "plt.xlabel('daily violations')\n",
    "plt.ylabel('year')\n",
    "plt.title('Daily Camera Violations by Camera')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Violations per day\n",
    "\n",
    "Make a histogram showing the distribution of total violation accrued each day.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All violations per day\n",
    "signal_df.groupby(['year', 'month', 'day']).sum().reset_index()['violations'].hist(bins=20, figsize=[8,6])\n",
    "plt.title('Citywide Daily Violations Histogram')\n",
    "plt.xlabel('daily violations')\n",
    "plt.show()\n",
    "\n",
    "# Individual camera violations per day\n",
    "signal_df.groupby(['year', 'month', 'day', 'intersection']).sum().reset_index()['violations'].hist(bins=100, figsize=[8,6])\n",
    "plt.title('Individual Camera Daily Violations Histogram', fontsize=14)\n",
    "plt.xlabel('daily violations')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Violations by intersection\n",
    "What does the distribution of violations look like by intersection?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What intersections are the big revenue generators? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top 10 plot\n",
    "df_top10 = signal_df.groupby(['intersection'])['violations'].sum().reset_index()\n",
    "df_top10 = df_top10.sort_values(['violations'], ascending=True).tail(10)\n",
    "ax3 = df_top10.plot.barh(y='violations', x='intersection', figsize=[8,6])\n",
    "\n",
    "ax3.set_title(\"Top 10 Most Violations by Intersection (multiple cameras)\")\n",
    "ax3.set_ylabel('') # do this post plot, you have to talk to y, even in a barh\n",
    "ax3.set_xlabel('violations')\n",
    "ax3.get_legend().remove()\n",
    "\n",
    "xticks = ax3.get_xticks()\n",
    "xticks=['{:,}'.format(int(x)) for x in xticks]\n",
    "print(xticks)\n",
    "ax3.set_xticklabels(xticks)\n",
    "\n",
    "\n",
    "plt.show()# box plot all cameras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic pd info\n",
    "print('All Data')\n",
    "print(signal_df['violations'].describe())\n",
    "\n",
    "print('\\n'*2 + 'Weekday Grouped Violations')\n",
    "print(df_weekday['violations'].describe())\n",
    "\n",
    "print('\\n'*2 + 'Monthly Grouped Violations')\n",
    "print(df_month['violations'].describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Violations mapped\n",
    "What does this look like on a map?  Does it make sense?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "from modules.mb import * \n",
    "import plotly\n",
    "plotly.offline.init_notebook_mode(connected=True)\n",
    "# mb contains token\n",
    "\n",
    "\n",
    "#px.set_mapbox_access_token(open(\".mapbox_token\").read())\n",
    "\n",
    "\n",
    "df_plot = signal_df.groupby(['intersection', 'latitude', 'longitude'], as_index=True)['violations'].sum().reset_index()\n",
    "#print(df_plot.head())\n",
    "df_plot['lat'] = df_plot['latitude'].apply(lambda x: '{:.2f}'.format(x))\n",
    "df_plot['long'] = df_plot['longitude'].apply(lambda x: '{:.2f}'.format(x))\n",
    "\n",
    "\n",
    "\n",
    "# fig = px.scatter_geo(results_df.groupby('camera_id').sum(), locations=\"iso_alpha\",\n",
    "#                      color=\"violations\", # which column to use to set the color of markers\n",
    "#                      #hover_name=\"country\", # column added to hover information\n",
    "#                      size=\"violations\", # size of markers\n",
    "#                      projection=\"natural earth\")\n",
    "\n",
    "#px.scatter_mapbox?\n",
    "fig = px.scatter_mapbox(df_plot, \n",
    "                        lat=\"latitude\", \n",
    "                        lon=\"longitude\", \n",
    "                        color=\"violations\",\n",
    "                        hover_name='intersection',\n",
    "                        size='violations',\n",
    "                        #label=['lat','long','violations'],\n",
    "                        color_continuous_scale='Rainbow', \n",
    "                        #range_color=[range_min, range],\n",
    "                        #center={'lat':41.975605, 'lon': -87.731670},\n",
    "                        zoom=9.5,\n",
    "                        opacity=0.6,\n",
    "                        height=700,\n",
    "                        hover_data={'intersection':False, 'lat':False, 'long':':.2f', 'latitude':False} ,\n",
    "                       )\n",
    "\n",
    "#fig.update_layout(mapbox_style=\"stamen-toner\", height=600) \n",
    "#fig.update_layout (textposition='top left', textfont_size=40)\n",
    "fig.update_layout(mapbox_style=\"open-street-map\", height=800)\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If I set it up with animation, does it add any value?  (year, month, weekday)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "\n",
    "\n",
    "df_plot = signal_df.groupby(['intersection', 'latitude', 'longitude', 'month'])['violations'].sum().reset_index()\n",
    "#weekday_dfs = []\n",
    "#for i in range(7):\n",
    "#    weekday_dfs.append(df_plot = results_df[results_df['weekday']==i])\n",
    "\n",
    "\n",
    "# fig = px.scatter_geo(results_df.groupby('camera_id').sum(), locations=\"iso_alpha\",\n",
    "#                      color=\"violations\", # which column to use to set the color of markers\n",
    "#                      #hover_name=\"country\", # column added to hover information\n",
    "#                      size=\"violations\", # size of markers\n",
    "#                      projection=\"natural earth\")\n",
    "\n",
    "#px.scatter_mapbox?\n",
    "\n",
    "fig = px.scatter_mapbox(df_plot, \n",
    "                        lat=\"latitude\", \n",
    "                        lon=\"longitude\", \n",
    "                        color=\"violations\",\n",
    "                        #text='address',\n",
    "                        animation_frame='month',\n",
    "                        size='violations',\n",
    "                        hover_name='intersection',\n",
    "                        labels=['violations', 'latitude', 'longitude'],\n",
    "                        color_continuous_scale='Rainbow', \n",
    "                        #range_color=[1000, 20000],\n",
    "                        #center={'lat':41.975605, 'lon': -87.731670},\n",
    "                        zoom=9.5,\n",
    "                        opacity=0.7,\n",
    "                        range_color=(0,1.2e4),\n",
    "                        \n",
    "                       )\n",
    "#fig.update_layout(mapbox_style=\"stamen-toner\")\n",
    "fig.update_layout(mapbox_style=\"open-street-map\", height=800)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How about a heat map of total violations to show the areas of most violations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#px.density_mapbox?\n",
    "crash_df['injuries_total'].isna().sum()\n",
    "crash_df = crash_df[crash_df['injuries_total'].notnull()]\n",
    "crash_df['injuries_total'] = crash_df['injuries_total'].astype(int)\n",
    "crash_df[['latitude', 'longitude']] = crash_df[['latitude', 'longitude']].astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crash_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_plot.rename({\"crash_record_id\": \"crashes\"}, axis=1)\n",
    "df_plot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot = crash_df.groupby(['intersection'])[['injuries_total', 'latitude', 'longitude', 'crash_record_id']] \\\n",
    "                        .agg({'latitude':'mean', 'longitude':'mean', 'injuries_total':'sum', 'crash_record_id':'count'}).reset_index()\n",
    "\n",
    "#df_plot = df_plot.rename({\"crash_record_id\": \"crashes\"}, axis=1)\n",
    "\n",
    "fig = px.scatter_mapbox(df_plot, \n",
    "                        lat=\"latitude\", \n",
    "                        lon=\"longitude\", \n",
    "                        color=\"crash_record_id\",\n",
    "                        #text='address',\n",
    "                        size='crash_record_id',\n",
    "                        hover_name='intersection',\n",
    "                        labels=['crash_record_id', 'latitude', 'longitude'],\n",
    "                        color_continuous_scale='Rainbow', \n",
    "                        #range_color=[1000, 20000],\n",
    "                        #center={'lat':41.975605, 'lon': -87.731670},\n",
    "                        zoom=9.5,\n",
    "                        opacity=0.7,\n",
    "                        range_color=(20,120),\n",
    "                        \n",
    "                       )\n",
    "#fig.update_layout(mapbox_style=\"stamen-toner\")\n",
    "fig.update_layout(mapbox_style=\"open-street-map\", height=800)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Active Cameras EDA\n",
    "\n",
    "The number of active cameras affects all of our data.  I do not know how many are operating and when they were in service.\n",
    "For my project, I will be using intersections instead of camera_id as it is not obvious which direction caused an intersection accident.  We will just lump all the cameras in an intersection into one.  Most intersections have 2 cams.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cameras per year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many rlc do we have by year.  Let's find out when they were OFF\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "#print(results_df.groupby(['camera_id', 'year']).count().reset_index())\n",
    "# how many in 2017?\n",
    "year_cams = []\n",
    "for year in range(2017, 2021):\n",
    "    year_cams.append([year, len(signal_df[signal_df['year']==year].groupby('camera_id').count().reset_index())])\n",
    "year_cams = np.array(year_cams)\n",
    "\n",
    "#plt.figure(figsize=[8,5])\n",
    "plt.bar(year_cams[:,0], year_cams[:,1])\n",
    "plt.title(\"Active Cameras by Year\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about if we looked at a more granular level.  Let's go by month.  Look for big swings.\n",
    "\n",
    "#### How does this compare to the number of violations during that time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#signal_df[\"violation_date\"] = pd.to_datetime(signal_df[\"violation_date\"])\n",
    "signal_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# lets look at a closer timeline of n cameras\n",
    "month_cams = []\n",
    "months = 'JanFebMarAprMayJunJulAugSepOctNovDec'\n",
    "for y in range(2017, 2021):\n",
    "    for m in range(1,13):\n",
    "        month_cams.append([months[(m-1)*3:m*3] + \"-\" + str(y),\n",
    "                               len(signal_df[(signal_df['year']==y) & (signal_df['month']==m)]\n",
    "                                .groupby('camera_id')\n",
    "                                .count()\n",
    "                                .reset_index())])\n",
    "month_cams = np.array(month_cams)\n",
    "\n",
    "plt.figure(figsize=[20,8])\n",
    "plt.bar([x for x in range(len(month_cams[:,1]))], month_cams[:,1].astype(np.int))\n",
    "plt.xticks([x for x in range(len(month_cams[:,1]))], month_cams[:,0], rotation=90)\n",
    "\n",
    "plt.title(\"Active Cameras by Month\")\n",
    "plt.ylim(285, 310)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Now do violations per month\n",
    "# lets look at a closer timeline of n cameras\n",
    "month_violations = []\n",
    "months = 'JanFebMarAprMayJunJulAugSepOctNovDec'\n",
    "for y in range(2017, 2021):\n",
    "    for m in range(1,13):\n",
    "        month_violations.append([months[(m-1)*3:m*3] + \"-\" + str(y),\n",
    "                               sum(signal_df[(signal_df['year']==y) & (signal_df['month']==m)]['violations'])])\n",
    "month_violations = np.array(month_violations)\n",
    "\n",
    "plt.figure(figsize=[20,8])\n",
    "plt.bar([x for x in range(len(month_violations[:,1]))], month_violations[:,1].astype(np.int))\n",
    "plt.xticks([x for x in range(len(month_violations[:,1]))], month_violations[:,0], rotation=90)\n",
    "\n",
    "plt.title(\"Violations by Month\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like we had a bunch removed in 2015, but we don't have reliable crash data for that period.\n",
    "In 2016 and 2017 in particular, multiples were added/removed, thats our experiment.  \n",
    "\n",
    "We will use intersection instead of camera_id to group our crashes and violations.\n",
    "\n",
    "Question!!!  What are the start and end dates for each camera??? Probably need to look at each year and catch the start and end date, then label our 50+ cameras for our natural experiment.  We might not have a ton of data to work from.\n",
    "\n",
    "Proposal:  Crashes were not recorded until 2015.  It wasn't fully mandatroy until Sept 2017 which unfortuantely is where the data is reliable.  However, we can go through every camera from 2015 to 2020 and look at the earliest date and latest date we have in the dataset.  That informs us when the camera went live or when it was shut down.  Reporting was by precinct.  The precinct is in the crash data  \n",
    "\n",
    "Note:  In EDA, I see a lot of down time on cameras which will mess us up.  It's probably maintenance/road work/malfunction etc.  Probably need to do a check to see when camera is down.  Maybe just look at consecutive days of zero fines (maybe look as SD along with it).  Consecutive zeros can be chopped out of the dataset, or better yet... just fill in the mean for those dates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crash EDA\n",
    "We are interested in learning more about our crash data.  We will only be looking at crashes that occurred at an intersection.  We have 60k crashes to look at taken from about half million total.\n",
    "\n",
    "I would like to investigate the following:\n",
    "- How do red light intersections compare to all others?\n",
    "- What is the most dangerous type of crash?\n",
    "- What are the primary causes of crashes at red light intersections?\n",
    "- Are cameras placed at most dangerous intersections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crash_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intersection vs all crashes\n",
    "\n",
    "How are intersection crashes different from crashes as a whole?\n",
    "I will divide the data up by type of crash, and look at some macro stats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = pd.read_sql_query(\"SELECT * from all_crashes\", conn)\n",
    "crash_df = pd.read_sql_query(\"SELECT * from signal_crashes\", conn)\n",
    "\n",
    "# crash form filled out by officer (including instructions) can be found\n",
    "# https://idot.illinois.gov/Assets/uploads/files/Transportation-System/Manuals-Guides-&-Handbooks/Safety/Illinois%20Traffic%20Crash%20Report%20SR%201050%20Instruction%20Manual%202019.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many were at traffic signals\n",
    "signal_crash = all_df[all_df['traffic_control_device']=='TRAFFIC SIGNAL']\n",
    "other_df = all_df[(all_df['traffic_control_device']!='TRAFFIC SIGNAL') | (all_df['intersection_related_i']!='Y')]\n",
    "intrel_df = all_df[(all_df['intersection_related_i']=='Y')]\n",
    "df = all_df[(all_df['intersection_related_i']=='Y')&(all_df['traffic_control_device']=='TRAFFIC SIGNAL')]\n",
    "df_rlc = crash_df[crash_df['intersection'].notnull()]\n",
    "\n",
    "# how many crashes are at signals?\n",
    "print('{:<25}{:<15}{:20}'.format('', 'n crash', 'Percent of total'))\n",
    "print('{:<25}{:<15,}{:<20}'.format('All in study', len(all_df), '100.0%'))\n",
    "print('{:<25}{:<15,}{:<4.1f}%'.format('At traffic signal', len(signal_crash), len(signal_crash)/len(all_df)*100))\n",
    "print('{:<25}{:<15,}{:.1f}%'.format('Intersection-related', \n",
    "                                                    len(intrel_df), \n",
    "                                                    len(intrel_df)/len(all_df)*100\n",
    "                                )\n",
    "     )\n",
    "\n",
    "print('{:<25}{:<15,}{:.1f}%'.format('Signal and Intersection', \n",
    "                                                    len(df), \n",
    "                                                    len(df)/len(all_df)*100\n",
    "                                )\n",
    "     )\n",
    "print('{:<25}{:<15,}{:.1f}%'.format('Signal, Int, and Camera', \n",
    "                                                    len(df_rlc), \n",
    "                                                    len(df_rlc)/len(all_df)*100                          )\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**At traffic signal:** can include accidents like hitting parked cars and cyclist hit by doors etc.<br>\n",
    "**Intersection-related:** Intersection is a cause or contributes to accident as determined by on-scene officer.  This includes stop signs and other intersection types (not signals)<br>\n",
    "**Signal and intersection:** Also has a red light intersection.  This filters out stop signs.<br>\n",
    "**Signal, Int and Camera:** Also has a red light cam present.  This is the focus of our project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Types of crashes\n",
    "Now we will survey the types of crashes in our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what kind of crashes occur at traffic light, and how does it compare to other crashes?\n",
    "\n",
    "def crash_stats(all_df, df):\n",
    "    # by percentages\n",
    "    crash_types = df['first_crash_type'].unique()\n",
    "\n",
    "    print_list = []\n",
    "    print('{:30}{:15}{:20}'.format(\"Type of Crash\", 'Total crashes','Percent of total'))\n",
    "    for crash in crash_types:\n",
    "        num_crashes = len(df[df['first_crash_type']==crash])\n",
    "        print_list.append([crash, num_crashes])\n",
    "    \n",
    "    print_list = sorted(print_list, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    for crash, n in print_list: \n",
    "        print('{:30}{:<15d}{:>5.1f}%'.format(crash, n, 100 * n / len(df)))\n",
    "\n",
    "def print_header(message):\n",
    "    print('--'*20)\n",
    "    print(message)\n",
    "    print('--'*20)\n",
    "        \n",
    "def print_crash_stats(all_df, signal_df, other_df, signal_int_df):\n",
    "    '''\n",
    "    all_df Dataframe: all crashes in study \n",
    "    signal_df Dataframe: all signal related crashes\n",
    "    other_df Dataframe: all non-signal related crahses\n",
    "    signal_int_df: both signal and intersection related crashes\n",
    "    '''\n",
    "    print('CRASH STATS')\n",
    "    print('Total crashes in study:', len(all_df))\n",
    "    print('Signal crashes: {:.1f}%'.format((100 * len(signal_df) / len(all_df))))\n",
    "\n",
    "    print_header('ALL CRASHES')\n",
    "    print('Total crashes:', len(other_df))\n",
    "    print()\n",
    "    crash_stats(all_df, other_df)\n",
    "    print('\\n\\n')\n",
    "    \n",
    "    \n",
    "    print_header('CRASHES AT SIGNAL')\n",
    "    print('Total crashes:', len(signal_df))\n",
    "    print()\n",
    "    crash_stats(all_df, signal_df)\n",
    "    print('\\n\\n')\n",
    "\n",
    "    \n",
    "    print_header('CRASHES AT SIGNAL AND INTERSECTION RELATED')\n",
    "    print('Total crashes:', len(signal_int_df))\n",
    "    print()\n",
    "    crash_stats(all_df, signal_int_df)\n",
    "    \n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "print_crash_stats(all_df, signal_crash, other_df, df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rear end and angle crashes are the ones of interest per the Houston study.  Red light cameras are supposed to decrease the number of angled crashes, but may increase rear end."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most dangerous crashes\n",
    "\n",
    "Taken directly from City of Chicago website FAQs https://www.chicago.gov/city/en/depts/cdot/supp_info/red-light_cameraenforcement.html#:~:text=The%20digital%20cameras%20are%20tied,vehicle%2C%20including%20the%20license%20plate.\n",
    "\n",
    "How are red-light camera intersections chosen?\n",
    "\n",
    "The City reviews crash data, paying particular attention to the number of \"right-angle crashes\" at these intersections--indicative of accidents caused when one vehicle runs a red light and strikes another.  Only locations with a high number of right-angle crashes are chosen for red-light cameras.\n",
    "\n",
    "I would like to verify their statement on why they chose the intersections they did.  This also could be the metric we use to verify how well the cams work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mydf in [all_df, signal_crash, other_df, df]:\n",
    "    mydf['injuries_total'].isna().sum()\n",
    "    mydf['injuries_total'].fillna(0, inplace=True) # assume no injuries if left blank\n",
    "\n",
    "    mydf['injuries_fatal'].isna().sum()\n",
    "    mydf['injuries_fatal'].fillna(0, inplace=True) # assume no deaths if left blank\n",
    "\n",
    "    mydf['injuries_total'] = all_df['injuries_total'].astype('int')\n",
    "    mydf['injuries_fatal'] = all_df['injuries_fatal'].astype('int')\n",
    "\n",
    "\n",
    "#all_df.injuries_total.sum()r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what kind of crashes occur at traffic light, and how does it compare to other crashes?\n",
    "\n",
    "def crash_stats2(df):\n",
    "    # by percentages\n",
    "    crash_types = df['first_crash_type'].unique()\n",
    "\n",
    "    print_list = []\n",
    "    \n",
    "    \n",
    "    print()\n",
    "    print('{:30}{:15}{:20}{:20}{:20}{:20}'.format(\"Type of Crash\", 'Total Crashes', 'Injuries', 'Injuries/Crash', 'Deaths', 'Deaths/Crash'))\n",
    "    for crash in crash_types:\n",
    "        num_crashes = len(df[df['first_crash_type']==crash])\n",
    "        num_injuries = df[df['first_crash_type']==crash]['injuries_total'].sum()\n",
    "        num_deaths = df[df['first_crash_type']==crash]['injuries_fatal'].sum()\n",
    "        print_list.append([crash, num_crashes, num_injuries, num_deaths])\n",
    "    \n",
    "    print_list = sorted(print_list, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    \n",
    "\n",
    "    for crash, n, injuries, deaths in print_list: \n",
    "        print('{:30}{:<15d}{:<20}{:<20.2f}{:<20}{:<20.5f}'.format(crash, n, injuries, injuries/n, deaths, deaths/n))\n",
    "    \n",
    "    return print_list\n",
    "\n",
    "def all_stats(message, df):\n",
    "        print('{:30}{:<15d}{:<20}{:<20.2f}{:<20}{:<20.5f}'.format(message, \n",
    "                                                                      len(df), \n",
    "                                                                      df['injuries_total'].sum(), \n",
    "                                                                      df['injuries_total'].sum()/len(df),\n",
    "                                                                      df['injuries_fatal'].sum(), \n",
    "                                                                      df['injuries_fatal'].sum()/len(df)))\n",
    "        \n",
    "\n",
    "def print_crash_stats2(all_df, signal_df, other_df, signal_int_df):\n",
    "    '''\n",
    "    all_df Dataframe: all crashes in study \n",
    "    signal_df Dataframe: all signal related crashes\n",
    "    other_df Dataframe: all non-signal related crahses\n",
    "    signal_int_df: both signal and intersection related crashes\n",
    "    '''\n",
    "    print('CRASH STATS')\n",
    "    print()\n",
    "    \n",
    "   \n",
    "\n",
    "    all_stats('ALL OTHER CRASHES', other_df)\n",
    "    \n",
    "    # First, we print the stats for all crashes\n",
    "    crash_stats2(all_df)\n",
    "    print('\\n\\n')\n",
    "    \n",
    "    print_header('CRASHES AT SIGNAL AND INTERSECTION RELATED')\n",
    "    \n",
    "    \n",
    "    all_stats('ALL SIGNAL & INTERSECTION CRASHES', signal_int_df)\n",
    "\n",
    "    print()\n",
    "    crash_stats2(signal_int_df)\n",
    "    \n",
    "    \n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "print_crash_stats2(all_df, signal_crash, other_df, df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Crashes involving signaled intersections:')\n",
    "print('\\t{:.1%} of all crashes'.format(len(df) / len(all_df)))\n",
    "print('\\t{:.1%} of all injuries'.format(df['injuries_total'].sum() / all_df['injuries_total'].sum()))\n",
    "print('\\t{:.1%} of all deaths'.format(df['injuries_fatal'].sum() / all_df['injuries_fatal'].sum()))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_list = crash_stats2(df)\n",
    "\n",
    "plot_df = pd.DataFrame(plot_list, columns=['type_crash', 'n_crashes', 'injuries', 'deaths'])\n",
    "plot_df['injury_rate'] = plot_df['injuries']/plot_df['n_crashes']\n",
    "plot_df['death_rate'] = plot_df['deaths']/plot_df['n_crashes']\n",
    "plot_df['death_per_injury'] = plot_df['deaths']/plot_df['injuries']\n",
    "\n",
    "print()\n",
    "plot_df[['type_crash','injuries']].sort_values(by='injuries',ascending=True).plot.barh(x='type_crash',\n",
    "                                                                                              y='injuries',\n",
    "                                                                                              figsize=[10,10],\n",
    "                                                                                              title='Red Light Total Injuries by Intersection Crash Type',\n",
    "                                                                                             )\n",
    "\n",
    "\n",
    "plot_df[['type_crash','injury_rate']].sort_values(by='injury_rate',ascending=True).plot.barh(x='type_crash',\n",
    "                                                                                              y='injury_rate',\n",
    "                                                                                              figsize=[10,10],\n",
    "                                                                                              title='Red Light Injury Rate by Intersection Crash Type',\n",
    "                                                                                             )\n",
    "                                                \n",
    "\n",
    "plt.show()\n",
    "plot_df[plot_df['death_rate']>0][['type_crash','death_rate']].sort_values(by='death_rate',ascending=True).plot.barh(x='type_crash',\n",
    "                                                                                            y='death_rate',\n",
    "                                                                                            figsize=[10,6], \n",
    "                                                                                            title='Red Light Death Rate by Intersection Crash Type',\n",
    "                                                                                           )\n",
    "\n",
    "plt.show()\n",
    "plot_df[plot_df['death_rate']>0][['type_crash','death_per_injury']].sort_values(by='death_per_injury',ascending=True).plot.barh(x='type_crash',\n",
    "                                                                                            y='death_per_injury',\n",
    "                                                                                            figsize=[10,6], \n",
    "                                                                                            title='Red Light Death/Injury Rate by Crash Type',\n",
    "                                                                                           )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chicago gov website claims that red light cameras are there to decrease the rate of crashes.\n",
    "Are the red light cams actually at most dangerous intersections?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Camera enabled intersections vs. Others\n",
    "Chicago has 3035 traffic intersections with lights\n",
    "153 have red light cams at them.\n",
    "We would assume these to be the most dangerous intersections in the city.\n",
    "https://www.chicago.gov/city/en/depts/cdot/provdrs/traffic_signals_andstreetlights/svcs/traffic_signals.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get only intersections with total crashes and violations\n",
    "# had to use a windowed query on this one\n",
    "\n",
    "int_crash_violations_df = pd.read_sql_query('''\n",
    "                            WITH cr AS\n",
    "                               (SELECT intersection, \n",
    "                                       COUNT(crash_record_id) as total_crashes,\n",
    "                                       SUM(injuries_total) as total_injuries, \n",
    "                                       SUM(injuries_fatal) as total_deaths\n",
    "                               FROM signal_crashes\n",
    "                               GROUP BY intersection)\n",
    "                            SELECT cr.intersection, total_crashes, SUM(v.violations) as total_violations, cr.total_injuries, cr.total_deaths\n",
    "                            FROM cr\n",
    "                            LEFT JOIN daily_violations v\n",
    "                               ON v.intersection=cr.intersection\n",
    "                            GROUP BY cr.intersection\n",
    "                            ORDER BY total_crashes DESC;\n",
    "                           ''', conn)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_crash_violations_df.head(50)\n",
    "\n",
    "#int_crash_violations_df.total_crashes.sum()\n",
    "\n",
    "\n",
    "total_intersections = 3035\n",
    "total_rlc = len(int_crash_violations_df)-1\n",
    "rlc_accidents = int_crash_violations_df[int_crash_violations_df['intersection'].isna()]['total_crashes'].sum()\n",
    "total_accidents = int_crash_violations_df['total_crashes'].sum()\n",
    "total_deaths = int_crash_violations_df.total_deaths.sum()\n",
    "total_injuries = int_crash_violations_df.total_injuries.sum()\n",
    "other_deaths = int_crash_violations_df[int_crash_violations_df['intersection'].isna()]['total_deaths'].sum()\n",
    "other_injuries = int_crash_violations_df[int_crash_violations_df['intersection'].isna()]['total_injuries'].sum()\n",
    "#print(rlc_accidents, total_accidents)\n",
    "\n",
    "print('No red light cam intersections:')\n",
    "print('{:.2%} of all red light intersections'.format(1 - total_rlc/total_intersections))\n",
    "print('{:.2%} of all red light accidents'.format(rlc_accidents/total_accidents))\n",
    "print('{:.2%} of all red light deaths'.format(other_deaths/total_deaths))\n",
    "print('{:.2%} of all red light injuries'.format(other_injuries/total_injuries))\n",
    "print('Deaths: {}  Injuries: {}'.format(other_deaths, other_injuries))\n",
    "\n",
    "\n",
    "print()\n",
    "print('Red light cam intersections:')\n",
    "print('{:.2%} of all red light intersections'.format(total_rlc/total_intersections))\n",
    "print('{:.2%} of all red light accidents'.format(1 - rlc_accidents/total_accidents))\n",
    "print('{:.2%} of all red light deaths'.format(1-other_deaths/total_deaths))\n",
    "print('{:.2%} of all red light injuries'.format(1 - other_injuries/total_injuries))\n",
    "print('Deaths: {} Injuries: {}'.format(total_deaths-other_deaths, total_injuries-other_injuries))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Red light cameras exist at intersections that are more dangerous, or perhaps at least more used than typical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crash/Injury/Deaths by Crash Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_crash = pd.read_sql_query('''\n",
    "                            WITH cr AS\n",
    "                               (SELECT first_crash_type as crash_type,\n",
    "                                       SUM(injuries_total) as total_injuries, \n",
    "                                       SUM(injuries_fatal) as total_deaths,\n",
    "                                       COUNT(crash_record_id) as total_crashes\n",
    "                               FROM signal_crashes\n",
    "                               GROUP BY first_crash_type)\n",
    "                            SELECT cr.crash_type, cr.total_crashes, cr.total_injuries, cr.total_deaths\n",
    "                            FROM cr\n",
    "                            GROUP BY cr.crash_type\n",
    "                            ORDER BY cr.total_crashes DESC;\n",
    "                           ''', conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USING MINMAX SCALING TO COMPARE\n",
    "type_crash['total_injuries'] = type_crash['total_injuries']/type_crash.total_injuries.sum()\n",
    "type_crash['total_deaths'] = type_crash['total_deaths']/type_crash.total_deaths.sum()\n",
    "type_crash['total_crashes'] = type_crash['total_crashes']/type_crash.total_crashes.sum()\n",
    "\n",
    "# Remove any crash type with no deaths\n",
    "plot_me = type_crash[type_crash['total_deaths'] > 0]\n",
    "\n",
    "\n",
    "plot_me.sort_values(by='total_injuries',ascending=True).plot.barh(x='crash_type', \n",
    "                                                                     figsize=[12,6], \n",
    "                                                                     title='Scaled Crash Data', \n",
    "                                                                      width=0.65,\n",
    "                                                                  color=['limegreen', 'gold', 'coral'],\n",
    "                                                                    )\n",
    "plt.ylabel('')\n",
    "plt.tight_layout()\n",
    "plt.savefig('images/scaled_crash_data.png')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most dangerous intersections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRY4. Getting there\n",
    "# learned that you only need one with statement (don't forget a comma between windows)\n",
    "cams_interest = pd.read_sql_query('''\n",
    "                                    WITH v as\n",
    "                                        (SELECT intersection,\n",
    "                                                sum(violations) as violations\n",
    "                                        FROM daily_violations\n",
    "                                        GROUP BY intersection\n",
    "                                        ),\n",
    "                                    cr as\n",
    "                                        (SELECT intersection,\n",
    "                                                COUNT(crash_record_id) as n_crash,\n",
    "                                                SUM(injuries_total) as injuries,\n",
    "                                                SUM(injuries_fatal) as deaths\n",
    "                                         FROM signal_crashes\n",
    "                                         GROUP BY intersection\n",
    "                                         ORDER BY intersection\n",
    "                                         )\n",
    "                                    SELECT v.intersection, v.violations, cr.n_crash, cr.injuries, cr.deaths\n",
    "                                    FROM v\n",
    "                                    LEFT JOIN cr\n",
    "                                        ON cr.intersection=v.intersection\n",
    "                                    GROUP BY v.intersection\n",
    "                                         \n",
    "                                    ''', conn)\n",
    "\n",
    "                          \n",
    "                                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Now we have every camera with every intersection with every startend\n",
    "# We need to add in \n",
    "\n",
    "# cams_interest['start'] = pd.to_datetime(cams_interest.start)\n",
    "# cams_interest['end'] = pd.to_datetime(cams_interest.end)\n",
    "\n",
    "cams_interest.info()\n",
    "cams_interest.head()\n",
    "\n",
    "# most dangerous intersections\n",
    "df_plot = cams_interest[cams_interest['intersection'].notnull()]\n",
    "df_plot['injuries_per_crash'] = df_plot['injuries'] / df_plot['n_crash']\n",
    "df_plot['violations'] = df_plot['violations'] / df_plot['violations'].sum()\n",
    "\n",
    "#df_plot['n_crash'] = df_plot['n_crash'] / df_plot['n_crash'].sum()\n",
    "#df_plot['injuries'] = df_plot['injuries'] / df_plot['injuries'].sum()\n",
    "#df_plot['deaths'] = df_plot['deaths'] / df_plot['deaths'].sum()\n",
    "\n",
    "\n",
    "df_plot[['intersection', 'n_crash']].sort_values(by='n_crash',ascending=False).plot.barh(x='intersection', \n",
    "                                                                     figsize=[20,70], \n",
    "                                                                     title='Most Dangerous Red Light Intersections (Total)', \n",
    "                                                                     width=0.65\n",
    "                                                                    )\n",
    "\n",
    "df_plot[['intersection', 'injuries_per_crash']].sort_values(by='injuries_per_crash',ascending=False).plot.barh(x='intersection', \n",
    "                                                                     figsize=[20,70], \n",
    "                                                                     title='Most Dangerous Red Light Intersections (Scaled Percentage)', \n",
    "                                                                     width=0.65\n",
    "                                                                    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cams_interest.deaths.sum())  # it matches previous result.  This is all deaths though.\n",
    "print(cams_interest.injuries.sum()) # 3041 total injuries from rlc\n",
    "print(cams_interest.n_crash.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_fetch_tables(c, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crashes by day of week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_of_week = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "\n",
    "print(crash_df.columns)\n",
    "print(day_of_week)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "crash_df['crashes'] = crash_df['crash_record_id'].notnull().astype(int)\n",
    "\n",
    "crash_df[['weekday', 'crashes']].groupby('weekday').count().reset_index().plot.bar(title='Crashes by day of week', \n",
    "                                                                                   rot=45,\n",
    "                                                                                   ax=ax,\n",
    "                                                                                   color='C0' # default color\n",
    "                                                                                  )\n",
    "ax.set_ylim(0, 12000)\n",
    "ax.set_xticklabels(day_of_week)\n",
    "ax.get_legend().remove()\n",
    "fig.tight_layout()\n",
    "plt.savefig('images/crash_vs_weekday.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total Crashes by Month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_of_year = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', \n",
    "                 'September', 'October', 'November', 'December']\n",
    "\n",
    "print(crash_df.columns)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "crash_df[(crash_df['year'] > 2017)&(crash_df['year'] < 2020)][['month', 'crashes']].groupby('month').sum().plot.bar(title='Crashes by month (2018-2019)', rot=90, ax=ax)\n",
    "ax.set_ylim(0, 3000)\n",
    "ax.set_xticklabels(month_of_year)\n",
    "ax.set_ylabel('crashes')\n",
    "ax.get_legend().remove()\n",
    "fig.tight_layout()\n",
    "fig.savefig('images/crashes_vs_month.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crashes by year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(crash_df.columns)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "crash_df[(crash_df['year']<2021)][['year', 'crashes']].groupby('year').sum().reset_index().plot.bar(x='year', \n",
    "                                                                                                    y='crashes', \n",
    "                                                                                                    title='Crashes by year', \n",
    "                                                                                                    rot=45, \n",
    "                                                                                                    ax=ax)\n",
    "#ax.set_ylim(0, 6000)\n",
    "ax.set_ylabel('crashes')\n",
    "ax.get_legend().remove()\n",
    "fig.tight_layout()\n",
    "\n",
    "fig.savefig('images/crash_vs_year.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crash reporting was not mandatory for all precincts until Sept 01, 2017.  Some crashes likely missing early in year.  2020 is low for COVID-19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crash_df['injuries_total'] = crash_df['injuries_total'].fillna(0).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "plotme = crash_df[['weekday', 'hour', 'crashes']].groupby(['weekday','hour']).sum().reset_index()\n",
    "plotme['day-time'] = plotme.apply(lambda x: float(x.weekday) + float(x.hour)/24, axis=1)\n",
    "fig = px.bar(plotme, x='day-time', y='crashes', title='Crashes by Hour of Week')\n",
    "\n",
    "\n",
    "\n",
    "myticks = []\n",
    "for day in day_of_week:\n",
    "    for hour in ['12AM', '6AM', '12PM', '6PM']:\n",
    "        myticks.append(day[:3] + '-' + hour)\n",
    "\n",
    "myvals = []\n",
    "for i in range(len(day_of_week)):\n",
    "    for j in [0, 0.25, 0.5, 0.75]:\n",
    "        myvals.append(i+j)\n",
    "        \n",
    "fig.update_layout(\n",
    "    xaxis = dict(\n",
    "        tickmode = 'array',\n",
    "        #tick0 = 0,\n",
    "        dtick = 1/4,\n",
    "        tickvals = myvals,\n",
    "        ticktext = myticks,\n",
    "    ),\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "\n",
    "plotme = crash_df[['weekday', 'hour', 'injuries_total']].groupby(['weekday','hour']).sum().reset_index()\n",
    "plotme['day-time'] = plotme.apply(lambda x: float(x.weekday) + float(x.hour)/24, axis=1)\n",
    "fig = px.bar(plotme, x='day-time', y='injuries_total', title='Injuries by Hour of Week')\n",
    "\n",
    "        \n",
    "fig.update_layout(\n",
    "    xaxis = dict(\n",
    "        tickmode = 'array',\n",
    "        #tick0 = 0,\n",
    "        dtick = 1/4,\n",
    "        tickvals = myvals,\n",
    "        ticktext = myticks,\n",
    "    ),\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "\n",
    "# ax = crash_df[['weekday', 'hour', 'crashes']].groupby(['weekday','hour']).sum().plot.bar(figsize=[20,6])\n",
    "# ax.set_title('Crashes by Hour')\n",
    "# ax.set_ylabel('Crashes')\n",
    "#ax.set_ylim(20, 30)\n",
    "\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weather EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wx_daily.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wx_vio = pd.merge(wx_daily, signal_df, how='left', on=['year', 'month', 'day'])\n",
    "wx_vio = wx_vio[wx_vio['year'] < 2021]\n",
    "wx_vio = wx_vio[wx_vio['temp'].notna()]\n",
    "\n",
    "wx_vio['temp'] = wx_vio['temp'].apply(lambda x: (x-273.15)*9/5 + 32)\n",
    "wx_vio['temp'] = wx_vio['temp'].astype(float)\n",
    "\n",
    "wx_cr = pd.merge(wx_daily, crash_df, how='left', on=['year', 'month', 'day'])\n",
    "wx_cr = wx_cr[wx_cr['year'] < 2021]\n",
    "wx_cr = wx_cr[wx_cr['temp'].notna()]\n",
    "wx_cr['temp'] = wx_cr['temp'].apply(lambda x: (x-273.15)*9/5 + 32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temperature and violations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_grouped = wx_vio[['violation_date', 'temp', 'violations']].groupby('violation_date') \\\n",
    "                                                            .agg({'temp':'max', 'violations':'sum'}) \\\n",
    "                                                            .reset_index()\n",
    "plt.figure(figsize=[8,8])\n",
    "sns.lmplot(data=temp_grouped, x='temp', y='violations', size=6, scatter_kws={\"s\": 10}, line_kws={'lw':2, 'color': 'red'})\n",
    "plt.title('Daily Red Light Camera Violations vs Temperature')\n",
    "plt.xlabel(\"Temp (F)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precipitation and Violations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precip_grouped = wx_vio[['violation_date', 'precip', 'violations']].groupby('violation_date') \\\n",
    "                                                            .agg({'precip':'max', 'violations':'sum'}) \\\n",
    "                                                            .reset_index()\n",
    "plt.figure(figsize=[8,8])\n",
    "sns.lmplot(data=precip_grouped, x='precip', y='violations', size=6, scatter_kws={\"s\": 10}, line_kws={'lw':2, 'color': 'red'})\n",
    "plt.title('Daily Red Light Camera Violations vs Precipitation')\n",
    "plt.xlabel(\"Precipitation (mm)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temperature vs. Crashes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wx_cr_grouped = wx_cr[['crash_record_id', 'precip', 'snow_1h', 'temp', 'year', 'month', 'day']] \\\n",
    "                    .groupby(['year', 'month', 'day']) \\\n",
    "                    .agg({'crash_record_id':'count', 'precip':'sum', 'temp':'max', 'snow_1h':'sum'}) \\\n",
    "                    .reset_index()\n",
    "wx_cr_grouped['n_crash'] = wx_cr_grouped['crash_record_id']\n",
    "wx_cr_grouped = wx_cr_grouped[wx_cr_grouped['n_crash']>0]\n",
    "\n",
    "\n",
    "\n",
    "# now do crashes\n",
    "plt.figure(figsize=[8,8])\n",
    "sns.lmplot(data=wx_cr_grouped, \n",
    "           x='temp', \n",
    "           y='n_crash', \n",
    "           scatter_kws={\"s\": 10}, \n",
    "           line_kws={'lw':2, 'color': 'red'})\n",
    "plt.title('Daily Red Light Camera Crashes vs Temperature')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of violations clearly increases with the temperature, but crashes do not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precip and Crashes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now do precip\n",
    "plt.figure(figsize=[10,8])\n",
    "sns.lmplot(data=wx_cr_grouped, \n",
    "           x='precip', \n",
    "           y='n_crash', \n",
    "           scatter_kws={\"s\": 20}, \n",
    "           line_kws={'lw':2, 'color': 'red'})\n",
    "plt.title('Daily Red Light Intersection Crashes vs Precip', fontsize=14)\n",
    "plt.xlabel('Precip (mm)')\n",
    "plt.xlim(0, 5000)\n",
    "\n",
    "plt.savefig('images/crash_vs_precip.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now do precip\n",
    "wx_cr_grouped['snow_1h'] = wx_cr_grouped['snow_1h'].fillna(0)\n",
    "plt.figure(figsize=[10,8])\n",
    "sns.lmplot(data=wx_cr_grouped, \n",
    "           x='snow_1h', \n",
    "           y='n_crash', \n",
    "           scatter_kws={\"s\": 20}, \n",
    "           line_kws={'lw':2, 'color': 'red'})\n",
    "plt.title('Daily Red Light Intersection Crashes vs Snowfall', fontsize=14)\n",
    "plt.xlim(0, 1000)\n",
    "\n",
    "plt.xlabel('Precip (mm)')\n",
    "plt.savefig('images/crash_vs_snow.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Congestion EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "congestion_df = pd.read_sql_query('''SELECT * \n",
    "                                  FROM hourly_congestion\n",
    "                                  WHERE year > 2016\n",
    "                                  ''', conn)\n",
    "\n",
    "wx_df = pd.read_sql_query('''SELECT * FROM hourly_weather WHERE year > 2016''', conn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Total potential wx entries:', len(weather_df) * 29)  # if every weather entry had every region\n",
    "print('Total congestion entries:', len(congestion_df))\n",
    "print()\n",
    "\n",
    "for year in range(2015, 2021):\n",
    "    print(year, 'traffic entries:', len(congestion_df[congestion_df['year']==year]))\n",
    "    print(year, 'weather entries:', len(wx_df[wx_df['year']==year]) * 29)\n",
    "    print()\n",
    "    \n",
    "\n",
    "# we have more wx data than congestion.  Consider dropping 2015?\n",
    "# it makes sense to have slightly more weather entries.  \n",
    "# Not all regions have buses running 24/7.  Could also have missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up congestion to fill in the missing overnight data with mean\n",
    "congestion_df.speed.isna().sum()\n",
    "\n",
    "print('Congestion rows with speed of zero: {:.2f}%'.format(congestion_df[congestion_df['speed']==0].count()[0] / len(congestion_df) * 100))\n",
    "\n",
    "\n",
    "\n",
    "def speed_fix(speed, hour):\n",
    "    # there is no significant congestion before 5am in Chicago.\n",
    "    # there are however a significant amount of buses sitting still before starting routes\n",
    "    if speed < 20 and 0 < hour < 5 or speed > 50:\n",
    "        return 28\n",
    "    else:\n",
    "        return speed\n",
    "\n",
    "#congestion_df.speed.replace(0, congestion_df.speed.mean(), inplace=True)\n",
    "# takes a few minutes to fix the speed discrepancy  \n",
    "\n",
    "############### MOVE ME TO PREPROCESSING  ######################\n",
    "congestion_df['speed'] = congestion_df.apply(lambda x: speed_fix(x.speed, x.hour), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "congestion_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Congestion vs Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "congestion_df['congestion'] = 100 - congestion_df['quantile_speed']\n",
    "hourly_congestion = congestion_df.drop(['region_id'], axis=1).groupby(['year', 'month', 'day', 'hour', 'weekday']).agg({'bus_count':'sum', 'num_reads':'sum', 'speed':np.mean, 'congestion':np.mean}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(month_of_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "day_of_week = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "\n",
    "fig1, ax1 = plt.subplots(figsize=[8, 6])\n",
    "hourly_congestion[['weekday', 'congestion']].groupby('weekday').mean().plot.bar(legend=False, ax=ax1)\n",
    "ax1.set_title('Congestion by Weekday')\n",
    "ax1.set_ylabel('Bus Speed')\n",
    "ax1.set_xticklabels(day_of_week)\n",
    "fig1.tight_layout()\n",
    "fig1.savefig('images/congestion_vs_weekday')\n",
    "plt.show()\n",
    "\n",
    "fig2, ax2 = plt.subplots(figsize=[8,6])\n",
    "hourly_congestion[['hour', 'congestion']].groupby(['hour']).mean().plot.bar(legend=False, ax=ax2)\n",
    "ax2.set_title('Congestion by Hour')\n",
    "ax2.set_ylabel('Congestion')\n",
    "fig2.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# # ax = hourly_congestion[['weekday', 'hour', 'speed']].groupby(['weekday','hour']).mean().plot.bar(figsize=[20,6])\n",
    "# # ax.set_title('Traffic Speed by Hour')\n",
    "# # ax.set_ylabel('Bus Speed')\n",
    "# # ax.set_ylim(20, 30)\n",
    "# # plt.show()\n",
    "\n",
    "# fig, ax3 = plt.subplots(figsize=[8,8])\n",
    "# hourly_congestion[['month', 'congestion']].groupby('month').mean().reset_index().plot.bar(ax=ax3, x='month', y='congestion', legend=False)\n",
    "# ax3.set_title('Congestion by Month')\n",
    "# ax3.set_ylabel('Congestion')\n",
    "# xlabels = ax3.get_xticks().tolist()\n",
    "# plt.xticks(xlabels, month_of_year, rotation='vertical')\n",
    "# fig.tight_layout()\n",
    "# fig.savefig('images/congestion_vs_month.png')\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# ax4 = hourly_congestion[['year', 'congestion']].groupby('year').mean().plot.bar(legend=False)\n",
    "# ax4.set_title('Congestion by Year')\n",
    "# ax4.set_ylabel('Congestion')\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# plotme = hourly_congestion[['weekday', 'hour', 'congestion']].groupby(['weekday','hour']).mean().reset_index()\n",
    "# plotme['day-time'] = plotme.apply(lambda x: float(x.weekday) + float(x.hour)/24, axis=1)\n",
    "# fig = px.bar(plotme, x='day-time', y='congestion', title='Congestion by Hour of Week')\n",
    "# #fig.ylabel('congestion (scaled)')\n",
    "        \n",
    "# fig.update_layout(\n",
    "#     xaxis = dict(\n",
    "#         tickmode = 'array',\n",
    "#         #tick0 = 0,\n",
    "#         dtick = 1/4,\n",
    "#         tickvals = myvals,\n",
    "#         ticktext = myticks,\n",
    "#     ),\n",
    "# )\n",
    "\n",
    "\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Holidays could be a consideration.  Look at Nov/Dec."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_congestion = congestion_df.groupby(['region_id']).agg({'speed':np.mean}).reset_index()\n",
    "\n",
    "# add region name\n",
    "region_congestion['region'] = region_congestion['region_id'].apply(lambda x: regions_df[regions_df['region_id']==x]['region'].max())\n",
    "\n",
    "\n",
    "ax = region_congestion.sort_values('speed', ascending=False).plot.barh('region', figsize=[8, 12])\n",
    "ax.set_xlabel('Speed (mph)', fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the mean speed by region, we see that we have to account for region if we use congestion. \n",
    "We will probably have to scale it by region so we can fairly compare and use congestion/speed in our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Congestion vs. Crashes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_cr = congestion_df.merge(crash_df, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_cr['congestion'] = 100 - con_cr['quantile_speed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_cr_daily = con_cr[['year', 'month', 'day', 'hour', 'congestion', 'speed', 'crash_record_id']] \\\n",
    "            .groupby(['year', 'month', 'day']) \\\n",
    "            .agg({'speed':'min', 'congestion':'max', 'crash_record_id':'count'}).reset_index()\n",
    "\n",
    "con_cr_daily['n_crash'] = con_cr_daily['crash_record_id']\n",
    "con_cr_daily['congestion'] = (con_cr_daily.speed.max() - con_cr_daily['speed']) / con_cr_daily.speed.max()\n",
    "\n",
    "sns.lmplot(data=con_cr_daily, x='congestion', y='n_crash',\n",
    "               scatter_kws={\"s\": 10}, \n",
    "               line_kws={'lw':2, 'color': 'red'},\n",
    "               height=6,\n",
    "               aspect=1.5\n",
    "              )\n",
    "\n",
    "# need to plot congestion bins with total crashes in each\n",
    "\n",
    "#con_cr_daily['congestion'] = con_cr_daily['congestion'] % 20 * 5\n",
    "#sns.distplot(con_cr_daily.congestion, kde=False)\n",
    "\n",
    "\n",
    "plt.xlabel('Peak Congestion (scaled)')\n",
    "plt.ylabel('n Crashes')\n",
    "plt.title('Daily Crashes vs. Peak Congestion')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Red light camera status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_fetch_tables(c, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from dateutil import parser\n",
    "\n",
    "int_startend = pd.read_sql_query(\"SELECT * FROM int_startend\", conn)\n",
    "int_startend['start'] = pd.to_datetime(int_startend['start'])\n",
    "int_startend['end'] = pd.to_datetime(int_startend['end'])\n",
    "\n",
    "\n",
    "start = int_startend['start'].min()\n",
    "end = int_startend['end'].max()\n",
    "x = np.arange(start, end, dtype='datetime64[D]')\n",
    "int_startend.sort_values(by=['start', 'end'], ascending=[True, False], inplace=True)\n",
    "my_start_date = '2017-09-01'  # can also use '2017-09-01' for reporting requirment\n",
    "\n",
    "# plot and grab ids for all cams that were installed during timeframe 2017 through current that edned or started\n",
    "# during the same time\n",
    "plt.figure(figsize=[12,8])\n",
    "ints_of_interest = []\n",
    "for i in range(len(int_startend)):\n",
    "    intersect = int_startend.iloc[i]\n",
    "    if (intersect['start'] > parser.parse(my_start_date) or parser.parse(my_start_date) < intersect['end'] < parser.parse('2020-12-31')):\n",
    "        #print(cam[1], \"PARSED\", parser.parse('2015-04-01'))\n",
    "        ints_of_interest.append(intersect['intersection'])\n",
    "        plt.plot([intersect[1], intersect[2]], [intersect[0], intersect[0]], linewidth=10, linestyle='-', color='red')  \n",
    "\n",
    "\n",
    "reporting = parser.parse('2017-08-01')\n",
    "plt.title('Intersections of Interest')\n",
    "plt.xlabel('Camera Operational Dates')\n",
    "plt.axvline(x=reporting, linestyle='--', linewidth=2)\n",
    "plt.annotate('Mandatory crash reporting', xy=[reporting, 3], rotation=270)\n",
    "plt.xlim(parser.parse('2016-12-31'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Camera status vs crashes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def table_info(c, conn):\n",
    "    '''\n",
    "    prints out all of the columns of every table in db\n",
    "    c : cursor object\n",
    "    conn : database connection object\n",
    "    '''\n",
    "    tables = c.execute(\"SELECT name FROM sqlite_master WHERE type='table';\").fetchall()\n",
    "    for table_name in tables:\n",
    "        table_name = table_name[0]\n",
    "        table = pd.read_sql_query(\"SELECT * from {} LIMIT 0\".format(table_name), conn)\n",
    "        print(table_name)\n",
    "        for col in table.columns:\n",
    "            print('\\t-' + col)\n",
    "        print()\n",
    "table_info(c, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_rlc_cr = pd.read_sql_query('''\n",
    "WITH ah AS(\n",
    "        SELECT *\n",
    "        FROM all_hours\n",
    "        ),\n",
    "         \n",
    "    cr AS(\n",
    "        SELECT year,\n",
    "                month,\n",
    "                day,\n",
    "                hour,\n",
    "                intersection,\n",
    "                injuries_total,\n",
    "                injuries_fatal,\n",
    "                crash_record_id,\n",
    "                first_crash_type,\n",
    "                (first_crash_type == 'REAR END') as rear_end,\n",
    "                (first_crash_type == 'TURNING') as turning,\n",
    "                (first_crash_type == 'ANGLE') as angle\n",
    "        FROM signal_crashes\n",
    "        )\n",
    "        \n",
    "        \n",
    "SELECT ah.*,\n",
    "    SUM(cr.injuries_total) as injuries_total,\n",
    "    COUNT(cr.crash_record_id) as n_crash,\n",
    "    SUM(cr.injuries_fatal) as injuries_fatal,\n",
    "    cr.first_crash_type,\n",
    "    SUM(cr.rear_end) as rear_end,\n",
    "    SUM(cr.angle) as angle,\n",
    "    SUM(cr.turning) as turning\n",
    "    \n",
    "FROM ah\n",
    "\n",
    "LEFT JOIN cr\n",
    "    ON cr.year = ah.year\n",
    "    AND cr.month = ah.month\n",
    "    AND cr.day = ah.day\n",
    "    AND cr.hour = ah.hour\n",
    "    AND cr.intersection = ah.intersection   \n",
    "       \n",
    "WHERE ah.date >= \\'2017-09-01\\'\n",
    "  \n",
    "GROUP BY ah.year, ah.month, ah.day, ah.hour, ah.intersection\n",
    "ORDER BY ah.year, ah.month, ah.day, ah.hour, ah.intersection\n",
    "''', conn)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_rlc_cr.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_rlc_cr.first_crash_type.unique()\n",
    "int_rlc_cr['rear_end'].fillna(0, inplace=True)\n",
    "int_rlc_cr['angle'].fillna(0, inplace=True)\n",
    "int_rlc_cr['turning'].fillna(0, inplace=True)\n",
    "int_rlc_cr['injuries_total'].fillna(0, inplace=True)\n",
    "int_rlc_cr['injuries_fatal'].fillna(0, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_rlc_cr.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cam status stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percent_change(df, col, text):\n",
    "    year_hours = 365.25 * 24\n",
    "    on_mean = df[df['rlc_state']==1][col].mean() * year_hours\n",
    "    off_mean = df[df['rlc_state']==0][col].mean() * year_hours\n",
    "    \n",
    "    if off_mean < 0.1:\n",
    "        print('Mean {}/year (cam off): {:.5f}\\nMean {}/year (cam on): {:.5f}'.format(text, off_mean, text, on_mean))\n",
    "    else:\n",
    "        print('Mean {}/year (cam off): {:.2f}\\nMean {}/year (cam on): {:.2f}'.format(text, off_mean, text, on_mean))\n",
    "    \n",
    "    pct_change = (on_mean - off_mean) / off_mean\n",
    "    print('Change (cam on): {:.2%}\\n'.format(pct_change))\n",
    "\n",
    "    \n",
    "\n",
    "print('Percent of data with cams off: {:.2%}\\n'.format(len(int_rlc_cr[int_rlc_cr['rlc_state']==0])/len(int_rlc_cr)))\n",
    "\n",
    "n_on = int_rlc_cr[int_rlc_cr['rlc_state']==1].n_crash.sum()\n",
    "n_off = int_rlc_cr[int_rlc_cr['rlc_state']==0].n_crash.sum()\n",
    "\n",
    "print('Total accidents with cams on: {}'.format(n_on))\n",
    "print('Total accidents with cams off: {}'.format(n_off))\n",
    "\n",
    "print()   \n",
    "percent_change(int_rlc_cr, 'n_crash', 'crash')\n",
    "percent_change(int_rlc_cr, 'injuries_total', 'injuries')\n",
    "percent_change(int_rlc_cr, 'injuries_fatal', 'deaths')\n",
    "\n",
    "percent_change(int_rlc_cr, 'rear_end', 'rear end accidents')\n",
    "percent_change(int_rlc_cr, 'turning', 'turning accidents')\n",
    "percent_change(int_rlc_cr, 'angle', 'angle accidents')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple crash stats by accident type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create my db\n",
    "crash_df = pd.read_sql_query('''\n",
    "WITH v AS(SELECT dv.intersection,\n",
    "                SUM(dv.violations) as violations,\n",
    "                (CASE\n",
    "                      WHEN JulianDay(se.start) <= JulianDay('2017-09-01 00:00:00')\n",
    "                      AND JulianDay(se.end) > JulianDay('2020-12-31 00:00:00')\n",
    "                          THEN CAST(JulianDay('2020-12-31 00:00:00') - JulianDay('2017-09-01 00:00:00') as Integer)\n",
    "                      \n",
    "                      WHEN JulianDay(se.start) > JulianDay('2017-09-01 00:00:00')\n",
    "                      AND JulianDay(se.end) > JulianDay('2020-12-31 00:00:00')\n",
    "                          THEN CAST (JulianDay('2020-12-31 00:00:00') - JulianDay(se.start) as Integer)\n",
    "                      \n",
    "                      WHEN JulianDay(se.start) > JulianDay('2017-09-01 00:00:00')\n",
    "                      AND JulianDay(se.end) <= JulianDay('2020-12-31 00:00:00')\n",
    "                          THEN CAST ((se.end) - JulianDay(se.start) as Integer)\n",
    "                    \n",
    "                      ELSE CAST (JulianDay(se.end) - JulianDay('2017-09-01 00:00:00') as Integer)\n",
    "                END) AS days_active,\n",
    "                COUNT(DISTINCT dv.camera_id) as n_cams,\n",
    "                start,\n",
    "                end,\n",
    "                day,\n",
    "                dv.month,\n",
    "                dv.year,\n",
    "                dv.intersection\n",
    "\n",
    "        FROM daily_violations as dv\n",
    "        LEFT JOIN int_startend as se\n",
    "            ON se.intersection = dv.intersection\n",
    "\n",
    "        GROUP BY dv.year, dv.month, dv.day, dv.intersection\n",
    "        ), \n",
    "\n",
    "    ic AS(SELECT *\n",
    "         FROM intersection_chars\n",
    "        ),\n",
    "\n",
    "    cr AS(SELECT *   \n",
    "         FROM signal_crashes\n",
    "         GROUP BY year, month, day, intersection\n",
    "        ),\n",
    "    \n",
    "    ah AS(SELECT * FROM all_hours GROUP BY year, month, day, intersection),\n",
    "    \n",
    "    rg AS(SELECT region_id, intersection\n",
    "        FROM intersection_cams\n",
    "        GROUP BY intersection)\n",
    "\n",
    "SELECT \n",
    "    (CAST(365 * SUM(cr.injuries_total) AS FLOAT) / 1217) as injuries_per_year,\n",
    "    (CAST(365 * COUNT(cr.crash_record_id) AS FLOAT)/ 1217) as crash_per_year,\n",
    "    ( (CAST(365 * COUNT(cr.crash_record_id) AS FLOAT)/ 1217) +\n",
    "      (CAST(365 * SUM(cr.injuries_total) AS FLOAT) / 1217) +\n",
    "      (CAST(365 * SUM(cr.injuries_incapacitating) AS FLOAT) / 1217)) AS danger_metric,\n",
    "\n",
    "    (CAST(v.days_active AS FLOAT) / 1217) AS active_cam,\n",
    "    \n",
    "    (CAST((ic.daily_traffic/ic.total_lanes) AS FLOAT)) as traffic_per_lane,\n",
    "    ic.protected_turn/ic.way as protected_ratio,\n",
    "\n",
    "    (ic.exit + ic.triangle + ic.angled + ic.one_way + ic.underpass) as complexity,\n",
    "\n",
    "    ic.*,\n",
    "    \n",
    "    v.n_cams,\n",
    "    (CAST(365 * SUM(v.violations) AS FLOAT) / v.days_active) as violations_per_year,\n",
    "    COUNT(crash_record_id) as n_crash,\n",
    "    SUM(injuries_total) as injuries_total,\n",
    "    SUM(injuries_fatal) as injuries_fatal,\n",
    "    SUM(injuries_non_incapacitating) as injuries_non_incapacitating,\n",
    "    v.days_active,\n",
    "    (CAST(ic.total_lanes AS FLOAT)/ic.way) AS lanes_per_direction,  \n",
    "    \n",
    "    rg.region_id\n",
    "\n",
    "FROM ah\n",
    "LEFT JOIN v\n",
    "    ON v.year = ah.year\n",
    "    AND v.month = ah.month\n",
    "    AND v.day = ah.day\n",
    "    AND v.intersection = ah.intersection\n",
    "LEFT JOIN cr\n",
    "    ON cr.year = ah.year\n",
    "    AND cr.month = ah.month\n",
    "    AND cr.day = ah.day\n",
    "    AND cr.intersection = ah.intersection\n",
    "LEFT JOIN ic\n",
    "    ON ah.intersection = ic.intersection\n",
    "LEFT JOIN rg\n",
    "    ON ah.intersection = rg.intersection\n",
    "WHERE cr.crash_date >= \\'2017-09-01\\' AND cr.crash_date <= \\'2020-12-31\\'\n",
    "GROUP BY ic.intersection\n",
    "ORDER BY ic.intersection\n",
    "                                    ''', conn)\n",
    "\n",
    "crash_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# increased crashes by type\n",
    "\n",
    "# Exits\n",
    "print('\\nExited Intersections')\n",
    "print('n intersections: {}'.format(crash_df[crash_df['exit']==1]['crash_per_year'].count()))\n",
    "print('Crashes/yr: {:.1f}'.format(crash_df[crash_df['exit']==1]['crash_per_year'].mean()))\n",
    "print('Crash per million vehicles: {:.3f}'.format( \\\n",
    "    (crash_df[crash_df['exit']==1]['crash_per_year'].sum()*1e6 /  (365 * crash_df[crash_df['exit']==1]['daily_traffic'].sum()))))\n",
    "\n",
    "\n",
    "# Splits\n",
    "print('\\nSplit Intersection')\n",
    "print('n intersections: {}'.format(crash_df[crash_df['split']==1]['crash_per_year'].count()))\n",
    "print('Mean Crashes/yr: {:.1f}'.format(crash_df[crash_df['split']==1]['crash_per_year'].mean()))\n",
    "print('Crash per million vehicles: {:.3f}'.format( \\\n",
    "    (crash_df[crash_df['split']==1]['crash_per_year'].sum()*1e6 /  (365 * crash_df[crash_df['split']==1]['daily_traffic'].sum()))))\n",
    "\n",
    "\n",
    "# 6 way\n",
    "print('\\n6 way Intersections')\n",
    "print('n intersections: {}'.format(crash_df[(crash_df['way']>=6) & \n",
    "                                            (crash_df['triangle']==1)]['crash_per_year'].count()))\n",
    "print('Mean Crashes/yr: {:.1f}'.format(crash_df[(crash_df['way']>=6) & \n",
    "                                                (crash_df['triangle']==1)]['crash_per_year'].mean()))\n",
    "print('Crash per million vehicles: {:.3f}'.format( \\\n",
    "    (crash_df[(crash_df['way']>=6) & (crash_df['triangle']==1)] \\\n",
    "     ['crash_per_year'].sum()*1e6 /  (365 * crash_df[crash_df['split']==1]['daily_traffic'].sum()))))\n",
    "\n",
    "\n",
    "\n",
    "# normal\n",
    "print('\\nTraditional 4 way Intersections')\n",
    "print('n intersections: {}'.format(crash_df[(crash_df['way']==4) & \n",
    "                                            (crash_df['triangle']==0) & \n",
    "                                            (crash_df['exit']==0) &\n",
    "                                            (crash_df['split']==0)]['crash_per_year'].count()))\n",
    "print('Mean Crashes/yr: {:.1f}'.format(crash_df[(crash_df['way']==4) & \n",
    "                                            (crash_df['triangle']==0) & \n",
    "                                            (crash_df['exit']==0) &\n",
    "                                            (crash_df['split']==0)]['crash_per_year'].mean()))\n",
    "\n",
    "fourway = crash_df[(crash_df['way']==4) & \n",
    "                    (crash_df['triangle']==0) & \n",
    "                    (crash_df['exit']==0) &\n",
    "                    (crash_df['split']==0)]\n",
    "\n",
    "print('Crash per million vehicles: {:.3f}'.format( (fourway['crash_per_year'].sum()*1e6) / \\\n",
    "                                                  (fourway['daily_traffic'].sum()*365)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
