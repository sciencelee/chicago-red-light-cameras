{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a SQL database\n",
    "This notebook builds the necessary db files for the project using SQLite3.\n",
    "\n",
    "Most data is taken from Chicago Data Portal https://data.cityofchicago.org/ using Socrata library.\n",
    "The API endpoints for the data are:\n",
    "- Red Light Violations: https://data.cityofchicago.org/resource/spqx-js37.json\n",
    "- Congestion by Region 2018-Present: https://data.cityofchicago.org/resource/kf7e-cur8.json\n",
    "- Congestion by Region 2013-2018: https://data.cityofchicago.org/resource/emtn-qqdi.json\n",
    "- Traffic Crashes: https://data.cityofchicago.org/resource/85ca-t3if.json\n",
    "\n",
    "Weather data is taken from https://openweathermap.org/weather-data and is saved as csv in data folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Required Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sodapy import Socrata\n",
    "#import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from modules.myfuncs import *\n",
    "import warnings\n",
    "import numpy as np\n",
    "from geopy.geocoders import Nominatim\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the data from portal using Socrata client\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unauthenticated client only works with public data sets. Note 'None'\n",
    "# in place of application token, and no username or password:\n",
    "\n",
    "url = \"data.cityofchicago.org\"\n",
    "client = Socrata(url, None)\n",
    "\n",
    "# Example authenticated client (needed for non-public datasets):\n",
    "# client = Socrata(data.cityofchicago.org,\n",
    "#                  MyAppToken,\n",
    "#                  userame=\"user@example.com\",\n",
    "#                  password=\"AFakePassword\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use a Socrata client query to get all data\n",
    "- rlc_cam is up to 1M redlight cams from 2015 to 2020\n",
    "- crash_data is up to 1M crashes from 2015 to 2020\n",
    "- traffic_data is up to 10M from 2015 to 2020\n",
    "\n",
    "Weather data is taken from csv in data folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Red light violations\n",
    "# Takes several minutes to run and holds about 500mb in memory to build\n",
    "\n",
    "# First 1000000 results, returned as JSON from API / converted to Python list of dictionaries by sodapy\n",
    "rlc_cam = client.get(\"spqx-js37\", #speed cams are at 'hhkd-xvj4' if you want to investigate?\n",
    "                     #where='violation_date > 01-01-2020',\n",
    "                     where='violation_date BETWEEN \\'2015-01-01T00:00:00.000\\' AND \\'2020-12-31T00:00:00.000\\'',\n",
    "                     limit=1000000,\n",
    "                    )\n",
    "\n",
    "rlc_df = pd.DataFrame.from_records(rlc_cam) # Convert to pandas DataFrame\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Crash Data\n",
    "crash_data = client.get(\"85ca-t3if\", \n",
    "                     where=\"crash_date BETWEEN \\'2015-01-01T00:00:00.000\\' AND \\'2020-12-31T00:00:00.000\\'\",\n",
    "                     limit=1000000,\n",
    "                    )\n",
    "\n",
    "crash_df = pd.DataFrame.from_records(crash_data) # Convert to pandas DataFrame\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Congestion Data\n",
    "traffic_data = client.get(\"emtn-qqdi\", \n",
    "                     #where=\"TIME > \\'2015-01-01T00:00:00.000\\'\",\n",
    "                     where='TIME BETWEEN \\'2015-01-01T00:00:00.000\\' AND \\'2020-12-31T00:00:00.000\\'',\n",
    "                     limit=10000000,\n",
    "                    )\n",
    "\n",
    "traffic_df = pd.DataFrame.from_records(traffic_data) # Convert to pandas DataFrame\n",
    "\n",
    "# Import weather data from csv\n",
    "wx_df = pd.read_csv('data/chi_wx.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Red Light Camera Data\n",
    "\n",
    "Data Columns of interest:\n",
    "\n",
    "INTERSECTION -\n",
    "Intersection of the location of the red light enforcement camera(s). There may be more than one camera at each intersection. Plain Text\n",
    "\n",
    "CAMERA ID -\n",
    "A unique ID for each physical camera at an intersection, which may contain more than one camera. Plain Text\n",
    "\n",
    "ADDRESS\t-\n",
    "The address of the physical camera (CAMERA ID). The address may be the same for all cameras or different, based on the physical installation of each camera. Plain Text\n",
    "\n",
    "VIOLATION DATE -\n",
    "The date of when the violations occurred. NOTE: The citation may be issued on a different date. Date & Time\n",
    "\n",
    "VIOLATIONS - \n",
    "Number of violations for each camera on a particular day. Number\n",
    "\n",
    "LATITUDE -\n",
    "The latitude of the physical location of the camera(s) based on the ADDRESS column. Geocoded using the WGS84. Number\n",
    "\n",
    "LONGITUDE -\n",
    "The longitude of the physical location of the camera(s) based on the ADDRESS column. Geocoded using the WGS84.\n",
    "Number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigate rlc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 569593 entries, 0 to 569827\n",
      "Data columns (total 10 columns):\n",
      "intersection      569593 non-null object\n",
      "camera_id         569593 non-null object\n",
      "address           569593 non-null object\n",
      "violation_date    569593 non-null datetime64[ns]\n",
      "violations        569593 non-null int64\n",
      "latitude          539918 non-null float64\n",
      "longitude         539918 non-null float64\n",
      "month             569593 non-null int64\n",
      "weekday           569593 non-null int64\n",
      "year              569593 non-null int64\n",
      "dtypes: datetime64[ns](1), float64(2), int64(4), object(3)\n",
      "memory usage: 47.8+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "intersection          0\n",
       "camera_id             0\n",
       "address               0\n",
       "violation_date        0\n",
       "violations            0\n",
       "latitude          29675\n",
       "longitude         29675\n",
       "month                 0\n",
       "weekday               0\n",
       "year                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rlc_df.info()\n",
    "rlc_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that we have all text/non-null objects.  Need to convert first before manipulating for preprocess.\n",
    "\n",
    "There are a fair number of missing locations/lat/long.  Hope to be able to replace those missing values.\n",
    "This represents a large enough portion of dataset that we should look them up.\n",
    "\n",
    "The na values for camera_id will have to be dropped, since we don't know what they are.\n",
    "\n",
    "We will not be using x andy y_coordinate, so we drop those.  We will also drop location.  We already have lat long in other columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "intersection          0\n",
       "camera_id             0\n",
       "address               0\n",
       "violation_date        0\n",
       "violations            0\n",
       "latitude          29675\n",
       "longitude         29675\n",
       "month                 0\n",
       "weekday               0\n",
       "year                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#client_df.dropna(subset=['camera_id']).isna().sum()\n",
    "try:\n",
    "    # put this is a try in case we run it twice, it will skip it.\n",
    "    rlc_df.dropna(subset=['camera_id'], inplace=True)\n",
    "    \n",
    "    # drop xy coord and location columns\n",
    "    rlc_df = rlc_df.drop(columns=['x_coordinate', 'y_coordinate', 'location'], index=1)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "\n",
    "\n",
    "rlc_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manipulate datatypes for preprocessing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intersection</th>\n",
       "      <th>camera_id</th>\n",
       "      <th>address</th>\n",
       "      <th>violation_date</th>\n",
       "      <th>violations</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>month</th>\n",
       "      <th>weekday</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>IRVING PARK AND KILPATRICK</td>\n",
       "      <td>2763</td>\n",
       "      <td>4700 W IRVING PARK ROA</td>\n",
       "      <td>2015-04-09</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>115TH AND HALSTED</td>\n",
       "      <td>2552</td>\n",
       "      <td>11500 S HALSTED STREE</td>\n",
       "      <td>2015-04-08</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>IRVING PARK AND KILPATRICK</td>\n",
       "      <td>2764</td>\n",
       "      <td>4700 W IRVING PARK ROA</td>\n",
       "      <td>2015-04-19</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>ELSTON AND IRVING PARK</td>\n",
       "      <td>1503</td>\n",
       "      <td>3700 W IRVING PARK ROA</td>\n",
       "      <td>2015-04-23</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>4700 WESTERN</td>\n",
       "      <td>2141</td>\n",
       "      <td>4700 S WESTERN AVENUE</td>\n",
       "      <td>2019-06-05</td>\n",
       "      <td>3</td>\n",
       "      <td>41.808378</td>\n",
       "      <td>-87.684571</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 intersection camera_id                 address  \\\n",
       "0  IRVING PARK AND KILPATRICK      2763  4700 W IRVING PARK ROA   \n",
       "2           115TH AND HALSTED      2552   11500 S HALSTED STREE   \n",
       "3  IRVING PARK AND KILPATRICK      2764  4700 W IRVING PARK ROA   \n",
       "4      ELSTON AND IRVING PARK      1503  3700 W IRVING PARK ROA   \n",
       "5                4700 WESTERN      2141   4700 S WESTERN AVENUE   \n",
       "\n",
       "  violation_date  violations   latitude  longitude  month  weekday  year  \n",
       "0     2015-04-09           4        NaN        NaN      4        3  2015  \n",
       "2     2015-04-08           5        NaN        NaN      4        2  2015  \n",
       "3     2015-04-19           4        NaN        NaN      4        6  2015  \n",
       "4     2015-04-23           3        NaN        NaN      4        3  2015  \n",
       "5     2019-06-05           3  41.808378 -87.684571      6        2  2019  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rlc_df['violations'] = rlc_df['violations'].apply(int)\n",
    "rlc_df['latitude'] = rlc_df['latitude'].apply(float)\n",
    "rlc_df['longitude'] = rlc_df['longitude'].apply(float)\n",
    "rlc_df['violation_date'] = pd.to_datetime(rlc_df['violation_date'])\n",
    "rlc_df['month'] = rlc_df['violation_date'].apply(lambda x: int(x.month))\n",
    "rlc_df['weekday'] = rlc_df['violation_date'].apply(lambda x: int(datetime.weekday(x)))\n",
    "rlc_df['year'] = rlc_df['violation_date'].apply(lambda x: int(x.year))\n",
    "\n",
    "rlc_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a df with info for each camera\n",
    "Will contain the following:\n",
    "- camera_id\n",
    "- location\n",
    "- start date (when was the camera turned on)\n",
    "- end date (when was the camera turned off)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam_df = rlc_df.copy()\n",
    "cam_df['start'] = cam_df['camera_id'].apply(lambda x: None)\n",
    "cam_df['end'] = cam_df['camera_id'].apply(lambda x: None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NA values in cam_startend\n",
      "camera_id    0\n",
      "start        0\n",
      "end          0\n",
      "dtype: int64\n",
      "\n",
      "Describe cam_startend\n",
      "       camera_id                start                  end\n",
      "count        363                  363                  363\n",
      "unique       363                   18                   18\n",
      "top         3032  2015-01-01 00:00:00  2020-12-20 00:00:00\n",
      "freq           1                  285                  256\n",
      "first        NaN  2015-01-01 00:00:00  2015-03-02 00:00:00\n",
      "last         NaN  2018-03-05 00:00:00  2020-12-20 00:00:00\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>camera_id</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1002</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>2020-12-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1003</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>2020-12-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1011</td>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>2020-12-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1014</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>2020-12-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1023</td>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>2020-12-20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  camera_id      start        end\n",
       "0      1002 2015-01-01 2020-12-19\n",
       "1      1003 2015-01-01 2020-12-19\n",
       "2      1011 2015-01-02 2020-12-20\n",
       "3      1014 2015-01-01 2020-12-20\n",
       "4      1023 2015-01-02 2020-12-20"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cam_start = cam_df.groupby(['camera_id'])['violation_date'].min().reset_index()\n",
    "cam_end = cam_df.groupby(['camera_id'])['violation_date'].max().reset_index()\n",
    "\n",
    "cam_startend = cam_start.copy()\n",
    "\n",
    "#print(cam_end[cam_end['camera_id']=='1503'].values[0][1])  # for testing output\n",
    "cam_startend['end'] = cam_start['camera_id'].apply(lambda x: cam_end[cam_end['camera_id']==x].values[0][1])\n",
    "\n",
    "cam_startend.rename(columns={\"violation_date\": \"start\"}, inplace=True)\n",
    "                                                   \n",
    "print('NA values in cam_startend:', cam_startend.isna().sum(), end='\\n\\n', sep='\\n')\n",
    "\n",
    "print('Describe cam_startend:', cam_startend.describe(), end='\\n\\n', sep='\\n')\n",
    "\n",
    "cam_startend.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a db table that has camera locations and intersections\n",
    "Intersections are present (and addresses), but we do not have lat/long info for all cams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "rlc_df.groupby('camera_id')['latitude'].max()  # Some cams do not have any data for lat long at all\n",
    "\n",
    "\n",
    "# Some of the addresses are truncated and not able to lookup with geocode\n",
    "\n",
    "address_fix = {'2400 W VAN BUREN STREE': '2400 W VAN BUREN STREET',\n",
    "               '4700 W IRVING PARK ROA': '4700 W IRVING PARK ROAD',\n",
    "               '11500 S HALSTED STREE': '11500 S HALSTED STREET',\n",
    "               '5500 S WENTWORTH AVEN': '5500 S WENTWORTH AVENUE',\n",
    "                '10300 S HALSTED STREE': '10300 S HALSTED STREET',\n",
    "               '3700 W IRVING PARK ROA': '3700 W IRVING PARK ROAD',\n",
    "               '1600 W IRVING PARK ROA': '1600 W IRVING PARK ROAD',\n",
    "               '7900 S JEFFERY BOULEV': '7900 S JEFFERY BOULEVARD',\n",
    "               '2800 W IRVING PARK ROA': '2800 W IRVING PARK ROAD',\n",
    "               '5200 W IRVING PARK ROA': '5200 W IRVING PARK ROAD',\n",
    "               '3100 S DR MARTIN L KING': '3100 S MARTIN KING DRIVE',\n",
    "               '1600 W DIVERSEY PARKWA': '1600 W DIVERSEY PARKWAY',\n",
    "               '140 W KINZIE': '140 W Kinzie St',\n",
    "                '150 N SACRAMENTO BOUL': '150 N SACRAMENTO BOUL',\n",
    "               '800 N SACRAMENTO AVEN':'800 N SACRAMENTO AVENUE',\n",
    "               '3200 N LAKESHORE DRIV':'3200 N LAKE SHORE DRIVE',\n",
    "               '6400 W FULLERTON AVENU':'6400 W FULLERTON AVENUE',\n",
    "               '6400 N MILWAUKEE AVEN':'6400 N MILWAUKEE AVENUE',\n",
    "               '7900 S STONEY ISLAND':'7900 S Stony Island Ave',  \n",
    "               '150 N SACRAMENTO BOUL':'150 N SACRAMENTO BOULEVARD',\n",
    "                '3200 N LAKESHORE DRIVE':'3200 N Lake Shore Dr',\n",
    "               '7900 S STONEY ISLAND AVENUE':'7900 S Stony Island Ave',\n",
    "               '5600 W FULLERTON AVENU':'5600 W FULLERTON AVENUE',\n",
    "               '8700 S LAFAYETTE AVEN':'8700 S LAFAYETTE AVENUE',\n",
    "               '4400 N MILWAUKEE AVEN':'4400 N MILWAUKEE AVENUE',\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two of them\n",
      "    camera_id           intersection                  address violation_date  \\\n",
      "83      1421     DAMEN AND DIVERSEY  2000 W DIVERSEY PARKWAY     2017-11-30   \n",
      "84      1421  LARAMIE AND FULLERTON    2400 N LARAMIE AVENUE     2020-12-19   \n",
      "\n",
      "    violations   latitude  longitude  month  weekday  year  \n",
      "83           1  41.932394 -87.678173     11        3  2017  \n",
      "84           6  41.924152 -87.756295     12        6  2020  \n",
      "\n",
      "Damen/Diversey 1\n",
      "Laramie/Fullerton: 1210\n",
      "Total cams 363\n"
     ]
    }
   ],
   "source": [
    "# we had some incorrect data in the code below, but have a creative fix.\n",
    "\n",
    "cam_locs = rlc_df.groupby(['camera_id', 'intersection']).max().reset_index()\n",
    "cam_locs.head()\n",
    "\n",
    "# we find there is a mismatch between lens, one of them is duplicated\n",
    "len(cam_locs)  # 364 total\n",
    "len(cam_locs['camera_id'].unique()) # 363\n",
    "\n",
    "cam_locs[cam_locs['camera_id'].duplicated()]  # 1421 is dupe\n",
    "print('Two of them\\n', cam_locs[cam_locs['camera_id'] == '1421'])  # we see two of them\n",
    "print()\n",
    "\n",
    "# Which one is it?\n",
    "print('Damen/Diversey', rlc_df[(rlc_df['camera_id']=='1421') & (rlc_df['intersection']=='DAMEN AND DIVERSEY')]['camera_id'].count())\n",
    "print('Laramie/Fullerton:', rlc_df[(rlc_df['camera_id']=='1421') & (rlc_df['intersection']=='LARAMIE AND FULLERTON')]['camera_id'].count())\n",
    "\n",
    "# Turns out that a camera has two locations. One was only used one time.  We drop it.\n",
    "cam_locs = cam_locs[(cam_locs['camera_id']!='1421') | (cam_locs['intersection']!='DAMEN AND DIVERSEY')]\n",
    "print(\"Total cams\", len(cam_locs))  # 363 total (got rid of the bad one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "camera_id          0\n",
       "intersection       0\n",
       "address            0\n",
       "violation_date     0\n",
       "violations         0\n",
       "latitude          19\n",
       "longitude         19\n",
       "month              0\n",
       "weekday            0\n",
       "year               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cam_locs.isna().sum()  # missing location for 19 cameras.  Let's fix it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like we also are missing 19 of the 363 cam locations.  Let's look it up!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "This section goes through all of the rlc and assigns latlong\n",
    "Many lights are missing it.  \n",
    "For each light, there is an address though.\n",
    "We use geocoding to get the latlong\n",
    "'''\n",
    "\n",
    "# let's get all of the red light cameras with their gps location.  \n",
    "# This will aid in placing the accidents at rlc intersections later (if closer than threshold point to point)\n",
    "# Some RLCs are missing location data,  but have addresses.  I can use geocoding I guess to look them up.\n",
    "\n",
    "\n",
    "geolocator = Nominatim(user_agent=\"https://github.com/sciencelee/chicago_rlc\")  # please change to match repo\n",
    "\n",
    "# Some example code\n",
    "#location = geolocator.geocode(\"175 5th Avenue NYC\")\n",
    "#print(location.address)\n",
    "# out: Flatiron Building, 175, 5th Avenue, Flatiron, New York, NYC, New York, ...\n",
    "\n",
    "#print((location.latitude, location.longitude))\n",
    "# out: (40.7410861, -73.9896297241625)\n",
    "\n",
    "#print(location.raw)\n",
    "# out: {'place_id': '9167009604', 'type': 'attraction', ...}\n",
    "\n",
    "\n",
    "# CAN USE THIS TO FIGURE OUT MY LAT LONG FROM RLC ADDRESS (or crash later)   \n",
    " \n",
    "def get_geocode(lat, long, address):\n",
    "    if lat > 0:  # it's a location\n",
    "        return (lat, long)\n",
    "    else: # it's a proper location tuple, and assumed to be correct latlong\n",
    "        if address in address_fix.keys(): address = address_fix[address]  # errors in the dataset chars omitted\n",
    "        # if we make it this far, we have no record of this cam_id yet, and it doesn't have a proper location\n",
    "        location = geolocator.geocode(address + ', Chicago, IL')\n",
    "        if location == None:\n",
    "            print(address+':'+address+' : could not geolocate') # print it out if we can't find (address errors)\n",
    "        else:\n",
    "            return (location.latitude, location.longitude)\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "# Got it down to one-liner for this. Found out you can't extract and assign series like you can variables\n",
    "cam_locs['location'] = cam_locs.apply(lambda x: get_geocode(x.latitude, x.longitude, x.address), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam_locs['location'].head()\n",
    "cam_locs['latitude'] = cam_locs['location'].apply(lambda x: x[0])\n",
    "cam_locs['longitude'] = cam_locs['location'].apply(lambda x: x[1])\n",
    "\n",
    "cam_locs = cam_locs.drop(columns=['violation_date', 'violations', 'month', 'weekday', 'year', 'location'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 363 entries, 0 to 363\n",
      "Data columns (total 5 columns):\n",
      "camera_id       363 non-null object\n",
      "intersection    363 non-null object\n",
      "address         363 non-null object\n",
      "latitude        363 non-null float64\n",
      "longitude       363 non-null float64\n",
      "dtypes: float64(2), object(3)\n",
      "memory usage: 17.0+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "camera_id       0\n",
       "intersection    0\n",
       "address         0\n",
       "latitude        0\n",
       "longitude       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cam_locs.info()\n",
    "cam_locs.isna().sum() # No longer missing location for 19 cameras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add a df of intersections with lat long\n",
    "This should help us later determine if crash is at intersection\n",
    "\n",
    "I chose to groupby the intersection and aggregate the most commonly occuring lat/long value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#results_df.groupby(['intersection', 'latitude', 'longitude']).reset_index()\n",
    "intersection_df = rlc_df.groupby(['intersection']).agg({'latitude':pd.Series.mode,'longitude':pd.Series.mode,}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 183 entries, 0 to 182\n",
      "Data columns (total 3 columns):\n",
      "intersection    183 non-null object\n",
      "latitude        183 non-null object\n",
      "longitude       183 non-null object\n",
      "dtypes: object(3)\n",
      "memory usage: 4.4+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intersection</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>111TH AND HALSTED</td>\n",
       "      <td>41.6923</td>\n",
       "      <td>-87.6425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>115TH AND HALSTED</td>\n",
       "      <td>41.6852</td>\n",
       "      <td>-87.6423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>119TH AND HALSTED</td>\n",
       "      <td>41.6777</td>\n",
       "      <td>-87.6421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>31ST AND CALIFORNIA</td>\n",
       "      <td>41.8373</td>\n",
       "      <td>-87.6952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>31ST ST AND MARTIN LUTHER KING DRIVE</td>\n",
       "      <td>41.8385</td>\n",
       "      <td>-87.617</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           intersection latitude longitude\n",
       "0                     111TH AND HALSTED  41.6923  -87.6425\n",
       "1                     115TH AND HALSTED  41.6852  -87.6423\n",
       "2                     119TH AND HALSTED  41.6777  -87.6421\n",
       "3                   31ST AND CALIFORNIA  41.8373  -87.6952\n",
       "4  31ST ST AND MARTIN LUTHER KING DRIVE  41.8385   -87.617"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intersection_df.info()\n",
    "intersection_df.head()  # that was easy!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We still have missing lat/long info for our rlc_df.  Let's fix it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "intersection          0\n",
       "camera_id             0\n",
       "address               0\n",
       "violation_date        0\n",
       "violations            0\n",
       "latitude          29675\n",
       "longitude         29675\n",
       "month                 0\n",
       "weekday               0\n",
       "year                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rlc_df.isna().sum()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS TAKES SOME TIME (8min on my macbook pro)\n",
    "def read_loc(camloc_df, lat, long, cam_id):\n",
    "    cam = camloc_df[camloc_df['camera_id']==cam_id]\n",
    "    return (float(cam['latitude']), float(cam['longitude']))\n",
    "        \n",
    "\n",
    "read_loc(cam_locs, 45, 87, '1002')  # testing purposes\n",
    "#results_df[:5].apply(lambda x: x.latitude, axis=1)  # tsting purpose\n",
    "\n",
    "# create another\n",
    "rlc_df['location'] = rlc_df.apply(lambda x: read_loc(cam_locs, x.latitude, x.longitude, x.camera_id), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# then add in the new lat longs to the df\n",
    "rlc_df['latitude'] = rlc_df['location'].apply(lambda x: x[0])\n",
    "rlc_df['longitude'] = rlc_df['location'].apply(lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'location' in rlc_df.columns:\n",
    "    rlc_df.drop(columns=['location'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crash data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop a few columns we don't need, including location (we have lat/long)\n",
    "dropme = ['statements_taken_i', 'private_property_i', 'photos_taken_i', 'dooring_i', 'date_police_notified','location']\n",
    "\n",
    "crash_df.drop(columns=dropme, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "crash_record_id                       0\n",
       "rd_no                               577\n",
       "crash_date                            0\n",
       "posted_speed_limit                    0\n",
       "traffic_control_device                0\n",
       "device_condition                      0\n",
       "weather_condition                     0\n",
       "lighting_condition                    0\n",
       "first_crash_type                      0\n",
       "trafficway_type                       0\n",
       "alignment                             0\n",
       "roadway_surface_cond                  0\n",
       "road_defect                           0\n",
       "report_type                       11247\n",
       "crash_type                            0\n",
       "hit_and_run_i                    330448\n",
       "damage                                0\n",
       "prim_contributory_cause               0\n",
       "sec_contributory_cause                0\n",
       "street_no                             0\n",
       "street_direction                      3\n",
       "street_name                           1\n",
       "beat_of_occurrence                    5\n",
       "num_units                             0\n",
       "most_severe_injury                  943\n",
       "injuries_total                      932\n",
       "injuries_fatal                      932\n",
       "injuries_incapacitating             932\n",
       "injuries_non_incapacitating         932\n",
       "injuries_reported_not_evident       932\n",
       "injuries_no_indication              932\n",
       "injuries_unknown                    932\n",
       "crash_hour                            0\n",
       "crash_day_of_week                     0\n",
       "crash_month                           0\n",
       "latitude                           2549\n",
       "longitude                          2549\n",
       "lane_cnt                         267394\n",
       "intersection_related_i           361044\n",
       "crash_date_est_i                 431586\n",
       "work_zone_i                      463281\n",
       "work_zone_type                   463924\n",
       "workers_present_i                465619\n",
       "dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crash_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 2.5k entries that have no location.  Let's drop them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "crash_df.dropna(subset=['latitude',], inplace=True)  # get rid of na locations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's look at what is in the data   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "traffic_control_device ['UNKNOWN' 'NO CONTROLS' 'TRAFFIC SIGNAL' 'STOP SIGN/FLASHER'\n",
      " 'OTHER WARNING SIGN' 'LANE USE MARKING' 'OTHER' 'OTHER REG. SIGN'\n",
      " 'SCHOOL ZONE' 'PEDESTRIAN CROSSING SIGN' 'YIELD'\n",
      " 'FLASHING CONTROL SIGNAL' 'POLICE/FLAGMAN' 'RR CROSSING SIGN'\n",
      " 'RAILROAD CROSSING GATE' 'OTHER RAILROAD CROSSING' 'DELINEATORS'\n",
      " 'NO PASSING' 'BICYCLE CROSSING SIGN']\n",
      "device_condition ['UNKNOWN' 'NO CONTROLS' 'FUNCTIONING PROPERLY' 'OTHER'\n",
      " 'FUNCTIONING IMPROPERLY' 'NOT FUNCTIONING' 'WORN REFLECTIVE MATERIAL'\n",
      " 'MISSING']\n",
      "weather_condition ['UNKNOWN' 'CLEAR' 'SNOW' 'RAIN' 'CLOUDY/OVERCAST' 'FOG/SMOKE/HAZE'\n",
      " 'OTHER' 'FREEZING RAIN/DRIZZLE' 'SLEET/HAIL' 'SEVERE CROSS WIND GATE'\n",
      " 'BLOWING SNOW' 'BLOWING SAND, SOIL, DIRT']\n",
      "lighting_condition ['DARKNESS, LIGHTED ROAD' 'DAYLIGHT' 'DARKNESS' 'DUSK' 'DAWN' 'UNKNOWN']\n",
      "first_crash_type ['PARKED MOTOR VEHICLE' 'REAR END' 'ANGLE' 'SIDESWIPE SAME DIRECTION'\n",
      " 'TURNING' 'REAR TO FRONT' 'PEDESTRIAN' 'PEDALCYCLIST' 'FIXED OBJECT'\n",
      " 'SIDESWIPE OPPOSITE DIRECTION' 'OTHER NONCOLLISION' 'REAR TO SIDE'\n",
      " 'OTHER OBJECT' 'HEAD ON' 'REAR TO REAR' 'ANIMAL' 'TRAIN' 'OVERTURNED']\n",
      "trafficway_type ['NOT DIVIDED' 'PARKING LOT' 'FOUR WAY' 'DIVIDED - W/MEDIAN (NOT RAISED)'\n",
      " 'ONE-WAY' 'DIVIDED - W/MEDIAN BARRIER' 'OTHER' 'UNKNOWN'\n",
      " 'CENTER TURN LANE' 'T-INTERSECTION' 'ALLEY' 'ROUNDABOUT' 'RAMP'\n",
      " 'FIVE POINT, OR MORE' 'DRIVEWAY' 'TRAFFIC ROUTE' 'NOT REPORTED'\n",
      " 'UNKNOWN INTERSECTION TYPE' 'Y-INTERSECTION' 'L-INTERSECTION']\n",
      "alignment ['STRAIGHT AND LEVEL' 'CURVE, LEVEL' 'STRAIGHT ON GRADE'\n",
      " 'STRAIGHT ON HILLCREST' 'CURVE ON HILLCREST' 'CURVE ON GRADE']\n",
      "roadway_surface_cond ['UNKNOWN' 'DRY' 'SNOW OR SLUSH' 'WET' 'ICE' 'OTHER' 'SAND, MUD, DIRT']\n",
      "road_defect ['UNKNOWN' 'NO DEFECTS' 'WORN SURFACE' 'SHOULDER DEFECT'\n",
      " 'DEBRIS ON ROADWAY' 'OTHER' 'RUT, HOLES']\n",
      "report_type ['NOT ON SCENE (DESK REPORT)' nan 'ON SCENE' 'AMENDED']\n",
      "crash_type ['INJURY AND / OR TOW DUE TO CRASH' 'NO INJURY / DRIVE AWAY']\n",
      "hit_and_run_i ['Y' nan 'N']\n",
      "damage ['OVER $1,500' '$500 OR LESS' '$501 - $1,500']\n",
      "prim_contributory_cause ['UNABLE TO DETERMINE' 'FOLLOWING TOO CLOSELY'\n",
      " 'DISREGARDING TRAFFIC SIGNALS' 'FAILING TO YIELD RIGHT-OF-WAY'\n",
      " 'FAILING TO REDUCE SPEED TO AVOID CRASH' 'IMPROPER BACKING'\n",
      " 'IMPROPER OVERTAKING/PASSING' 'NOT APPLICABLE' 'DISREGARDING STOP SIGN'\n",
      " 'EVASIVE ACTION DUE TO ANIMAL, OBJECT, NONMOTORIST'\n",
      " 'IMPROPER TURNING/NO SIGNAL' 'DRIVING SKILLS/KNOWLEDGE/EXPERIENCE'\n",
      " 'IMPROPER LANE USAGE' 'DRIVING ON WRONG SIDE/WRONG WAY'\n",
      " 'DISREGARDING ROAD MARKINGS' 'DISTRACTION - FROM OUTSIDE VEHICLE'\n",
      " 'ANIMAL' 'ROAD CONSTRUCTION/MAINTENANCE'\n",
      " 'CELL PHONE USE OTHER THAN TEXTING' 'EXCEEDING SAFE SPEED FOR CONDITIONS'\n",
      " 'EQUIPMENT - VEHICLE CONDITION'\n",
      " 'OPERATING VEHICLE IN ERRATIC, RECKLESS, CARELESS, NEGLIGENT OR AGGRESSIVE MANNER'\n",
      " 'DISREGARDING OTHER TRAFFIC SIGNS' 'PHYSICAL CONDITION OF DRIVER'\n",
      " 'UNDER THE INFLUENCE OF ALCOHOL/DRUGS (USE WHEN ARREST IS EFFECTED)'\n",
      " 'WEATHER' 'EXCEEDING AUTHORIZED SPEED LIMIT'\n",
      " 'VISION OBSCURED (SIGNS, TREE LIMBS, BUILDINGS, ETC.)'\n",
      " 'ROAD ENGINEERING/SURFACE/MARKING DEFECTS'\n",
      " 'DISTRACTION - OTHER ELECTRONIC DEVICE (NAVIGATION DEVICE, DVD PLAYER, ETC.)'\n",
      " 'DISTRACTION - FROM INSIDE VEHICLE' 'PASSING STOPPED SCHOOL BUS'\n",
      " 'TURNING RIGHT ON RED' 'RELATED TO BUS STOP' 'DISREGARDING YIELD SIGN'\n",
      " 'HAD BEEN DRINKING (USE WHEN ARREST IS NOT MADE)'\n",
      " 'BICYCLE ADVANCING LEGALLY ON RED LIGHT' 'TEXTING'\n",
      " 'MOTORCYCLE ADVANCING LEGALLY ON RED LIGHT' 'OBSTRUCTED CROSSWALKS']\n",
      "sec_contributory_cause ['UNABLE TO DETERMINE' 'NOT APPLICABLE' 'FAILING TO YIELD RIGHT-OF-WAY'\n",
      " 'VISION OBSCURED (SIGNS, TREE LIMBS, BUILDINGS, ETC.)'\n",
      " 'IMPROPER LANE USAGE' 'DRIVING SKILLS/KNOWLEDGE/EXPERIENCE'\n",
      " 'IMPROPER BACKING' 'FAILING TO REDUCE SPEED TO AVOID CRASH'\n",
      " 'IMPROPER TURNING/NO SIGNAL' 'DISTRACTION - FROM INSIDE VEHICLE'\n",
      " 'WEATHER' 'EQUIPMENT - VEHICLE CONDITION' 'DISREGARDING STOP SIGN'\n",
      " 'FOLLOWING TOO CLOSELY' 'IMPROPER OVERTAKING/PASSING'\n",
      " 'OPERATING VEHICLE IN ERRATIC, RECKLESS, CARELESS, NEGLIGENT OR AGGRESSIVE MANNER'\n",
      " 'DISTRACTION - FROM OUTSIDE VEHICLE'\n",
      " 'EVASIVE ACTION DUE TO ANIMAL, OBJECT, NONMOTORIST'\n",
      " 'DISREGARDING TRAFFIC SIGNALS' 'EXCEEDING AUTHORIZED SPEED LIMIT'\n",
      " 'DRIVING ON WRONG SIDE/WRONG WAY' 'EXCEEDING SAFE SPEED FOR CONDITIONS'\n",
      " 'DISREGARDING ROAD MARKINGS' 'DISREGARDING YIELD SIGN'\n",
      " 'PASSING STOPPED SCHOOL BUS' 'DISREGARDING OTHER TRAFFIC SIGNS'\n",
      " 'ROAD ENGINEERING/SURFACE/MARKING DEFECTS' 'PHYSICAL CONDITION OF DRIVER'\n",
      " 'CELL PHONE USE OTHER THAN TEXTING'\n",
      " 'HAD BEEN DRINKING (USE WHEN ARREST IS NOT MADE)'\n",
      " 'MOTORCYCLE ADVANCING LEGALLY ON RED LIGHT'\n",
      " 'BICYCLE ADVANCING LEGALLY ON RED LIGHT' 'TURNING RIGHT ON RED'\n",
      " 'OBSTRUCTED CROSSWALKS' 'ROAD CONSTRUCTION/MAINTENANCE'\n",
      " 'UNDER THE INFLUENCE OF ALCOHOL/DRUGS (USE WHEN ARREST IS EFFECTED)'\n",
      " 'DISTRACTION - OTHER ELECTRONIC DEVICE (NAVIGATION DEVICE, DVD PLAYER, ETC.)'\n",
      " 'TEXTING' 'RELATED TO BUS STOP' 'ANIMAL']\n",
      "street_no ['370' '2341' '4700' ... '12353' '11254' '11729']\n",
      "street_direction ['N' 'S' 'W' 'E']\n",
      "street_name ['HAMLIN AVE' 'NARRAGANSETT AVE' 'HALSTED ST' ... 'ATTRILL ST'\n",
      " 'ELSTON PKWY' 'NASHOTAH AVE']\n",
      "beat_of_occurrence ['1122' '2512' '933' '1011' '114' '1822' '835' '834' '1813' '831' '911'\n",
      " '1922' '815' '1833' '2413' '1823' '821' '1712' '823' '2221' '2535' '1824'\n",
      " '922' '1722' '2211' '2232' '321' '1231' '931' '1034' '2532' '1133' '1411'\n",
      " '1911' '1711' '2031' '2233' '1934' '1232' '722' '1814' '322' '1214'\n",
      " '2423' '733' '2432' '132' '1422' '2522' '2412' '111' '614' '524' '2223'\n",
      " '712' '1834' '1233' '512' '433' '122' '1912' '612' '811' '1432' '1424'\n",
      " '532' '323' '632' '813' '1624' '1022' '1713' '833' '1935' '225' '213'\n",
      " '331' '1522' '1524' '1115' '624' '1621' '233' '131' '2411' '935' '1014'\n",
      " '224' '2534' '1634' '1932' '1511' '112' '2531' '613' '1113' '724' '1821'\n",
      " '915' '1811' '1623' '634' '2514' '513' '523' '825' '423' '2212' '2013'\n",
      " '533' '1215' '1223' '723' '1731' '434' '2033' '824' '1213' '113' '923'\n",
      " '1732' '1412' '1931' '1724' '2515' '1414' '2011' '1013' '735' '232' '222'\n",
      " '1033' '1124' '1631' '1024' '1531' '124' '611' '1513' '2511' '1433' '431'\n",
      " '1112' '1533' '622' '422' '511' '2213' '1131' '332' '1212' '814' '1923'\n",
      " '2234' '2525' '1434' '234' '1211' '1221' '2032' '631' '1031' '1224' '711'\n",
      " '432' '2433' '2022' '2513' '123' '2422' '1921' '2521' '1633' '1123' '413'\n",
      " '1111' '1831' '1924' '2523' '214' '1632' '312' '734' '912' '1622' '1812'\n",
      " '421' '1023' '1913' '221' '212' '623' '732' '1651' '812' '531' '314'\n",
      " '333' '1523' '412' '215' '1614' '925' '832' '1235' '1723' '2533' '1832'\n",
      " '924' '324' '411' '1925' '1915' '2024' '715' '1222' '1114' '121' '414'\n",
      " '334' '934' '822' '1121' '1933' '1225' '914' '1733' '1132' '1532' '1612'\n",
      " '235' '621' '713' '921' '1914' '2431' '1431' '2012' '1125' '1512' '1135'\n",
      " '1613' '1234' '726' '2524' '714' '2424' '133' '725' '1654' '1032' '932'\n",
      " '223' '211' '1423' '913' '424' '1611' '633' '2222' '1421' '311' '731'\n",
      " '1134' '1021' '2023' '231' '1413' '313' '522' '1012' nan]\n",
      "num_units ['2' '3' '1' '6' '4' '5' '8' '7' '9' '10' '11' '12' '14' '15' '18' '16']\n",
      "most_severe_injury ['NO INDICATION OF INJURY' 'NONINCAPACITATING INJURY'\n",
      " 'REPORTED, NOT EVIDENT' 'INCAPACITATING INJURY' 'FATAL' nan]\n",
      "injuries_fatal ['0' '1' nan '2' '4' '3']\n",
      "injuries_incapacitating ['0' '1' '2' nan '3' '4' '6' '5' '7']\n",
      "injuries_non_incapacitating ['0' '2' '1' '4' '3' nan '5' '21' '6' '7' '8' '18' '10' '9' '14' '12' '11'\n",
      " '16']\n",
      "injuries_reported_not_evident ['0' '1' '2' '5' '3' '4' nan '6' '9' '7' '10' '8' '15' '11']\n",
      "injuries_no_indication ['1' '2' '3' '4' '0' '6' '7' '5' '8' nan '9' '11' '10' '16' '12' '18' '21'\n",
      " '17' '14' '46' '13' '22' '26' '19' '27' '34' '29' '24' '61' '20' '30'\n",
      " '32' '42' '40' '15' '50' '37' '28' '31' '36' '33' '25' '38' '39']\n",
      "injuries_unknown ['0' nan]\n",
      "crash_hour ['3' '18' '17' '2' '5' '16' '14' '13' '7' '19' '20' '10' '23' '8' '22'\n",
      " '15' '12' '0' '9' '21' '4' '1' '11' '6']\n",
      "crash_day_of_week ['2' '1' '7' '4' '6' '5' '3']\n",
      "crash_month ['11' '7' '12' '2' '8' '9' '6' '3' '4' '1' '5' '10']\n",
      "latitude ['41.887233727' '41.923097678' '41.808815039' ... '41.922809982'\n",
      " '41.969015325' '41.71184597']\n",
      "longitude ['-87.721106404' '-87.785278659' '-87.645682953' ... '-87.777044877'\n",
      " '-87.69610903' '-87.537465129']\n",
      "lane_cnt [nan '2' '1' '4' '8' '0' '3' '6' '5' '10' '28' '7' '99' '11' '9' '12' '16'\n",
      " '20' '433634' '25' '15' '30' '60' '35' '1191625' '22' '19' '400' '21'\n",
      " '902' '14' '100' '41' '299679' '17' '40' '45' '218474' '80' '24' '44']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intersection_related_i [nan 'Y' 'N']\n",
      "crash_date_est_i [nan 'Y' 'N']\n",
      "work_zone_i [nan 'Y' 'N']\n",
      "work_zone_type [nan 'UTILITY' 'CONSTRUCTION' 'MAINTENANCE' 'UNKNOWN']\n",
      "workers_present_i [nan 'Y' 'N']\n"
     ]
    }
   ],
   "source": [
    "# What's in this data?\n",
    "col_interest = ['traffic_control_device', 'device_condition', 'weather_condition',\n",
    "       'lighting_condition', 'first_crash_type', 'trafficway_type',\n",
    "       'alignment', 'roadway_surface_cond', 'road_defect', 'report_type',\n",
    "       'crash_type', 'hit_and_run_i', 'damage', 'prim_contributory_cause',\n",
    "       'sec_contributory_cause', 'street_no', 'street_direction',\n",
    "       'street_name', 'beat_of_occurrence', 'num_units', 'most_severe_injury', \n",
    "        'injuries_fatal', 'injuries_incapacitating',\n",
    "       'injuries_non_incapacitating', 'injuries_reported_not_evident',\n",
    "       'injuries_no_indication', 'injuries_unknown', 'crash_hour',\n",
    "       'crash_day_of_week', 'crash_month', 'latitude', 'longitude', 'lane_cnt',\n",
    "       'intersection_related_i', 'crash_date_est_i',\n",
    "       'work_zone_i', 'work_zone_type',\n",
    "       'workers_present_i']\n",
    "\n",
    "for col in col_interest:\n",
    "    print(col, crash_df[col].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This helps us.  \n",
    "We can filter 'traffic_control_device' == 'TRAFFIC SIGNAL'.  \n",
    "We can filter 'intersection_related_i' == 'Y'\n",
    "\n",
    "This will leave us with only crashes that occurred at/because of intersections, and with a signal at the intersection.\n",
    "\n",
    "intersection_related_i: A field observation by the police officer whether an intersection played a role in the crash. Does not represent whether or not the crash occurred within the intersection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "crash_df = crash_df[(crash_df['traffic_control_device']=='TRAFFIC SIGNAL') & \\\n",
    "                    (crash_df['intersection_related_i']=='Y')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We will now focus on trying to bring rlc intersections to our crashes\n",
    "We find that we have 363 cameras at 183 intersections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>camera_id</th>\n",
       "      <th>intersection</th>\n",
       "      <th>address</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1002</td>\n",
       "      <td>WESTERN AND CERMAK</td>\n",
       "      <td>2200 S WESTERN AVENUE</td>\n",
       "      <td>41.851984</td>\n",
       "      <td>-87.685786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1003</td>\n",
       "      <td>WESTERN AND CERMAK</td>\n",
       "      <td>2400 W CERMAK ROAD</td>\n",
       "      <td>41.852141</td>\n",
       "      <td>-87.685753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1011</td>\n",
       "      <td>PETERSON AND WESTERN</td>\n",
       "      <td>6000 N WESTERN AVE</td>\n",
       "      <td>41.990586</td>\n",
       "      <td>-87.689822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1014</td>\n",
       "      <td>PETERSON AND WESTERN</td>\n",
       "      <td>2400 W PETERSON</td>\n",
       "      <td>41.990609</td>\n",
       "      <td>-87.689735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1023</td>\n",
       "      <td>IRVING PARK AND NARRAGANSETT</td>\n",
       "      <td>6400 W IRVING PK</td>\n",
       "      <td>41.953025</td>\n",
       "      <td>-87.786683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>359</td>\n",
       "      <td>3051</td>\n",
       "      <td>LAKE AND UPPER WACKER</td>\n",
       "      <td>200 N UPPER WACKER DR</td>\n",
       "      <td>41.886067</td>\n",
       "      <td>-87.636537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>3052</td>\n",
       "      <td>LAKE AND UPPER WACKER</td>\n",
       "      <td>340 W UPPER WACKER DR</td>\n",
       "      <td>41.886997</td>\n",
       "      <td>-87.626608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>361</td>\n",
       "      <td>3072</td>\n",
       "      <td>DAMEN AND ELSTON</td>\n",
       "      <td>2426 N DAMEN AVE</td>\n",
       "      <td>41.925732</td>\n",
       "      <td>-87.678089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>362</td>\n",
       "      <td>3082</td>\n",
       "      <td>MICHIGAN AND ONTARIO</td>\n",
       "      <td>628 N MICHIGAN AVE</td>\n",
       "      <td>41.893432</td>\n",
       "      <td>-87.624364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>363</td>\n",
       "      <td>3084</td>\n",
       "      <td>MICHIGAN AND ONTARIO</td>\n",
       "      <td>100 E ONTARIO ST</td>\n",
       "      <td>41.893426</td>\n",
       "      <td>-87.625362</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>363 rows  5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    camera_id                  intersection                address   latitude  \\\n",
       "0        1002            WESTERN AND CERMAK  2200 S WESTERN AVENUE  41.851984   \n",
       "1        1003            WESTERN AND CERMAK     2400 W CERMAK ROAD  41.852141   \n",
       "2        1011          PETERSON AND WESTERN     6000 N WESTERN AVE  41.990586   \n",
       "3        1014          PETERSON AND WESTERN        2400 W PETERSON  41.990609   \n",
       "4        1023  IRVING PARK AND NARRAGANSETT       6400 W IRVING PK  41.953025   \n",
       "..        ...                           ...                    ...        ...   \n",
       "359      3051         LAKE AND UPPER WACKER  200 N UPPER WACKER DR  41.886067   \n",
       "360      3052         LAKE AND UPPER WACKER  340 W UPPER WACKER DR  41.886997   \n",
       "361      3072              DAMEN AND ELSTON       2426 N DAMEN AVE  41.925732   \n",
       "362      3082          MICHIGAN AND ONTARIO     628 N MICHIGAN AVE  41.893432   \n",
       "363      3084          MICHIGAN AND ONTARIO       100 E ONTARIO ST  41.893426   \n",
       "\n",
       "     longitude  \n",
       "0   -87.685786  \n",
       "1   -87.685753  \n",
       "2   -87.689822  \n",
       "3   -87.689735  \n",
       "4   -87.786683  \n",
       "..         ...  \n",
       "359 -87.636537  \n",
       "360 -87.626608  \n",
       "361 -87.678089  \n",
       "362 -87.624364  \n",
       "363 -87.625362  \n",
       "\n",
       "[363 rows x 5 columns]"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cam_locs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intersection</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>cam1</th>\n",
       "      <th>cam2</th>\n",
       "      <th>cam3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>111TH AND HALSTED</td>\n",
       "      <td>41.692465</td>\n",
       "      <td>-87.642441</td>\n",
       "      <td>2422</td>\n",
       "      <td>2424</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>115TH AND HALSTED</td>\n",
       "      <td>41.685190</td>\n",
       "      <td>-87.642280</td>\n",
       "      <td>2552</td>\n",
       "      <td>2553</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>119TH AND HALSTED</td>\n",
       "      <td>41.677923</td>\n",
       "      <td>-87.641990</td>\n",
       "      <td>2402</td>\n",
       "      <td>2404</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>31ST AND CALIFORNIA</td>\n",
       "      <td>41.838438</td>\n",
       "      <td>-87.687713</td>\n",
       "      <td>2061</td>\n",
       "      <td>2064</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>31ST ST AND MARTIN LUTHER KING DRIVE</td>\n",
       "      <td>41.838534</td>\n",
       "      <td>-87.615640</td>\n",
       "      <td>2121</td>\n",
       "      <td>2123</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           intersection   latitude  longitude  cam1  cam2  \\\n",
       "0                     111TH AND HALSTED  41.692465 -87.642441  2422  2424   \n",
       "1                     115TH AND HALSTED  41.685190 -87.642280  2552  2553   \n",
       "2                     119TH AND HALSTED  41.677923 -87.641990  2402  2404   \n",
       "3                   31ST AND CALIFORNIA  41.838438 -87.687713  2061  2064   \n",
       "4  31ST ST AND MARTIN LUTHER KING DRIVE  41.838534 -87.615640  2121  2123   \n",
       "\n",
       "   cam3  \n",
       "0  None  \n",
       "1  None  \n",
       "2  None  \n",
       "3  None  \n",
       "4  None  "
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_cams = cam_locs.groupby(['intersection']) \\\n",
    "                    .agg({'latitude':pd.Series.max, 'longitude':pd.Series.max,}) \\\n",
    "                    .reset_index()\n",
    "\n",
    "int_cams['cam1'] = int_cams['intersection'] \\\n",
    "                            .apply(lambda x: cam_locs[cam_locs['intersection']==x]['camera_id'].iloc[0])\n",
    "\n",
    "int_cams['cam2'] = int_cams['intersection'].apply( \\\n",
    "                            lambda x: None if len(cam_locs[cam_locs['intersection']==x])==1 \\\n",
    "                            else cam_locs[cam_locs['intersection']==x]['camera_id'].iloc[1])\n",
    "\n",
    "int_cams['cam3'] = int_cams['intersection'].apply( \\\n",
    "                            lambda x: None if len(cam_locs[cam_locs['intersection']==x])<3 \\\n",
    "                            else cam_locs[cam_locs['intersection']==x]['camera_id'].iloc[2])                             \n",
    "\n",
    "int_cams.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Cameras 363\n",
      "Total Intersections 183\n"
     ]
    }
   ],
   "source": [
    "print('Total Cameras', len(cam_locs))\n",
    "print('Total Intersections', len(int_cams))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add the intersection to my crashes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WESTERN AND 79TH\n",
      "BLUE ISLAND AND DAMEN\n",
      "LAWRENCE AND WESTERN\n",
      "HALSTED AND 95TH\n",
      "WESTERN AND FULLERTON\n",
      "WESTERN AND ARMITAGE\n",
      "LAFAYETTE AND 87TH\n",
      "ASHLAND AND LAWRENCE\n",
      "WESTERN AND FULLERTON\n",
      "HOLLYWOOD AND SHERIDAN\n",
      "DIVERSEY AND WESTERN\n",
      "PULASKI AND MONTROSE\n",
      "BROADWAY/SHERIDAN AND DEVON\n",
      "CICERO AND 47TH\n",
      "PULASKI AND NORTH\n",
      "ASHLAND AND 47TH\n",
      "4700 WESTERN\n",
      "PETERSON AND WESTERN\n",
      "LAFAYETTE AND 87TH\n",
      "JEFFERY AND 79TH\n",
      "COTTAGE GROVE AND 95TH\n",
      "CALIFORNIA AND DIVERSEY\n",
      "JEFFERY AND 79TH\n",
      "HALSTED AND 63RD\n",
      "CICERO AND PETERSON\n",
      "ARCHER/NARRAGANSETT AND 55TH\n",
      "DIVERSEY AND AUSTIN\n",
      "55TH AND KEDZIE\n",
      "MADISON AND WESTERN\n",
      "ASHLAND AND IRVING PARK\n",
      "99TH AND HALSTED\n",
      "PETERSON AND WESTERN\n",
      "ASHLAND AND MADISON\n",
      "HOLLYWOOD AND SHERIDAN\n",
      "COTTAGE GROVE AND 95TH\n",
      "KEDZIE AND 26TH\n",
      "HALSTED AND MADISON\n",
      "CICERO AND WASHINGTON\n",
      "BROADWAY/SHERIDAN AND DEVON\n",
      "99TH AND HALSTED\n",
      "PULASKI AND MONTROSE\n",
      "WESTERN AND NORTH\n",
      "WESTERN AND ADDISON\n",
      "KEDZIE AND 31ST\n",
      "CALIFORNIA AND DIVERSEY\n",
      "DAMEN AND 63RD\n",
      "HALSTED AND 95TH\n",
      "FULLERTON AND NARRAGANSETT\n",
      "HALSTED AND 103RD\n",
      "SACRAMENTO AND CHICAGO\n",
      "CICERO AND FULLERTON\n",
      "WESTERN AND FOSTER\n"
     ]
    }
   ],
   "source": [
    "# Now I am desperate.  This takes too long to process.  Let's simplify it and make it a box instead.\n",
    "box_side = 50  # effectively makes it check for crash being within 25m of interscection\n",
    "box_lat = box_side / 111070 / 2 # 111070 is meters in deg lat in Chicago\n",
    "box_long = box_side / 83000 / 2 # 83000 is meters in deg long in Chicago\n",
    "\n",
    "def box_check(lat, long, ints_df):\n",
    "    answer = (ints_df[  (ints_df['latitude'] > (lat - box_lat)) & \n",
    "                      (ints_df['latitude'] < (lat + box_lat)) &\n",
    "                      (ints_df['longitude'] > (long - box_long)) &\n",
    "                      (ints_df['longitude'] < (long + box_long))\n",
    "                     ])\n",
    "    if answer.empty: return None\n",
    "    return answer['intersection'].values[0]\n",
    "    \n",
    "# THIS SEEMS TO WORK WITH SPEED AND ELIMINATES MEMORY PROBLEM\n",
    "for i in range(100): #(len(df)):\n",
    "    intersect = box_check(float(crash_df.iloc[i]['latitude']), \n",
    "                          float(crash_df.iloc[i]['longitude']), \n",
    "                          int_cams)\n",
    "    if intersect: print(intersect)\n",
    "    \n",
    "    \n",
    "# MOMENT OF TRUTH (takes a few minutes, but at least it runs.  This caused me lots of trouble)\n",
    "crash_df['intersection'] = crash_df.apply(lambda x: box_check(float(x.latitude), \n",
    "                                                              float(x.longitude), \n",
    "                                                              int_cams), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "crash_df['crash_date'] = pd.to_datetime(crash_df['crash_date'])\n",
    "crash_df['year'] = crash_df['crash_date'].apply(lambda x: int(x.year))\n",
    "crash_df['month'] = crash_df['crash_date'].apply(lambda x: int(x.month))\n",
    "crash_df['day'] = crash_df['crash_date'].apply(lambda x: int(x.day))\n",
    "crash_df['hour'] = crash_df['crash_date'].apply(lambda x: int(x.hour))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 60332 entries, 3 to 466328\n",
      "Data columns (total 48 columns):\n",
      "crash_record_id                  60332 non-null object\n",
      "rd_no                            60260 non-null object\n",
      "crash_date                       60332 non-null datetime64[ns]\n",
      "posted_speed_limit               60332 non-null object\n",
      "traffic_control_device           60332 non-null object\n",
      "device_condition                 60332 non-null object\n",
      "weather_condition                60332 non-null object\n",
      "lighting_condition               60332 non-null object\n",
      "first_crash_type                 60332 non-null object\n",
      "trafficway_type                  60332 non-null object\n",
      "alignment                        60332 non-null object\n",
      "roadway_surface_cond             60332 non-null object\n",
      "road_defect                      60332 non-null object\n",
      "report_type                      58554 non-null object\n",
      "crash_type                       60332 non-null object\n",
      "hit_and_run_i                    11420 non-null object\n",
      "damage                           60332 non-null object\n",
      "prim_contributory_cause          60332 non-null object\n",
      "sec_contributory_cause           60332 non-null object\n",
      "street_no                        60332 non-null object\n",
      "street_direction                 60332 non-null object\n",
      "street_name                      60332 non-null object\n",
      "beat_of_occurrence               60332 non-null object\n",
      "num_units                        60332 non-null object\n",
      "most_severe_injury               60316 non-null object\n",
      "injuries_total                   60316 non-null object\n",
      "injuries_fatal                   60316 non-null object\n",
      "injuries_incapacitating          60316 non-null object\n",
      "injuries_non_incapacitating      60316 non-null object\n",
      "injuries_reported_not_evident    60316 non-null object\n",
      "injuries_no_indication           60316 non-null object\n",
      "injuries_unknown                 60316 non-null object\n",
      "crash_hour                       60332 non-null object\n",
      "crash_day_of_week                60332 non-null object\n",
      "crash_month                      60332 non-null object\n",
      "latitude                         60332 non-null object\n",
      "longitude                        60332 non-null object\n",
      "lane_cnt                         27069 non-null object\n",
      "intersection_related_i           60332 non-null object\n",
      "crash_date_est_i                 2676 non-null object\n",
      "work_zone_i                      464 non-null object\n",
      "work_zone_type                   361 non-null object\n",
      "workers_present_i                97 non-null object\n",
      "intersection                     6951 non-null object\n",
      "year                             60332 non-null int64\n",
      "month                            60332 non-null int64\n",
      "day                              60332 non-null int64\n",
      "hour                             60332 non-null int64\n",
      "dtypes: datetime64[ns](1), int64(4), object(43)\n",
      "memory usage: 22.6+ MB\n"
     ]
    }
   ],
   "source": [
    "crash_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now add congestion region number to my crash data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to get rid of congestion if there aren't enough buses to properly measure it.\n",
    "# choosing to just fill it in with a .9 quantile\n",
    "\n",
    "speed90 = traffic_df['speed'].quantile(0.9)\n",
    "print(speed90)\n",
    "#traffic_df['speed'].apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now we dump all of the data into a single db with multiple tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create/connect to db and build the TABLEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sqlite3 version: 2.6.0\n",
      "connected to database/rlc.db\n"
     ]
    }
   ],
   "source": [
    "# Create a db\n",
    "conn = create_connection('database/rlc.db')  # function I created in myfuncs file\n",
    "c = conn.cursor()\n",
    "#conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### daily_violations TABLE - from rlc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('cam_startend',), ('intersection_locations',), ('hourly_congestion',), ('congestion_regions',), ('hourly_weather',), ('intersection_cams',), ('signal_crashes',), ('cam_locations',), ('inersection_locations',), ('daily_violations',)]\n"
     ]
    }
   ],
   "source": [
    "sql_fetch_tables(c, conn)  # helper function in myfuncs\n",
    "delete_all_entries(c, conn, 'daily_violations') # in myfuncs\n",
    "rlc_df.to_sql('daily_violations', conn, if_exists='replace', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cam_locations TABLE - from cam_locs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('cam_startend',), ('intersection_locations',), ('hourly_congestion',), ('congestion_regions',), ('hourly_weather',), ('intersection_cams',), ('signal_crashes',), ('cam_locations',), ('daily_violations',)]\n"
     ]
    }
   ],
   "source": [
    "sql_fetch_tables(c, conn)  # helper function in myfuncs\n",
    "delete_all_entries(c, conn, 'cam_locations') # in myfuncs\n",
    "cam_locs.to_sql('cam_locations', conn, if_exists='replace', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### intersection_locations TABLE - from intersection_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('cam_startend',), ('intersection_locations',), ('hourly_congestion',), ('congestion_regions',), ('hourly_weather',), ('intersection_cams',), ('signal_crashes',), ('daily_violations',), ('cam_locations',)]\n"
     ]
    }
   ],
   "source": [
    "sql_fetch_tables(c, conn)  # helper function in myfuncs\n",
    "delete_all_entries(c, conn, 'intersection_locations') # in myfuncs\n",
    "intersection_df.to_sql('inersection_locations', conn, if_exists='replace', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### intersection_cams TABLE - from int_cams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('cam_startend',), ('intersection_locations',), ('hourly_congestion',), ('congestion_regions',), ('hourly_weather',), ('intersection_cams',), ('signal_crashes',), ('cam_locations',), ('inersection_locations',), ('daily_violations',)]\n"
     ]
    }
   ],
   "source": [
    "sql_fetch_tables(c, conn)  # helper function in myfuncs\n",
    "delete_all_entries(c, conn, 'intersection_cams') # in myfuncs\n",
    "int_cams.to_sql('inersection_cams', conn, if_exists='replace', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### signal_crashes TABLE - from crash_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('cam_startend',), ('intersection_locations',), ('hourly_congestion',), ('congestion_regions',), ('hourly_weather',), ('intersection_cams',), ('signal_crashes',), ('cam_locations',), ('inersection_locations',), ('daily_violations',), ('inersection_cams',)]\n"
     ]
    }
   ],
   "source": [
    "sql_fetch_tables(c, conn)  # helper function in myfuncs\n",
    "delete_all_entries(c, conn, 'signal_crashes') # in myfuncs\n",
    "crash_df.to_sql('signal_crashes', conn, if_exists='replace', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use this code to test any of your tables for proper data storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('2763', 4), ('2552', 5), ('2764', 4), ('1503', 3), ('2141', 3)]\n",
      "569593\n"
     ]
    }
   ],
   "source": [
    "query = c.execute(\"SELECT camera_id, violations FROM daily_violations;\").fetchall()\n",
    "print(query[:5])\n",
    "print(len(query))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
